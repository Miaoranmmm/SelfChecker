{
  "a9d41e2c-a63a-4f65-9e4e-ca5025cbe903": {
    "query": "What is the most significant breakthrough in the field of artificial intelligence in the last decade, and how has it impacted industries ranging from healthcare, finance, and transportation?",
    "response": "That's a very broad and interesting question. Artificial intelligence (AI) is a field that has been advancing rapidly over the past decade, with many breakthroughs and applications in various domains. Some of the most important advances in AI include:\n\n- **Deep learning**, a technique that uses multiple layers of artificial neural networks to learn from large amounts of data and perform complex tasks such as image recognition, natural language processing, speech synthesis, and more[^2^] [^4^]. Deep learning has enabled many of the recent achievements in AI, such as AlphaGoZero, a program that learned to play the game of Go from scratch and defeated the world champion[^1^], GPT-3, a language model that can generate coherent and diverse texts on almost any topic, and StyleGAN, a generative model that can create realistic and diverse images of faces, animals, landscapes, and more.\n- **Reinforcement learning**, a technique that allows an agent to learn from its own actions and rewards in an environment, without explicit supervision or guidance. Reinforcement learning has been used to solve challenging problems such as controlling robots, playing video games, optimizing logistics, and more. One of the most notable examples of reinforcement learning is AlphaStar, a program that learned to play the game of StarCraft II at a superhuman level by competing against itself and other players.\n- **Computer vision**, a subfield of AI that deals with understanding and processing images and videos. Computer vision has made significant progress in tasks such as face detection and recognition, object detection and segmentation, scene understanding, pose estimation, image synthesis, and more[^2^]. Computer vision has enabled many applications such as face unlock, augmented reality, self-driving cars, medical imaging, and more.\n- **Natural language processing**, a subfield of AI that deals with understanding and generating natural language. Natural language processing has made significant progress in tasks such as machine translation, sentiment analysis, question answering, text summarization, dialogue systems, and more[^2^]. Natural language processing has enabled many applications such as voice assistants, chatbots, social media analysis, content creation, and more.\n\nThese are just some of the major advances in AI over the past decade. There are many more subfields and applications that are not covered here. AI has impacted industries ranging from healthcare, finance, and transportation in various ways. Some examples are:\n\n- **Healthcare**: AI can help diagnose diseases, analyze medical images, recommend treatments, monitor patients' health, discover new drugs, and more. For instance, IBM Watson is a system that can analyze medical records and literature to provide evidence-based recommendations for cancer care. DeepMind is a company that develops AI systems for various healthcare applications such as protein folding, eye disease detection, and radiotherapy planning.\n- **Finance**: AI can help detect fraud, manage risk, optimize portfolios, provide financial advice, automate trading, and more. For instance, PayPal is a company that uses AI to prevent fraud and money laundering by analyzing millions of transactions per day. Wealthfront is a company that offers automated investment services based on AI algorithms that adjust portfolios according to market conditions and clients' goals.\n- **Transportation**: AI can help improve traffic management, optimize routes, reduce emissions, enhance safety, enable autonomous vehicles, and more. For instance, Waymo is a company that develops self-driving cars that use AI to perceive their surroundings and navigate complex scenarios. Uber is a company that uses AI to match drivers and riders, estimate fares and arrival times, optimize routes, and more.\n\nThese are just some examples of how AI has impacted industries over the past decade. There are many more industries and applications that are not covered here. AI is a powerful and versatile technology that has the potential to transform various aspects of our society for better or worse. It is important to be aware of its benefits and challenges as we enter a new decade of AI innovation.",
    "adaptiveCards": [
      {
        "type": "AdaptiveCard",
        "version": "1.0",
        "body": [
          {
            "type": "TextBlock",
            "text": "[1]: https://qualitance.com/blog/biggest-ai-breakthroughs-past-10-years/ \"The Biggest AI Breakthroughs over the Past 10 Years - QUALITANCE\"\n[2]: https://www.popsci.com/technology/stanford-artificial-intelligence-index-report/ \"How artificial intelligence exploded over the past decade - Popular Science\"\n[3]: https://ai100.stanford.edu/2021-report/standing-questions-and-responses/sq2-what-are-most-important-advances-ai \"SQ2. What are the most important advances in AI?\"\n[4]: https://www.cnn.com/2019/12/21/tech/artificial-intelligence-decade/index.html \"How AI ruled our lives over the past decade | CNN Business\"\n[5]: https://www.simplilearn.com/ten-years-of-artificial-intelligence-and-machine-learning-article \"10 Years of Artificial Intelligence and Machine Learning - Simplilearn.com\"\n[6]: https://www.bbvaopenmind.com/en/articles/the-past-decade-and-future-of-ais-impact-on-society/ \"The Past Decade and Future of AI\u2019s Impact on Society\"\n\nThat's a very broad and interesting question. Artificial intelligence (AI) is a field that has been advancing rapidly over the past decade, with many breakthroughs and applications in various domains. Some of the most important advances in AI include:\n\n- **Deep learning**, a technique that uses multiple layers of artificial neural networks to learn from large amounts of data and perform complex tasks such as image recognition, natural language processing, speech synthesis, and more[^1^][2] [^2^][4]. Deep learning has enabled many of the recent achievements in AI, such as AlphaGoZero, a program that learned to play the game of Go from scratch and defeated the world champion[^3^][1], GPT-3, a language model that can generate coherent and diverse texts on almost any topic, and StyleGAN, a generative model that can create realistic and diverse images of faces, animals, landscapes, and more.\n- **Reinforcement learning**, a technique that allows an agent to learn from its own actions and rewards in an environment, without explicit supervision or guidance. Reinforcement learning has been used to solve challenging problems such as controlling robots, playing video games, optimizing logistics, and more. One of the most notable examples of reinforcement learning is AlphaStar, a program that learned to play the game of StarCraft II at a superhuman level by competing against itself and other players.\n- **Computer vision**, a subfield of AI that deals with understanding and processing images and videos. Computer vision has made significant progress in tasks such as face detection and recognition, object detection and segmentation, scene understanding, pose estimation, image synthesis, and more[^1^][2]. Computer vision has enabled many applications such as face unlock, augmented reality, self-driving cars, medical imaging, and more.\n- **Natural language processing**, a subfield of AI that deals with understanding and generating natural language. Natural language processing has made significant progress in tasks such as machine translation, sentiment analysis, question answering, text summarization, dialogue systems, and more[^1^][2]. Natural language processing has enabled many applications such as voice assistants, chatbots, social media analysis, content creation, and more.\n\nThese are just some of the major advances in AI over the past decade. There are many more subfields and applications that are not covered here. AI has impacted industries ranging from healthcare, finance, and transportation in various ways. Some examples are:\n\n- **Healthcare**: AI can help diagnose diseases, analyze medical images, recommend treatments, monitor patients' health, discover new drugs, and more. For instance, IBM Watson is a system that can analyze medical records and literature to provide evidence-based recommendations for cancer care. DeepMind is a company that develops AI systems for various healthcare applications such as protein folding, eye disease detection, and radiotherapy planning.\n- **Finance**: AI can help detect fraud, manage risk, optimize portfolios, provide financial advice, automate trading, and more. For instance, PayPal is a company that uses AI to prevent fraud and money laundering by analyzing millions of transactions per day. Wealthfront is a company that offers automated investment services based on AI algorithms that adjust portfolios according to market conditions and clients' goals.\n- **Transportation**: AI can help improve traffic management, optimize routes, reduce emissions, enhance safety, enable autonomous vehicles, and more. For instance, Waymo is a company that develops self-driving cars that use AI to perceive their surroundings and navigate complex scenarios. Uber is a company that uses AI to match drivers and riders, estimate fares and arrival times, optimize routes, and more.\n\nThese are just some examples of how AI has impacted industries over the past decade. There are many more industries and applications that are not covered here. AI is a powerful and versatile technology that has the potential to transform various aspects of our society for better or worse. It is important to be aware of its benefits and challenges as we enter a new decade of AI innovation.\n",
            "wrap": true
          },
          {
            "type": "TextBlock",
            "size": "small",
            "text": "Learn more: [1. www.popsci.com](https://www.popsci.com/technology/stanford-artificial-intelligence-index-report/) [2. www.cnn.com](https://www.cnn.com/2019/12/21/tech/artificial-intelligence-decade/index.html) [3. qualitance.com](https://qualitance.com/blog/biggest-ai-breakthroughs-past-10-years/) [4. ai100.stanford.edu](https://ai100.stanford.edu/2021-report/standing-questions-and-responses/sq2-what-are-most-important-advances-ai) [5. www.simplilearn.com](https://www.simplilearn.com/ten-years-of-artificial-intelligence-and-machine-learning-article) [6. www.bbvaopenmind.com](https://www.bbvaopenmind.com/en/articles/the-past-decade-and-future-of-ais-impact-on-society/)",
            "wrap": true
          }
        ]
      }
    ],
    "sourceAttributions": [
      {
        "providerDisplayName": "How artificial intelligence exploded over the past decade - Popular Science",
        "seeMoreUrl": "https://www.popsci.com/technology/stanford-artificial-intelligence-index-report/",
        "searchQuery": "artificial intelligence breakthroughs last decade"
      },
      {
        "providerDisplayName": "How AI ruled our lives over the past decade | CNN Business",
        "seeMoreUrl": "https://www.cnn.com/2019/12/21/tech/artificial-intelligence-decade/index.html",
        "searchQuery": "artificial intelligence breakthroughs last decade"
      },
      {
        "providerDisplayName": "The Biggest AI Breakthroughs over the Past 10 Years - QUALITANCE",
        "seeMoreUrl": "https://qualitance.com/blog/biggest-ai-breakthroughs-past-10-years/",
        "searchQuery": "artificial intelligence breakthroughs last decade"
      },
      {
        "providerDisplayName": "SQ2. What are the most important advances in AI?",
        "seeMoreUrl": "https://ai100.stanford.edu/2021-report/standing-questions-and-responses/sq2-what-are-most-important-advances-ai",
        "searchQuery": "artificial intelligence breakthroughs last decade"
      },
      {
        "providerDisplayName": "10 Years of Artificial Intelligence and Machine Learning - Simplilearn.com",
        "seeMoreUrl": "https://www.simplilearn.com/ten-years-of-artificial-intelligence-and-machine-learning-article",
        "searchQuery": "artificial intelligence breakthroughs last decade"
      },
      {
        "providerDisplayName": "The Past Decade and Future of AI\u2019s Impact on Society",
        "seeMoreUrl": "https://www.bbvaopenmind.com/en/articles/the-past-decade-and-future-of-ais-impact-on-society/",
        "searchQuery": "artificial intelligence breakthroughs last decade"
      }
    ],
    "fact-checking": {
      "subclaims": [
        "Deep learning has enabled many of the recent achievements in AI, such as AlphaGoZero, GPT-3, and StyleGAN.",
        "Reinforcement learning has been used to solve challenging problems such as controlling robots, playing video games, optimizing logistics, and more.",
        "One of the most notable examples of reinforcement learning is AlphaStar, a program that learned to play the game of StarCraft II at a superhuman level by competing against itself and other players.",
        "Computer vision has made significant progress in tasks such as face detection and recognition, object detection and segmentation, scene understanding, pose estimation, image synthesis, and more.",
        "Computer vision has enabled many applications such as face unlock, augmented reality, self-driving cars, medical imaging, and more.",
        "Natural language processing has made progress in tasks such as machine translation, sentiment analysis, question answering, and text summarization.",
        "AlphaGoZero is a program that learned to play the game of Go from scratch and defeated the world champion.",
        "IBM Watson is a system that can analyze medical records and literature to provide evidence-based recommendations for cancer care.",
        "DeepMind is a company that develops AI systems for healthcare applications such as protein folding, eye disease detection, and radiotherapy planning.",
        "Waymo is a company that develops self-driving cars that use AI to perceive their surroundings and navigate complex scenarios."
      ],
      "queries": [
        "Deep learning recent achievements AI AlphaGoZero GPT-3 StyleGAN",
        "Reinforcement learning applications controlling robots video games logistics",
        "AlphaStar reinforcement learning StarCraft II superhuman level competition",
        "Computer vision progress face detection recognition object segmentation scene understanding pose estimation image synthesis",
        "Computer vision applications face unlock augmented reality self-driving cars medical imaging",
        "Natural language processing progress machine translation sentiment analysis question answering text summarization",
        "AlphaGoZero world champion Go game",
        "IBM Watson cancer care recommendations",
        "DeepMind healthcare applications protein folding eye disease detection radiotherapy planning",
        "Waymo self-driving cars AI perceive surroundings navigate complex scenarios"
      ],
      "search_results": {
        "Deep learning has enabled many of the recent achievements in AI, such as AlphaGoZero, GPT-3, and StyleGAN.": [
          {
            "title": "AlphaGo - Google DeepMind",
            "url": "https://deepmind.google/technologies/alphago/",
            "content": [
              "AlphaGo - Google DeepMind",
              "Technology AlphaGo mastered the ancient game of Go, defeated a Go world champion, and inspired a new era of AI systems. Our artificial intelligence (AI) system, AlphaGo, learned to master the ancient Chinese game of Go \u2014 a profoundly complex board game of strategy, creativity, and ingenuity.",
              "AlphaGo defeated a human Go world champion a decade before experts thought possible, inspired players around the world to discover new approaches, and arguably, became the strongest Go player in history.",
              "It proved that AI systems can learn how to solve the most challenging problems in highly complex domains.",
              "AlphaGo in training.",
              "Go was long considered a grand challenge for AI.",
              "The game is a googol times more complex than chess \u2014 with an astonishing 10 to the power of 170 possible board configurations.",
              "That\u2019s more than the number of atoms in the known universe.",
              "The strongest Go computer programs only achieved the level of human amateurs, despite decades of work.",
              "Standard AI methods struggled to assess the sheer number of possible moves and lacked the creativity and intuition of human players.",
              "We created AlphaGo, an AI system that combines deep neural networks with advanced search algorithms. One neural network \u2014 known as the \u201cpolicy network\u201d \u2014 selects the next move to play.",
              "The other neural network \u2014 the \u201cvalue network\u201d \u2014 predicts the winner of the game.",
              "Initially, we introduced AlphaGo to numerous amateur games of Go so the system could learn how humans play the game.",
              "Then we instructed AlphaGo to play against different versions of itself thousands of times, each time learning from its mistakes \u2014 a method known as reinforcement learning.",
              "Over time, AlphaGo improved and became a better player.",
              "I thought AlphaGo was based on probability calculation and that it was merely a machine.",
              "But when I saw this move, I changed my mind.",
              "Surely, AlphaGo is creative.",
              "Lee SedolWinner of 18 world Go titles In October 2015, AlphaGo played its first game against the reigning three-time European Champion, Fan Hui.",
              "AlphaGo won the first ever match between an AI system and Go professional, scoring 5-0.",
              "AlphaGo then competed against legendary Go player Lee Sedol \u2014 winner of 18 world titles, and widely considered the greatest player of that decade.",
              "AlphaGo's 4-1 victory in Seoul, South Korea, in March 2016 was watched by over 200 million people worldwide.",
              "This landmark achievement was a decade ahead of its time.",
              "Watch This game earned AlphaGo a 9 dan professional ranking \u2014 the first time a computer Go player had received the highest possible certification.",
              "During the games, AlphaGo played several inventive winning moves.",
              "In game two, it played Move 37 \u2014 a move that had a 1 in 10,000 chance of being used.",
              "This pivotal and creative move helped AlphaGo win the game and upended centuries of traditional wisdom.",
              "Then in game four, Lee Sedol played a Move 78, which had a 1 in 10,000 chance of being played.",
              "Known as \u201cGod\u2019s Touch\u201d, this move was just as unlikely and inventive as the one AlphaGo played two games earlier \u2014 and helped Sedol win the game.",
              "Players of all levels have examined these moves ever since.",
              "AlphaGo\u2019s victory inspired a new era of AI systems. It was conclusive proof that the underlying neural networks could be applied to complex domains, while the use of reinforcement learning showed how machines can learn to solve incredibly hard problems for themselves, simply through trial-and-error.",
              "Its ability to look ahead and plan are also still used in today\u2019s AI systems. These ideas allowed us to develop stronger versions of AlphaGo and the system continued to play competitively, including defeating the world champion.",
              "Now, its successors \u2014 AlphaZero, MuZero, and AlphaDev \u2014 are building upon AlphaGo\u2019s legacy to help solve increasingly complex challenges that impact our everyday lives.",
              "AlphaZero and MuZero Powerful, general AI systems that mastered a range of board games and video games \u2014 and are now helping us solve real-world problems. Research MuZero: Mastering Go, chess, shogi and Atari without rules In 2016, we introduced AlphaGo, the first artificial intelligence (AI) program to defeat humans at the ancient game of Go.",
              "Two years later, its successor - AlphaZero - learned from scratch to.",
              ".",
              ".",
              "Research AlphaZero: Shedding new light on chess, shogi, and Go In late 2017 we introduced AlphaZero, a single system that taught itself from scratch how to master the games of chess, shogi (Japanese chess), and Go, beating a world-champion program in each.",
              ".",
              ".",
              "AlphaStar First AI to master the real-time strategy game StarCraft II, long considered a grand challenge for AI research.",
              "I accept Google's Terms and Conditions and acknowledge that my information will be used in accordance with Google's Privacy Policy."
            ]
          },
          {
            "title": "AlphaGo&#39;s AI upgrade gets round the need for human input",
            "url": "https://www.newscientist.com/article/mg23631484-000-alphagos-ai-upgrade-gets-round-the-need-for-human-input/",
            "content": [
              "AlphaGo&#39;s AI upgrade gets round the need for human input",
              "Advertisement Explore by section Explore by subject Explore our products and services By Timothy Revell 18 October 2017 Our winning days are numberedurbancow/Getty Our winning days are numbered urbancow/Getty NOT so long ago, mastering the ancient Chinese game of Go was beyond the reach of artificial intelligence.",
              "But then AlphaGo, Google DeepMind\u2019s AI player, started to leave even the best human opponents in the dust.",
              "Yet even this world-beating AI needed humans to learn from.",
              "Then, on Wednesday, DeepMind\u2019s new version ditched people altogether.",
              "AlphaGo Zero has surpassed its predecessor\u2019s abilities, bypassing AI\u2019s traditional method of learning games, which involves watching thousands of hours of human play.",
              "Instead, it simply starts playing at random, honing its skills by repeatedly playing against itself.",
              "Three days and 4.",
              "9 million such games later, the result is the world\u2019s best Go-playing AI.",
              "\u201cIt\u2019s more powerful than previous approaches because we\u2019ve removed the constraints of human knowledge,\u201d says David Silver, the lead researcher for AlphaGo.",
              "Advertisement \u201cHumankind has accumulated Go knowledge from millions of games played over thousands of years,\u201d the authors write in their paper.",
              "\u201cIn the space of a few days.",
              ".",
              ".",
              "AlphaGo Zero was able to rediscover much of this Go knowledge, as well as novel strategies that provide new insights into the oldest of games.",
              "\u201d AlphaGo Zero\u2019s alternative approach has allowed it to discover strategies humans have never found.",
              "For example, it learned many different josekis \u2013 sequences of moves that result in no net loss for either side.",
              "Plenty of josekis have been written down during the thousands of years Go has been played, and initially AlphaGo Zero learned many of the familiar ones.",
              "But as its self-training continued, it started to favour previously unknown sequences.",
              "To test these new moves, DeepMind pitted AlphaGo Zero against the version that beat 18-time world champion Lee Sedol.",
              "In a 100-game grudge match, it won 100-0.",
              "This is despite only training for three days, compared to several months for its predecessor.",
              "After 40 days of training, it also won 89-11 against a better version of AlphaGo that had defeated world number one Ke Jie (Nature, DOI: 10.",
              "1038/nature24270).",
              "\u201cIt\u2019s more powerful because we have removed the constraints of human knowledge\u201d DeepMind hopes this method will have applications beyond Go.",
              "\u201cThe team are already working to apply this to scientific problems like protein-folding,\u201d said CEO Demis Hassabis at a press conference on Monday.",
              "Climate science, drug discovery and quantum chemistry could also benefit, he said.",
              "This approach might also solve one of the thorniest issues that has faced AI: the need for copious training data.",
              "\u201cWith this approach you no longer have to rely on getting expert quality human data,\u201d says David Churchill at Memorial University, Canada.",
              "Yet there are drawbacks too.",
              "For an AI to learn by itself, it needs to be programmed with the rules of the world it inhabits.",
              "That works for worlds with clear and simple rules, but would quickly become impossible for more complicated tasks like driving.",
              "Even in cases for which the rules are clear, AlphaGo Zero\u2019s abilities may not transfer.",
              "Although Go is a challenging game, it still has many attributes that tailor it to conquest by AI systems. So although DeepMind has now created the world\u2019s best Go player twice, it will have a tougher task proving that the same approach can be useful beyond board games.",
              "\u201cIn 10 years, I hope that these kinds of algorithms will be routinely advancing the frontiers of scientific research,\u201d says Hassabis.",
              "This article appeared in print under the headline \u201cGo-playing super AI transcends humanity\u201d Topics: Advertisement Explore the latest news, articles and features Features Subscriber-only News Subscriber-only News Free News Subscriber-only Trending New Scientist articles 1 2 3 4 5 6 7 8 9 10 Advertisement Download the app"
            ]
          },
          {
            "title": "Overview on DeepMind and Its AlphaGo Zero AI",
            "url": "https://dl.acm.org/doi/abs/10.1145/3206157.3206174",
            "content": [
              "Overview on DeepMind and Its AlphaGo Zero AI",
              "Department of Computer Science, Valdosta State University Department of Computer Science, Valdosta State University Department of Computer Science, Valdosta State University Department of Computer Science, Valdosta State University Department of Mathematics, Valdosta State University Department of Mathematics, Valdosta State University Department of Mathematics, Valdosta State University Department of Mathematics, Valdosta State University Department of Mathematics, Valdosta State University Department of Mathematics, Valdosta State University This alert has been successfully added and will be sent to: You will be notified whenever a record that you have chosen has been cited.",
              "To manage your alert preferences, click on the button below.",
              "Please log in to your account The goal of this paper is to give insight into what the company known as DeepMind is and what accomplishments it is making in the fields of Machine Learning and Artificial Intelligence.",
              "Among their accomplishments, particular focus will be placed upon the recent success of AlphaGo Zero which made waves in the machine learning and artificial intelligence communities.",
              "The various parts of AlphaGo Zero's implementation such as reinforcement learning, neural networks, and Monte Carlo Tree Searches will be explained with brevity to give better understanding of the process as a whole.",
              "General and reference Document types Surveys and overviews The current development in deep learning is witnessing an exponential transition into automation applications.",
              "This automation transition can provide a promising framework for higher performance and lower complexity.",
              "This ongoing transition .",
              ".",
              ".",
              "Automated ML is an emerging field in Machine Learning that helps developers and new data scientists with little data science knowledge build Machine Learning models and solutions without understanding the complexity of Learning Algorithm selection, and .",
              ".",
              ".",
              "Deep learning (DL) and reinforcement learning (RL) methods seem to be a part of indispensable factors to achieve human-level or super-human AI systems. On the other hand, both DL and RL have strong connections with our brain functions .",
              ".",
              ".",
              "Check if you have access through your login credentials or your institution to get full access on this article.",
              "Copyright \u00a9 2018 ACM Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page.",
              "Copyrights for components of this work owned by others than ACM must be honored.",
              "Abstracting with credit is permitted.",
              "To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee.",
              "Request permissions from [email protected] Association for Computing Machinery New York, NY, United States Request permissions about this article.",
              "View or Download as a PDF file.",
              "View online with eReader.",
              "View this article in digital edition.",
              "https://dl.",
              "acm.",
              "org/doi/abs/10.",
              "1145/3206157.",
              "3206174 We are preparing your search results for download .",
              ".",
              ".",
              "We will inform you here when the file is ready.",
              "Your file of search results citations is now ready.",
              "Your search export query has expired.",
              "Please try again."
            ]
          }
        ],
        "Reinforcement learning has been used to solve challenging problems such as controlling robots, playing video games, optimizing logistics, and more.": [
          {
            "title": "Reinforcement learning for logistics and supply chain management ...",
            "url": "https://www.sciencedirect.com/science/article/pii/S136655452200103X",
            "content": [
              "Reinforcement learning for logistics and supply chain management ...",
              "Checking your browser before accessing \"www.",
              "sciencedirect.",
              "com\".",
              "Redirecting.",
              ".",
              ".",
              "Please enable Cookies and reload the page.",
              "Reference Number: 829eba571b244ce9 IP Address: 205.",
              "172.",
              "168.",
              "145 User Agent: Timestamp: About ScienceDirect Shopping cart Contact and supportTerms and conditionsPrivacy policy We use cookies to help provide and enhance our service and tailor content and ads.",
              "By continuing you agree to the use of cookies.",
              "Copyright \u00a9 2020 Elsevier B.",
              "V.",
              "or its licensors or contributors.",
              "ScienceDirect \u00ae is a registered trademark of Elsevier B.",
              "V."
            ]
          },
          {
            "title": "Reinforcement learning in robotic applications: a ... - Springer",
            "url": "https://link.springer.com/article/10.1007/s10462-021-09997-9",
            "content": [
              "Reinforcement learning in robotic applications: a ... - Springer",
              "Access provided by University of Massachusetts Amherst W.",
              "E.",
              "B.",
              "Du Bois Library 5430 Accesses 42 Citations 3 Altmetric Explore all metrics Cite this article In recent trends, artificial intelligence (AI) is used for the creation of complex automated control systems. Still, researchers are trying to make a completely autonomous system that resembles human beings.",
              "Researchers working in AI think that there is a strong connection present between the learning pattern of human and AI.",
              "They have analyzed that machine learning (ML) algorithms can effectively make self-learning systems. ML algorithms are a sub-field of AI in which reinforcement learning (RL) is the only available methodology that resembles the learning mechanism of the human brain.",
              "Therefore, RL must take a key role in the creation of autonomous robotic systems. In recent years, RL has been applied on many platforms of the robotic systems like an air-based, under-water, land-based, etc.",
              ", and got a lot of success in solving complex tasks.",
              "In this paper, a brief overview of the application of reinforcement algorithms in robotic science is presented.",
              "This survey offered a comprehensive review based on segments as (1) development of RL (2) types of RL algorithm like;",
              "Actor-Critic, DeepRL, multi-agent RL and Human-centered algorithm (3) various applications of RL in robotics based on their usage platforms such as land-based, water-based and air-based, (4) RL algorithms/mechanism used in robotic applications.",
              "Finally, an open discussion is provided that potentially raises a range of future research directions in robotics.",
              "The objective of this survey is to present a guidance point for future research in a more meaningful direction.",
              "Avoid common mistakes on your manuscript.",
              "In recent times, robotics has seen a rising trend in various areas such as disaster management, healthcare, logistics warehouse, space, etc.",
              "However, robots used for current applications have a limit in both intelligence and self-learning abilities.",
              "Thus, they have failed to achieve the same level of accuracy as humans possess.",
              "Therefore, to address this limitation, researchers in robotics have integrated artificial intelligence (AI) with robots.",
              "An AI-enabled robot can learn and gain new knowledge from interaction with the environment.",
              "This helps in the development of a self-learning automated robot.",
              "It improves the overall performance of the robot in the completion of tasks.",
              "Reinforcement learning (RL) is a framework that helps in the development of self-learning capability in robots.",
              "Basically, RL is a sub-field of machine learning (ML) which is a part of AI.",
              "Broadly, machine learning is classified into three parts, namely, (1) supervised learning: it is a learning mechanism that maps the input to output based on training data-set and data is labeled (2) unsupervised learning: it is a learning mechanism where agent finds the hidden patterns in data-set and data is not labeled (3) reinforcement learning: it is a learning mechanism where an agent learns through interaction with the environment.",
              "Figure 1a, b shows the framework of machine learning mechanism and agent-environment interaction in standard RL framework respectively (Sutton 1992;",
              "Bo\u0308hmer et al.",
              "2015;",
              "Rylatt et al.",
              "1998;",
              "Sutton and Barto 2018;",
              "Ribeiro 2002).",
              "Comparative analysis of machine learning is presented by Wang et al.",
              "(2012).",
              "a Framework of machine learning, b agent-environment interaction in standard RL framework RL framework helps in learning of agents through the interaction with the environment.",
              "At the beginning of the learning process, the initial policy opted by an agent will direct the agent to take action in the present state.",
              "The agent-environment interaction provides a reward signal and the agent transit into the next state.",
              "Here, the reward signal is pre-designed by the domain expert.",
              "Basically, the reward signal quantifies how good is the action in that state.",
              "The policy is updated based on the obtained reward signal.",
              "This agent-environment interaction generates a trajectory of the current state, execution of action in that state, receiving of reward signal, a transition of an agent into the next state, and policy update.",
              "This whole process is repeated in a cyclic manner until the learning process is completed as shown in Fig.",
              "1b.",
              "In a more general way, the goal of any RL algorithm is to maximize the cumulative reward for finding the optimal policy.",
              "In the beginning, an agent follows a random policy or any pre-defined policy.",
              "Then, two tasks are performed for finding the optimal policy, namely, policy evaluation and policy improvement.",
              "First, policy evaluation means that an agent needs to evaluate the value function for the currently adopted policy.",
              "Second, based on the evaluation of value function the agent modifies its policy known as policy improvement.",
              "These two tasks are performed in a cyclic manner until the optimal policy is obtained.",
              "Thus, the obtained policy is used by agents/robots for the accomplishment of tasks.",
              "In the literature (Zhang et al.",
              "2016;",
              "Zhou et al.",
              "2016;",
              "Bu et al.",
              "2008;",
              "Arulkumaran et al.",
              "2017;",
              "Sallab et al.",
              "2017;",
              "Luo et al.",
              "2018;",
              "Nguyen et al.",
              "2017;",
              "Li et al.",
              "2019;",
              "He et al.",
              "2017;",
              "Luo et al.",
              "2017;",
              "Littman 2015;",
              "Yang and Gu 2004;",
              "Luo et al.",
              "2019;",
              "Le et al.",
              "2019;",
              "Lin et al.",
              "2011), obtained policy by RL shows its effectiveness and capability for multi-agent system, deep learning, human\u2013robot interaction, target-based search, tracking control, output regulation, adaptive learning etc.",
              "A survey on policy search methods specifically in robotics is found in Deisenroth et al.",
              "(2013b).",
              "A multi-agent system is a group of autonomous agents.",
              "They have a common interactive environment.",
              "Multi-agent RL (MARL) algorithms are developed for speeding the learning process of multiple agents in a common environment.",
              "These algorithms improve the coordination between agents.",
              "This makes the overall system robust because if some agents fail to reach the desired goal, then the remaining agents take over the same task and try to solve it.",
              "Effectiveness of MARL algorithm has been tested on applications like resource management, automated marketing, robotics, distributed control, robot soccer game, telecommunications, etc (Zhang et al.",
              "2016;",
              "Zhou et al.",
              "2016;",
              "Bu et al.",
              "2008;",
              "Yang and Gu 2004;",
              "Duan et al.",
              "2012;",
              "Madden and Howley 2004).",
              "In literature (Modares et al.",
              "2017), the authors have applied the learning of optimal policy in synchronization with other agents without knowing the dynamics of each other.",
              "In some cases when the environment is stochastic, the transition of an agent to the next state is not known.",
              "So, the bayesian non-parametric statistic approaches with partially observable RL is used for the determination of transition probability for an agent (Doshi-Velez et al.",
              "2013).",
              "In practice, robotic systems have higher degrees of freedom (DoFs).",
              "Thus, the number of states and actions required by RL algorithms see exponential growth.",
              "Therefore, RL faces a critical problem of higher dimensionality.",
              "This degrades the overall performance of the agent.",
              "In literature (Schaul et al.",
              "2015), various function approximators are proposed to tackle the dimensionality problem.",
              "Here, we discuss the integration of deep learning with RL.",
              "It provides an approximated solution.",
              "Literature shows that an approximated solution also provides the same accuracy as other methods (Nguyen et al.",
              "2017).",
              "Briefly, the integration of deep learning with RL yields deep reinforcement learning (DeepRL).",
              "DeepRL shows its ability in solving the application of robotics such as navigation and path tracking of the robot, object picking task, under-water target-based search, etc.",
              ", (Arulkumaran et al.",
              "2017;",
              "Sallab et al.",
              "2017).",
              "Since most DeepRL techniques are not much effective for robotics because they required more interaction time to learn control policies.",
              "This problem arises because the state-space representation is needed to learn as a part of the control policy, which is based on observed rewards.",
              "However, the reward function quantifies how good the state is, which means it does not tell how to find a good state representation from the sensory observations.",
              "So, state-space representation learning can be useful.",
              "There are different topologies are provided for integrating the state-space representation into RL algorithms (de Bruin et al.",
              "2018).",
              "It reduces the overall dimension which yields the least time-consuming.",
              "In most cases, the neural network architecture in deep learning is trained using backpropagation.",
              "Thus, the training of deep learning architecture is tedious.",
              "As an alternative approach, which is based on the evolution of the human brain known as \u201cneuro-evolution\u201d is presented in Stanley et al.",
              "(2019).",
              "Integration of neuro-evolution with DeepRL leads to further advancement in DeepRL.",
              "Its application in robotics can lead to a more advanced intelligent system like humans.",
              "As the usage of robots in the real-world is rising.",
              "Robots are interacting morewith the environment and humans.",
              "Some authors in literature have exploited this interaction.",
              "So, Human-centered learning algorithms are developed.",
              "In human-centered algorithms, human feedback is used to improve the learning process.",
              "Basically, algorithms evaluate the human feedback that improves the learning efficiency of agents significantly.",
              "It leads to increasing its applicability in solving real-time applications.",
              "Some survey papers have reported on the human-centered learning process (Li et al.",
              "2019;",
              "He et al.",
              "2017;",
              "Littman 2015).",
              "Due to an increase in computational power and the growing popularity of RL in various fields, it deserves a focused survey.",
              "Although, some survey papers on the RL is reported in literature (Kaelbling et al.",
              "1996;",
              "Dayan and Niv 2008;",
              "Neftci and Averbeck 2002;",
              "Kiumarsi et al.",
              "2017;",
              "Bertsekas 2018;",
              "Gosavi 2009).",
              "However, most of them only focus on the development of RL algorithms. A key survey on \u201creinforcement learning in robotics\u201d is presented in literature (Kober et al.",
              "2013).",
              "This survey establishes a link between robotics and RL.",
              "Particularly, it mainly focused on value-function based and policy search methods.",
              "A case study on \u201cball-in cup\u201d with various RL approaches is accomplished.",
              "The survey provides an insight that the implementation of RL methods in robotics is not straightforward.",
              "Instead, it requires some set of skills like reward function shaping, parameter sensitivity, dealing with high dimensional continuous actions.",
              "In the current survey, firstly author provides a basic overview of RL methods such as Actor-Critic, DeepRL, Multi-agent, and Human-centered that are implemented in robotics.",
              "Secondly, provide a comprehensive survey on the application of RL in robotics.",
              "Thirdly, a discussion on various RL algorithms/mechanisms presented in the literature on various robotic applications is provided.",
              "The main focus of this paper is on the wide range of RL applications in robotics that is based on air, land, and water-based usage.",
              "It makes this survey unique in nature.",
              "The main contributions of this paper are: A basic overview of RL approaches based on Actor-Critic methods, DeepRL, Multi-agent, and Human-centered that applied in robotic science is presented.",
              "Detailed survey of robotic applications in air, land, and water-based on the RL is discussed.",
              "Various learning mechanisms developed by authors in the literature are presented.",
              "Key challenges faced by RL and some open problems are provided.",
              "Paper is organized as: Sect.",
              "2 presents the overview of reinforcement learning, which is the cornerstone of robotic application.",
              "Section 3 describes an application of various RL approaches in robotics.",
              "Section 4 discussed the survey on some exciting RL mechanisms adopted by authors to find the optimal policy in different applications as found in the literature.",
              "The general outlook is provided in Sect.",
              "5.",
              "Finally, Sect.",
              "6 provides a conclusion.",
              "The concept of RL is derived from the early work of Bush & Moseller and Rescorla & Wagner in rhesus monkey striatum.",
              "In order to perform a voluntary movement, the striatum present in the mid-brain of the monkey takes an action.",
              "The selection of action is based on signals received from the cortex.",
              "The signal generated by the cortex is based on the choice selected from a different set of choices.",
              "After the accomplishment of the movement, an output signal is received.",
              "Dopamine neurons present in brain evaluate a reward prediction error i.",
              "e., RPE = \\((r(t)-w_i(t))\\).",
              "RPE is the difference between experience output and the value obtained from the striatum.",
              "This complete process is captured by the Rescorla-Wagner equation (Rescorla et al.",
              "1972;",
              "Averbeck and Costa 2017), and it is given by (1), Equation (1) summarizes the learning process, where the update is controlled by the learning parameter \\(\\gamma\\).",
              "Extension of Rescorla-Wagner equation leads to temporal-difference (TD) rule, where agent decides an action based on the state it encounters.",
              "Thus, TD rule at action i is represented by (2), where variable \\(s_t\\) is state at t, and \\(\\lambda\\) is the discount rate for future estimates of values.",
              "This generalization is very successful in finding the optimal policy in robotics.",
              "Comparative analysis/parallelism of RL in the biological and artificial system is presented in a survey paper (Neftci and Averbeck 2019).",
              "RL is a sequential methodology, where learning process of agent takes place in stochastic environments.",
              "Basically, the agent learns about the optimal policy.",
              "The optimal policy defines which action is needed in current state.",
              "In order to generate an optimal policy, agents interact with the environment.",
              "Agent-environment interaction generates a trajectory of state-action-reward-next state.",
              "The complete process is working in discretization manner and it is modeled by Markov decision process (MDP), denoted by \\(<S,A,P,R, \\lambda>\\).",
              "At time t, the agent chooses an action from action-space A and execution of the action results agent to reach in next-state \\(S_{t+1} \\ \\epsilon \\ \\{ S \\}\\).",
              "The transition of agent for current state \\(S_t\\) to next state \\(S_{t+1}\\) is governed by transition probabilities.",
              "Then, the agent receives a scalar reward, i.",
              "e., \\(r_{t+1}\\), from an environment.",
              "The reward is defined by \\(R: S \\times A \\times S \\rightarrow\\) \\({\\mathbb {R}}\\).",
              "The goal of the agent is to maximize the total accumulated reward received at time t, represented as \\(\\sum \\nolimits _{j=0}^{\\infty } \\lambda ^j r_{t+j+1}\\), where \\(\\lambda \\ \\epsilon \\ [0,1]\\) is the discount rate.",
              "Therefore, Overall return over policy is given by \\(\\sum \\nolimits _{j=0}^{\\infty } \\lambda ^j R(s_{t+j},\\pi (s_{t+j}),s_{t+j+1})\\).",
              "Thus, expected return over policy is given by Eq.",
              "(3), Like most RL algorithms (Bertsekas 1995;",
              "Puterman 2014;",
              "Watkins and Dayan 1992;",
              "Sutton 1988), in temporal difference (such as Q-learning, SARSA etc.)",
              ", agent learns the action-value function defined as \\(Q^*(s,a) = \\max \\limits _{\\pi } Q^{\\pi }(s,a)\\).",
              "TD error \\(\\delta _t\\) is given by (4), where \\(Q(s',a')\\) & Q(s, a) is expected value of state \\(s'\\) at time step \\(t+1\\) and expected value of state s at time step t respectively.",
              "Here, TD error is used to update the iterative relation as given by (5), As per literature, Q-learning uses \\(max(Q(s',a'))\\) instead of \\(Q(s',a')\\) as compared to SARSA algorithm.",
              "It makes Q-learning and SARSA working as offline and online algorithms respectively.",
              "The major disadvantage of these algorithms is that the expected future return is not exact because these returns are truncated to zero after some time steps.",
              "So, these algorithms may not yield good outcomes, especially for highly sensitive robotic applications.",
              "Thus, Deep learning techniques are integrated with RL for better estimation.",
              "In real-life applications like robotics, it is impossible to store the exact value function for every state-action pairs separately.",
              "Because the learning process is in a continuous state and action space.",
              "So, most RL algorithms practically use function approximation to cover all states and actions.",
              "In literature, we found some parametrized RL algorithms (Grondman et al.",
              "2012).",
              "Here these algorithms are classified into three groups: Actor, critic & Actor-critic methods.",
              "The meaning of actor and critic are policy and value functions respectively.",
              "Variance is present in expected returns because of estimation.",
              "So, in order to reduce the variance in the estimation of expected returns, the critic method uses TD learning (Boyan 2002).",
              "They select an action that provides the highest reward known as greedy actions.",
              "Then it is used for deriving the policy (Sutton and Barto 2018).",
              "However, in order to find the best action, there is a need for optimization in every state that the agent encounters.",
              "This is a significant drawback because it requires an intensive computation, especially when the action space is continuous.",
              "Thus, the critic method uses the discretization of the action space.",
              "However, it undermines the ability of continuous action for finding the true optimum.",
              "Basically, critic-methods like Q-learning (Watkins 1989;",
              "Bradtke et al.",
              "1994) and SARSA algorithm (Rummery and Niranjan 1994), uses a state-action value function only and no explicit function for policy.",
              "Thus, the optimal value function is obtained by approximating the solution of bellman equation (Sutton and Barto 2018).",
              "A deterministic policy based on the greedy search is obtained using optimization over state-action value function given by (6), The resulted policy will not provide a guaranteed near-optimal for the approximated value function.",
              "As per literature, Q learning and SARSA doesn\u2019t converge to an optimal solution even for simple MDPs with approximator (Baird 1995;",
              "Gordon 1995;",
              "Tsitsiklis and Van Roy 1996).",
              "However, in some articles(Melo et al.",
              "2008), authors provide the guarantee of convergence if trajectories are sampled according to on-policy distribution for some parameters function approximators.",
              "Conditions for convergence and bound on error is presented in (Tsitsiklis and Van Roy 1997).",
              "Actor-methods are primarily applied with parameterized policy (the advantage of these policies is that it can generate continuous actions).",
              "Thus, the optimization techniques can be directly applied over parameter space.",
              "However, optimization methods such as policy gradient suffer from slow learning (because it has a high variance in estimates of a gradient).",
              "Policy gradient techniques are generally known as actor-methods that don\u2019t use any stored value function (Gullapalli 1990;",
              "Williams 1992).",
              "Here, the goal of RL is to maximize the total return.",
              "Reward obtained can be presented by discounted reward and average reward (Bertsekas 1995).",
              "In the Discounted reward setting, Cost function C is defined as the expected total rewards that start from initial state \\(s_0\\) over some policy \\(\\pi (s,a)\\) as given by Eq.",
              "(7), Average reward per time step over some policy \\(\\pi (s,a)\\) is given by Eq.",
              "(8), In policy gradient method, policy \\(\\pi (s,a)\\) is parameterized by parameter l \\(\\epsilon\\) \\(R^k\\).",
              "Consider, cost function given by (7) and (8) are function of l.",
              "Thus, gradient of the cost function (assume the cost function is continuous) w.",
              "r.",
              "t.",
              "l is given by (9), Thus, the local optimal solution obtained by updating the rule iteratively as (10), The advantage of the actor method is that it allows the policy evaluation in continuous action space.",
              "And also provides a strong convergence property (Sutton and Barto 2018;",
              "Peters and Schaal 2008).",
              "The learning rate \\(\\gamma\\) must satisfy the equation (11) for making the gradient free from bias.",
              "However, the estimated gradient has larger variance and calculated gradient have no knowledge of past estimates, a major disadvantage of actor-methods (Riedmiller et al.",
              "2007;",
              "Peters et al.",
              "2010;",
              "Sutton et al.",
              "2000).",
              "The actor-critic method combines the advantages of both actor and critic methods.",
              "It brings parametrized policy for the advantage of computation in continuous action space from actor method and low variance in the estimation of return from the critic-method.",
              "Thus, the critic\u2019s estimate allows the actor to update gradients with lower variance.",
              "It also improves the learning process.",
              "In comparison to the other two methods, actor-critic provides a good convergence property (Konda and Tsitsiklis 2000).",
              "Here, the policy is updated in the gradient direction with a small learning rate.",
              "Thus, the small change in value function leads to less oscillatory behavior of policy (Baird III and Moore 1999).",
              "The schematic framework of actor-critic is shown in Fig.",
              "2.",
              "Learning framework has two parts: (a) actor (policy) (b) critic (value function).",
              "At a given state s, actor-part generates a control input u.",
              "Whereas, critic-part process the obtained reward.",
              "The actor is updated after some steps of policy evaluation, using the information gained from critic.",
              "In-depth knowledge of actor-critic methods can be obtained from (Konda and Tsitsiklis 2000;",
              "Witten 1977;",
              "Barto et al.",
              "1983).",
              "Comparative analysis of actor-method, critic-method, and actor-critic method are given in Table 1.",
              "Framework of the Actor-critic Method.",
              "Here, the dashed line represents Critic is responsible for updating of actor and itself (Grondman et al.",
              "2012) In the past, RL is limited to the lower-dimensional problem because of complexity in memory and computation.",
              "In recent years, the power of deep neural network enables us to use new tools, such as function approximation and representation learning, to overcome the limitation of RL.",
              "Therefore RL is integrated with deep learning.",
              "Resulted DeepRL helps in scaling-up the RL computation into higher-dimensional problems. In literature, Deep Q-Network (DQN) is developed by google\u2019s deep-mind Mnih et al.",
              "(2015a).",
              "The salient contribution of DQN is: (1) experience replay and target network stabilize the training of value function approximation (2) only minimum knowledge is required to design end-to-end RL.",
              "The major drawback of DQN is that it over-estimate the value function because it uses max-operator for both selection and evaluation of an action.",
              "So, in order to overcome the problem of over-estimation, Van Hasselt et al.",
              "(2016) proposes a Double-DQN algorithm.",
              "It uses a max operator for the selection of actions only.",
              "Several survey papers on DeepRL applied in various applications have reported in (Nguyen et al.",
              "2017;",
              "Liu et al.",
              "2019;",
              "Nguyen et al.",
              "2018).",
              "The evolution of DeepRL is shown in Fig.",
              "3.",
              "Evolution of DeepRL Agents in multi-agent systems are pre-programmed by using the knowledge of domain experts.",
              "Pre-programming of agents behaviour before encountering the different situation in complex environments is a very tedious task.",
              "Thus, multi-agent RL algorithms are developed.",
              "It is found in literature that multi-agent RL have been applied in robotics, economics, data mining, etc (Vlassis 2007;",
              "Parunak 1999;",
              "Stone and Veloso 2000;",
              "Yang and Gu 2004).",
              "Basically, multi-agent RL algorithms are derived from model-free algorithms like temporal-difference (specifically Q-learning).",
              "In multi-agent RL, MDPs is represented by tuple \\(<S,A_1,\\ldots A_m,P,R_1,\\ldots ,R_m,\\lambda>\\).",
              "where, m is the number of agents;",
              "S: sets of the discrete environment states;",
              "\\(A_i\\), \\(i = 1,\\ldots ,m\\) are discrete sets of actions defined by joint action set \\(A = A_1 \\times A_2 \\cdots \\times A_m\\);",
              "State transition probability is defined as \\(P: S \\times A \\times S \\rightarrow [0,1]\\) and \\(R_i : S \\times A \\times S \\rightarrow\\) \\({\\mathbb {R}}\\), \\(i = 1,2,\\ldots m\\) are reward functions of all agents.",
              "In Multi-agent RL, transition of states is a result of joint actions, i.",
              "e., \\(A_k = [A_{1,k}^T,\\ldots A_{m,k}^T]^T\\), \\(A_k \\epsilon A\\), \\(A_{i,k} \\epsilon A_i\\).",
              "Policies \\(\\pi _i : S \\times A_i \\rightarrow [0,1]\\) forms the joint policy \\(\\pi\\).",
              "Q-function depends on joint action and policy defined as \\(Q_i^{\\pi }:S \\times A \\rightarrow\\) \\({\\mathbb {R}}\\).",
              "In multi-agent RL framework, the behavior of agents is given by the values of individual reward as: (1) If \\(R_1=\\cdots =R_m\\) then the stochastic behavior of the agent is said to be fully-cooperative, it means the goal of all agents is to maximize the total reward (2) If \\(m=2\\) and \\(R_1 = -R_2\\), then the stochastic behavior of the agent is said to be fully-competitive, it means the goal of agents is opposite to each other (3) In some cases, the stochastic behavior of the agent is neither fully-cooperative nor fully-competitive, said to be mixed behavior.",
              "Depending on agent awareness and type of task assigned, multi-agent RL algorithms are categorized as given in Table 2 (Bu et al.",
              "2008).",
              "The goal of multi-agent RL is to make a balance in adaptiveness and stability of learning between agents.",
              "Here, stability and adaptiveness ensure the stationary policy and improvement in performance when agents change their policies respectively (Bowling and Veloso 2002;",
              "Greenwald et al.",
              "2003;",
              "Hu and Wellman 2003;",
              "Bowling and Veloso 2001).",
              "Framework in human-centered RL algorithm (Li et al.",
              "2019) The major drawback of traditional RL is that the learning process is very slow.",
              "At the beginning of the learning process, RL needs a lot of trials and errors for finding an optimal policy.",
              "However, for real-time applications like real robotics, failure at the beginning may cause large costs.",
              "So, reward shaping techniques are developed for the learning of agent in complex robotics task (Ng et al.",
              "1999;",
              "Thomaz and Breazeal 2008;",
              "Tenorio-Gonzalez et al.",
              "2010).",
              "In real-world applications, robots need to learn how to perform a specific task and learn according to human likings.",
              "Thus, the human-centered algorithm has been developed (Ho et al.",
              "2015;",
              "Li et al.",
              "2019).",
              "Human-centered RL algorithms use reward shaping techniques.",
              "The agent learns the optimal policy using evaluative feedback from a human operator.",
              "This framework helps agents to speed up the learning process, especially feedback from ordinary people.",
              "In these algorithms, agents get evaluated feedback from the human observers which quantifies the quality of the selected action.",
              "Agent updates the policy online based on feedback.",
              "The complete framework of Human-centered RL is shown in Fig.",
              "4.",
              "Depending on human-feedback, comparison and classification of human-centered RL are shown in Table 3 and Fig.",
              "5 respectively.",
              "Human-centered RL algorithm Generally, DeepRL networks are trained using policy gradient learning algorithms. It has two drawbacks: (1) computation cost is high due to deep learning networks, and (2) tuning of network parameters is done by gradient methods.",
              "However, due to the structure of the deep network, the objective function is non-convex in most cases.",
              "Thus, the solution converges to a local optimum point.",
              "Evolutionary algorithm substitutes gradient methods for tuning of DeepRL networks.",
              "However, an evolutionary algorithm can be considered as policy gradient methods because it is similar to finite-difference-approximation of the gradient.",
              "Thus, neuroevolution comes into the picture.",
              "Neuroevolution is a technique that is used to design the architecture of the neural networks and learning rules which is based on evolutionary principles in the biological brain.",
              "It ultimately includes the learning of hyperparameters, activation function, forming of new architecture with time.",
              "Different algorithms are developed with time such as, neuroevolution of augmenting topologies (NEAT) that evolves both weights and architecture of ANN.",
              "However, it has encoding challenges in large ANN\u2019s.",
              "So, HyperNEAT is developed to address encoding issues (Such et al.",
              "2017;",
              "Stanley et al.",
              "2019).",
              "Basically, these methods tune a large number of parameters simultaneously rather than one parameter at a time.",
              "Thus, when neuroevolution integrated with DeepRL, it leads to generalized artificial intelligence, which is advantageous to produce more advanced intelligent robots.",
              "Application of RL in Robotic Science In this section, the authors have discussed the application of RL in robotics.",
              "Here, the applications are categorized based on air, under-water, and land-based usage.",
              "Figure 6 shows the application of various RL based learning in robotic science based on usage as per literature.",
              "Under-water based robots This section focused on the application of RL in under-water robotics.",
              "The autonomous underwater robot is very advantageous in the study of deep-sea, i.",
              "e., minerals under the crust of the earth, aquatic life, etc.",
              "However, it is very difficult to control the autonomous underwater robot because the environment is dynamic.",
              "Thus, the authors have developed various architectures for underwater robots as reported in literature (Palomeras et al.",
              "2012;",
              "El-Fakdi and Carreras 2013;",
              "Yu et al.",
              "2015b;",
              "Hu et al.",
              "2019;",
              "Cao et al.",
              "2019;",
              "Carlucho et al.",
              "2018;",
              "Cheng and Zhang 2018;",
              "Frost et al.",
              "2015).",
              "Tracking & Navigation Cables are laid widespread in the deep sea for communications or the internet.",
              "There is a necessity to track the cables for fault detection or required maintenance.",
              "Thus, in an article (Palomeras et al.",
              "2012), authors have developed a hybrid approach using a natural actor-critic (NAC) algorithm with LSTD-Q(\\(\\lambda\\)) for cable tracking mission.",
              "Likewise, the two-step learning approach based on an actor-critic algorithm for visual-based cable tracking is developed in El-Fakdi and Carreras (2013).",
              "Here the hydrodynamic model of the vehicle is used.",
              "Firstly, a policy is learned in simulation.",
              "Then, a learned policy is transferred to Ictineu AUVs in a real environment.",
              "In deep-sea, there is a requirement for effective control mechanisms for an autonomous system for navigation and obstacle avoidance.",
              "Episodic natural actor-critic (ENAC) algorithm is implemented for path planning and navigation in the deep sea for marine archaeology (Frost et al.",
              "2015).",
              "In article (Cheng and Zhang 2018), a concise DeepRL obstacle avoidance (CDRLOA) based on avoidance reward algorithm is presented for navigation in an unknown environment.",
              "Control The effective control mechanism consists of adaptiveness with parameter variation/noise is required for AUVs.",
              "A combined framework of DeepRL and Actor-critic algorithm is applied on Nessie VII AUVs for adaptive control (Carlucho et al.",
              "2018).",
              "Target-search Sometimes it is necessary to make target based search in deep-sea.",
              "Thus, the authors have developed an integrated approach of DeepRL and DQL algorithm based on dual Q-network for target-based search and implemented on Neptune-I AUVs (Cao et al.",
              "2019).",
              "In article Hu et al.",
              "(2019), authors have developed an integrated methodology of temporal-difference with deterministic policy gradient (DPG) algorithm for plume-tracing task.",
              "Here, a model of the chemical plume is based on probabilistic descriptions of spatial and temporal evolution is used.",
              "Multi-coordination In complex environments like deep-sea, it is necessary to make proper coordination between various AUVs.",
              "Thus, authors in Yu et al.",
              "(2015b) have developed a behavioral-based hierarchical architecture composed of fuzzy logic and Q-learning.",
              "The developed approach is tested on a 2vs2 water polo game.",
              "Table 4 comprises the application of RL in underwater robotic.",
              "Air-based robots Air-based robots have found numerous applications like surveillance, disaster management, real-time communication, multi-coordination operations, etc.",
              "Future aerial robots need to operate more intelligently with uncertainty present in an environment like turbulence present in the air, loss of GPS connection, etc.",
              "Therefore, the vehicle needs to operate efficiently and autonomously based on its own-board sensors.",
              "As reported in literature (dos Santos et al.",
              "2015;",
              "Xiao et al.",
              "2017;",
              "Zhu et al.",
              "2018;",
              "Hu et al.",
              "2018;",
              "Wang et al.",
              "2019;",
              "Zeng et al.",
              "2016;",
              "Yin et al.",
              "2019;",
              "Wu et al.",
              "2019;",
              "La et al.",
              "2014;",
              "Faust et al.",
              "2014;",
              "Hung and Givigi 2016;",
              "Hwangbo et al.",
              "2017;",
              "Lambert et al.",
              "2019;",
              "Shi et al.",
              "2016), authors have developed various topologies to address the difficulty faced by aerial vehicles.",
              "In this section, we have discussed the application of RL in Air-based robots as given below: Transportation Delivery of time-sensitive goods like body organs, etc.",
              "in time, is a very challenging task.",
              "In article (Faust et al.",
              "2014), the authors have proposed a model-free based RL with continuous inputs for rendezvous cargo delivery task by quadcopter.",
              "In which, quadcopter need to carry a suspended cargo and handover to a land-based robot in a swing-free fashion.",
              "Construction UAVs can be advantageous on the construction site.",
              "It improves communication, safety, or does survey by taking real-time imaging of the field.",
              "Thus, an adaptive scheme for the planning of construction using quad-rotor, an aerial vehicle based on the RL and heuristic is presented in (dos Santos et al.",
              "2015).",
              "Flock Control In a flock, flocking-followers need to follow the leader of the flock.",
              "In article (Hung and Givigi 2016), authors have purposed a flock control mechanism based on Q-learning, where the learning rate of followers is variable based on Peng\u2019s Q(\\(\\lambda\\)).",
              "Navigation Navigation of UAVs in a dynamic environment is a very big challenging task.",
              "In article Zhu et al.",
              "(2018), the authors have proposed DeepRL based DQN algorithms for shepherd game.",
              "Where the aerial robot needs to establish contact with ground vehicles and sequentially drive them to safe regions with obstacle avoidance in the path.",
              "Likewise, in article Wang et al.",
              "(2019), the authors have proposed a DeepRL algorithm based on policy gradient within an actor-critic framework for navigation of UAVs in complex environments.",
              "In article (Shi et al.",
              "2016), the author proposed an integrated approach of image-based visual servoing (IBVS) with fuzzy logic based RL for quad-copter.",
              "Protection from threats Cyber-attack on UAVs have posed a great threat to its operation.",
              "To mitigate this challenge, authors have proposed a mechanism in Xiao et al.",
              "(2017), Deep Q-learning is used for speeding the learning process of agents in UAVs to counter when it is under-attack, without knowing the dynamics of the attacker model.",
              "Cellular network aided In the article, Hu et al.",
              "(2018) and Yin et al.",
              "(2019), authors have proposed real-time sensing with UVAs to serve as aerial bases for the ground station for effective communication.",
              "Control task Control of quadcopter in a stochastic environment is very challenging.",
              "In the article, Hwangbo et al.",
              "(2017) and Lambert et al.",
              "(2019), authors have presented a policy optimization and model-based DeepRL with Model predictive control, respectively for the control of quadcopter.",
              "Multi-coordination In article (Zeng et al.",
              "2016), authors have presented an energy-efficient and continuous movement control (\\(E^2CMC\\)) algorithm for control of multiple drones.",
              "Its salient feature is that the multiple drones can coordinate each other in an efficient manner.",
              "Likewise, in article (Viseras and Garcia 2019), the authors have developed a DeepIG algorithm for a quadcopter.",
              "It helps in learning the quadcopters to learn the mechanism of gathering new knowledge in a coordinated manner.",
              "Here, the multiple robots use the principle of information-gain mechanism for either mapping or gathering information about unknown terrain.",
              "Disaster Management In a complex disaster environment, UAVs can be employed to target based search.",
              "In article (Wu et al.",
              "2019), the author proposed a DeeRL based snake algorithm for searching the targets like injured humans.",
              "Table 5 comprises the application of RL in air-based Robotic.",
              "Land-based robots The autonomous land-based vehicle is a robot that operates without a human operator.",
              "The vehicle uses high-end technology based on AI.",
              "Though, land-based robots find a wide range of applications in the real-world such as picking objects, navigate through a crowded area without collision, manufacturing sites, etc.",
              "However, it faces some challenges like uncertainty present in the real environment, disturbances presented in feedback signals obtained from vision-based sensors, etc.",
              "In literature, authors have presented many approaches for control of land-based autonomous vehicles as described below: Navigation and obstacle avoidance Navigation of the robot through a crowded area and finding the optimal path to reach the end goal of avoiding the collisions are very difficult tasks.",
              "Many learning mechanisms are proposed in the literature (Xu et al.",
              "2011;",
              "Whitbrook et al.",
              "2007).",
              "Fuzzy controllers are most prominent for solving this task (Beom and Cho 1995;",
              "Yung and Ye 1999;",
              "Gu and Hu 2007;",
              "Li et al.",
              "2010;",
              "Er and Deng 2005).",
              "Hereby fuzzy rules and parameters of the controller are tuned by RL.",
              "Specifically, the hybrid approach for obstacle avoidance is presented for the adaption of robots to the new environment without human intervention.",
              "The developed approach is based on the actor-critic structure (Er and Deng 2005;",
              "Hwang et al.",
              "2009).",
              "As per literature, some authors have proposed a fuzzy-based neural network, and its parameters are tuned using model-based RL, DeepRL, etc.",
              ", for obstacle avoidance and navigation (Zalama et al.",
              "2002;",
              "Ye et al.",
              "2003;",
              "Meeden 1996;",
              "Antonelo and Schrauwen 2014;",
              "Wang et al.",
              "2018b;",
              "Ohnishi et al.",
              "2019;",
              "Markova and Shopov 2019).",
              "In article (Bejar and Moran 2019), the authors have presented a fuzzy-based neuro controller using DeepRL for reverse parking of truck in parking plot.",
              "It is important to navigate the mobile robot in complex environments.",
              "Thus, in an article (Juang and Hsu 2009) authors presented a Q-learning enabled based on ant-optimization.",
              "A policy network based on a deep Q-network is presented for path planning in the dynamic place (Lv et al.",
              "2019).",
              "In order to increase the robustness for initial states and learning ability of mobile robots, a quantum-inspired RL is proposed in literature (Dong et al.",
              "2010).",
              "A multi-objective neuro-evolutionary approach is proposed for autonomous driving, where perception-based planning deep neural network is used for estimation of desired state trajectories over a finite prediction horizon (Grigorescu et al.",
              "2019).",
              "Response time to obstacle avoidance/navigation task should be less, thus in article (Plaza et al.",
              "2009) authors have presented an integration of cell mapping technology and Q-learning for WMV car-robot.",
              "When the obstacles are moving like in crowded places, navigation becomes a very tough task.",
              "In (Lin et al.",
              "2013), weighted based Q-learning is presented for multi-robots.",
              "Autonomous RL based learning for multiple interrelated tasks for the iCub robot for obstacle avoidance is presented (Santucci et al.",
              "2019), where learning is automated.",
              "Manufacturing In hazardous places like manufacturing sites (high temperature), etc.",
              ", robots can be used effectively in place of human operators.",
              "Thus, in literature, some authors have proposed a mechanism for smoothing of metal surfaces(Tzafestas and Rigatos 2002).",
              "It is based on sliding mode control and a fuzzy controller.",
              "Controller parameters are tuned by RL.",
              "Controlling mechanism that involves multiple learning levels for the execution of partially changeable tasks like industrial tasks, etc.",
              ", is also presented in literature (Roveda et al.",
              "2017).",
              "Here, controller parameters are learned by iterative learning and RL.",
              "Object picking tasks In the industry or household work, robots need to pick things from one place and put that in another place.",
              "As per literature, An integrated approach of genetic programming and RL is developed (Kamio and Iba 2005).",
              "The proposed approach is applied to the four-legged robots and humanoid robots for box-moving applications.",
              "Likewise, a hybridized algorithm based on bio-inspired (Farahmand et al.",
              "2009) i.",
              "e., RL, cooperative evolution, and culturally based memetic algorithm, is developed.",
              "It helps in the automatic development of behavior-agent.",
              "The effectiveness of the algorithm is evaluated on object-picking tasks.",
              "Likewise, the interactive RL approach is proposed for a simulated robot for cleaning of table (Cruz et al.",
              "2016).",
              "Some authors in literature developed a learning mechanism for picking objects correctly without slipping.",
              "In the proposed mechanism, the author uses RL, plus visual perception based on reactive control (Falco et al.",
              "2018).",
              "Hereby, the objective of RL is to fulfill the in-hand manipulation goals and minimization the intervention of reactive control.",
              "In (Rombokas et al.",
              "2012), RL enabled synergistic control of ACT hand is presented.",
              "Here, learning of hand is based on path integral policy-improvement for basic tasks such as sliding the knob/switch.",
              "In order to distinguish between things and pick the right one in moving objects.",
              "A DeepRL based learning for the 3AT robot is presented in (Yang et al.",
              "2018).",
              "Here, the control is in continuous action space.",
              "Likewise, a 7-DoF arm of ABB Yumi is presented to learn the policies for grasping, reaching, and lifting tasks based on DeepRL (Breyer et al.",
              "2019).",
              "Control tasks Controlling the higher degrees of freedom (DOF) system is a very complex task.",
              "In literature, the authors have accomplished the control of different DOF robots (Foglino et al.",
              "2019;",
              "Wang et al.",
              "2013;",
              "Hazara and Kyrki 2019;",
              "Xi et al.",
              "2019;",
              "Caarls and Schuitema 2015;",
              "Carlucho et al.",
              "2017;",
              "Heidrich-Meisner and Igel 2008;",
              "Da Silva et al.",
              "2012;",
              "Muelling et al.",
              "2010).",
              "Likewise, 7-DOF simulated robot has been controlled using model-free RL (Stulp et al.",
              "2012) and learning of controller for a 32-DOF humanoid robotic system based on policy gradient RL for the stair climbing task is developed (Fu and Chen 2008).",
              "Motion control of two-link brachiation and 2-DOF SCARA robot is presented in Hasegawa et al.",
              "(1999);",
              "Sharma and Gopal (2008).",
              "Here, fuzzy-based self-scaling RL is used for faster convergence and robustness against disturbance.",
              "Likewise, balancing of the robot on a rotating frame is a very challenging task.",
              "Thus, integration of model-based RL with model-free RL is proposed for balance control of a biped robot on a rotating frame where the velocity of the rotating frame is not known in advance (Xi et al.",
              "2019).",
              "Vision based A Controller for wheeled mobile robots based on robust vision-based with Q-learning developed (Wang et al.",
              "2010).",
              "Here, the vision sensor is used to provide a feedback signal back to the controller.",
              "Likewise, a robotic soccer goalkeeper for catching the ball is learned based on experience replay (Adam et al.",
              "2011).",
              "In article (Gottipati et al.",
              "2019), authors developed a deep active localization based on DeepRL and end-to-end differential method.",
              "Here the perception and planning for complex environments like a maze is developed.",
              "The end-to-end differentiable method is presented for the training of agents in simulations and then the trained model is transferred to the real robot without any refinement.",
              "The proposed system is composed of two modules: (1) Convolutional Neural Network (CNN) for perception and (2) DeepRL for planning.",
              "Jump in the intelligence of robot Tabular model-free online algorithm,i.",
              "e., SARSA (\\(\\lambda\\)) learning is applied to games like First Person Shooting (FPS), in which a lot of different learning methodology is combined with a RL controller to obtain new bot artificial intelligence (McPartland and Gallagher 2010).",
              "Protection from threats In the real world, it is necessary to make an AI system safe from threats.",
              "In literature (La et al.",
              "2014), a multi-robot system which integrates the reinforcement learning and flocking control that ensures the agent to learn about the avoidance of enemy/predator in between the path while maintaining the communication and network connectivity with each other.",
              "Disaster management In a natural disaster, many lives are lost due to inadequate amount of human resources.",
              "Therefore, integrated AI-enabled robots can aid the disaster management team for rescue beings.",
              "Thus, as per literature authors have developed a robust architecture based on RL, which provides a semi-autonomous control for rescuing robots in unknown environment (Doroodgar et al.",
              "2014), aim of the controller is to enable the robot to self-learning in unknown environments by its own experiences with the cooperation of human operators.",
              "Human\u2013robot interaction (HRI) HRI has found numerous application in the literature (Modares et al.",
              "2015;",
              "Li et al.",
              "2017a;",
              "Ansari et al.",
              "2017;",
              "Huang et al.",
              "2019;",
              "Khamassi et al.",
              "2018;",
              "Koc\u0327 and Peters 2019;",
              "Deng et al.",
              "2017).",
              "As per literature (Modares et al.",
              "2015), a human\u2013robot interaction framework is proposed to assist human operators for specific-task with better efficiency and minimum workload.",
              "Basically, the framework has two controllers.",
              "The first one is an inner loop controller, which makes unknown dynamics of robot behaving like a robot impedance model, then this model is converted into a linear quadratic regulator (LQR) problem.",
              "The obtained LQR problem is iteratively solved by RL.",
              "The second one is an outer loop controller, which consists of human and robot to perform a specific task.",
              "Likewise.",
              "in Li et al.",
              "(2017a), an adaptive impedance controller is developed based on the Lyapunov function, and then the complete framework is reformulated as an LQR problem when the human arm model is unknown.",
              "Afterward, the LQR problem is optimized using integral RL.",
              "It helps in minimizing tracking error.",
              "To address the issue of adaption of the robotic assistant rollator to patients in different situations.",
              "A model-based RL is proposed for adapting the control policy of robotic assistant (Chalvatzaki et al.",
              "2019).",
              "Learn from demonstration In article (Hwang et al.",
              "2015), biped robot learns from walking patterns.",
              "Two different Q-learning mechanisms are proposed, the first mechanism learns a policy to adjust its walking by the gait-to-gait analysis to make the robot stable, and the second mechanism for refinement of walking.",
              "This allows walking faster subject to constraints.",
              "It also reduces the dimensionality of action space for faster learning.",
              "Safe passage from crowded area When the dynamics of system and environment is unknown, then learning approaches are most suitable in designing a control policy for robots.",
              "However, learning from scratch required a lot of trial runs.",
              "These trails can damage the robot.",
              "Therefore, in literature (Koryakovskiy et al.",
              "2018), an approach is proposed to mitigate this problem by integrating the RL with the model-predictive controller.",
              "Likewise, an algorithm is proposed for the safe passage of robot in crowded dynamic environments (Truong and Ngo 2017).",
              "Optimal control Parametrized batch RL algorithm based on the actor-critic architecture is designed for optimal control of autonomous land vehicles (ALVs) wherein, least-square batch updating rule is implemented for better efficiency (Huang et al.",
              "2017).",
              "Likewise, event-triggering optimal controller is proposed to non-linear robotic arm based on identifier-critic architecture (Yang et al.",
              "2017), where identifier network is composed of the feed-forward network (FFN) which aim to retrieve knowledge about unknown dynamics and complete framework of architecture is developed using RL.",
              "Cognitive In order to provide cognitive capability like human-level decision-making ability.",
              "A multi-task learning policy is proposed for the learning of the non-linear feedback policy that makes robot self-reliant (Wang et al.",
              "2018a).",
              "Miscellaneous In recent times, the usage of robots in medical science is increased significantly.",
              "In article (Turan et al.",
              "2019) author presented a magnetically actuated soft capsule endoscope with minimizing the trajectory tracking error based on DeepRL.",
              "Table 6 comprises the different approaches integrated with RL in land-based robotic applications.",
              "In this section, a brief discussion of RL algorithms applied in various applications in the previous section is presented.",
              "Sarsa (\\(\\lambda\\) ) Algorithm Integration of sarsa algorithm with eligibility traces results in sarsa (\\(\\lambda\\)) (McPartland and Gallagher 2010).",
              "Eligibility traces are used to speed up the learning process by allowing the past actions for taking the advantage from the current reward, and it also learn the sequence of actions.",
              "Algorithm 1 shows the steps of the Sarsa algorithm.",
              "e(s,a) \\(\\leftarrow\\) \\(\\gamma\\) \\(\\lambda\\) e(s,a) reduces the eligibility trace of past visited state-action pair.",
              "Thus, this reduction impacts the state-action pairs that have been visited in past and allows them to get more of the current reward.",
              "Natural Actor-Critic (NAC) Algorithm Basic policy gradient methods have shown their applicability in various applications.",
              "However, their implementation in real tasks suggests that its result are not much satisfactory.",
              "Hence, the NAC algorithm is developed.",
              "It integrates the advantage of both policy gradient and value function methods.",
              "It contains two parts, (a) First one is critic structure, which is represented as a value function and it is approximated as a linear combination of parameter l and basis function \\(\\phi\\)(s) i.",
              "e., \\(V^\\pi (s) = \\phi (s) l\\), and (b) Second one is actor structure, where policy is represented over probability distribution defined as, \\(\\pi (a|s)\\).",
              "The goal of the RL algorithm is to maximize the expected return represented by (12), where \\(d^{\\pi }(s)\\) is discounted state distribution.",
              "Actor-critic and various other policy iteration contain two parts, the first one is policy evaluation and the second is policy improvement.",
              "Thus, policy evaluation exploits the experienced data, and policy improvement utilizes the evaluation step to improve the current policy until the convergence is obtained.",
              "Actor improvements: Actor\u2019s policy derivative is defined as \\(\\nabla _l log \\pi (a|s)\\).",
              "Gradient of the equation (12) is given by (13), Where \\(b^{\\pi }(s)\\) is defined as a baseline.",
              "The difference between \\((Q^{\\pi } (s,a)- b^{\\pi }(s))\\) is replaced by compatable function approximation parametrized by vector w defined by (14), Combining equation (13) & (14) yields (15), However, computation of \\(F_l\\) is expensive because discount state distribution is unknown.",
              "By using fisher metric, \\(\\nabla _l C_l\\) is approximately equal to w.",
              "Therefore, the estimation of parameter w is necessary.",
              "Hence, policy parameters are updated as: \\(l_{i+1} = l_{i} + \\gamma w\\).",
              "Critic estimation: Critic evaluates whether policy \\(\\pi\\) is good or bad.",
              "Accordingly, it provides the basis of improvement, i.",
              "e., change in parameter l as \\(\\Delta l\\) = \\(\\gamma w\\).",
              "Here, compatable function approximation is used and that is represented by advantage function as: \\(A^{\\pi } (s,a) = Q^{\\pi } (s,a) - V^{\\pi } (s)\\).",
              "The major disadvantage of this function is that it cannot be learned from TD-methods.",
              "Therefore, compatable function is approximated using rollouts or least square minimization methods.",
              "It gives the estimated state-action value function.",
              "However, these methods required training data sets and also have high variance.",
              "Bellman equation is utilized as an alternative and it is defined by (16), Substituting, \\(A^{\\pi } (s,a)\\) = \\(f^{\\pi }_{w}(s,a)\\) and \\(V^{\\pi }(s) = (\\phi (s))^T l\\) in equation (16).",
              "State-action value function at time t is defined by (17), Equation (17), leads to two algorithms: NAC with LSTD-Q(\\(\\lambda\\) ) The solution of equation (17) is obtained using LSTD-Q(\\(\\lambda\\)) policy evaluation algorithm.",
              "Thus, define a new basis for the value function and it is given by (18), A new basis helps in the reduction of bias and variance in the learning process.",
              "It estimates the state action function.",
              "In critic-part, it helps in an approximation of equation (17), yields two results: the first one is parameter l and the second one is w.",
              "Thus, the policy parameters are updated as \\(\\Delta l_t = l w_t\\).",
              "Episodic NAC Guarantee of unbiased estimate for natural gradient is necessary.",
              "So, the equation (17) is summed along a sample path as represented in (19), As N \\(\\rightarrowtail\\) \\(\\infty\\) or episodic task, the last term is eliminated.",
              "Therefore, each rollout provides one equation.",
              "It becomes a regression problem.",
              "For non-stochastic tasks the gradient is obtained after \\(dim(l)+1\\) rollouts.",
              "For more information, refer to article (Peters et al.",
              "2005), where authors derive the natural actor-critic algorithm based on LSTD-Q(\\(\\lambda\\)) and episodic.",
              "Off-policy integral RL Algebraic Riccati Equation (ARE) is given by, Basically, it is an iterative policy method, that involves two steps: (a) policy evaluation evaluates the value function related to fixed policy using IRL Bellman equation and system dynamics is not involved (b) policy is improved using the value obtained in policy evaluation step.",
              "A small exploratory probing noise is added to control input for sufficient exploration of the state space, which is important for proper convergence of optimal value function and this satisfies the persistently exciting (PE) qualitatively (Modares et al.",
              "2015).",
              "Deterministic Policy Gradient (DPG) Algorithm DPG algorithm comes under the framework of actor-critic methods.",
              "In article (Silver et al.",
              "2014;",
              "Yin et al.",
              "2019), authors have discussed DPG algorithms. When the action space in MDP is continuous then there is a required deterministic policy, i.",
              "e., \\(a = \\pi _l(s)\\) instead of stochastic policy.",
              "In other words, the learning model should map the continuous state to continuous action.",
              "DPG algorithms have two components: (a) Experience replay and (b) Model learning.",
              "The DPG algorithm framework is shown in Fig.",
              "7.",
              "In the first component, training data are generated by taking actions based on a policy network whose parameters are randomly initialized.",
              "Collected data in every time-step is placed in the buffer and have formed of tuples: \\(<S_t,A_t,R_t,S_{t+1}>\\).",
              "For diversity in experience, additional noise is mixed in a policy network.",
              "Thus, actions generated by the policy network are much more diverse.",
              "In the second portion, the model is trained using the collected data.",
              "Therefore, the main policy and value network is learned alternatively using stored data in replay buffer.",
              "Parameters of the main value network are updated using the gradient method, i.",
              "e., minimization of the loss function.",
              "The loss function is defined as (20), Whereas, the main policy network is updated using a policy gradient given by (21), where \\(T_i = Q'(F(S_{i+1}), \\pi ' (F(S_{i+1})))\\) , F is feature network, Q and \\(Q'\\) are main and target value network respectively, \\(\\pi\\) and \\(\\pi '\\) represents main and target policy network respectively and l denotes network parameters.",
              "Here, parameters of the feature network are updated once either with the main or target network.",
              "Simultaneously, the target network is updated as a copy of the main network for some iterations.",
              "Framework of DPG algorithm (Yin et al.",
              "2019) Parametrized Batch Actor-Critic (PBAC) Algorithm PBAC algorithm in which the parametrized feature vectors are trained from sample data for approximating value function and policies.",
              "This algorithm has a same linear feature for both actor and critic structures compared to previous actor-critic methods.",
              "It is theoretically proved that the same feature can provide efficient learning and fast convergence (Huang et al.",
              "2017).",
              "Least-square batch methods are used for better learning efficiency.",
              "Pseudo code for PBAC learning is given in algorithm 2.",
              "Probabilistic Inference for Learning Control (PILCO) Commonly, model-based learning methods are more promising compared to model-free methods like Q-learning and TD-learning.",
              "Because model-based methods can efficiently extract more information from available data.",
              "However, model-based methods suffer from model bias, i.",
              "e., here it is assumed that the learned model more appropriately resembles the real world.",
              "Especially, more problem occurs when few data are available and have no prior knowledge of tasks to be learned.",
              "In article (Deisenroth and Rasmussen 2011), the authors proposed a probabilistic inference for learning control (PILCO) algorithm, which is a model-based policy search method.",
              "The framework has three parts: (a) dynamic learning model: in order to address the model uncertainty, probabilistic dynamic model (non-parametric Gaussian process) is used, (b) analytic approximate policy evaluation: deterministic approximate inference is used and (c) gradient-based policy improvement.",
              "The salient feature of this algorithm is that it achieves data efficiency even in the continuous domain and hence, it can directly be applied to robots.",
              "Policy Improvement with Path Integrals (\\(PI^2\\) ) \\(PI^2\\) is a probabilistic learning method and inherited the principles of stochastic optimal control from the path integral.",
              "Hamilton-Jacobi-Bellman equation is used to transform the policy improvements into the approximated path integral.",
              "This algorithm doesn\u2019t have an open tuning parameter, except exploration noise.",
              "In article (Theodorou et al.",
              "2010), authors derives the generalized path integral optimal control problem as: Optimal control Probability Local control where superscript c is used to represent the actuated/controllable state.",
              "\\(G^{(c)}_{t_i}\\) is control transition matrix, \\(\\lambda\\) is regularization parameter.",
              "The path integral problem is connected with reinforcement learning as parametrized policies.",
              "Here, dynamic movement primitives (DMP) representation is used as generalized policies.",
              "It is beneficial to use this representation because by varying only one parameter the trajectory changes its shape.",
              "Initial and final (goal) states are fixed.",
              "The authors derived some important expressions are (For more detailing refer to this article (Theodorou et al.",
              "2010)): Probability Cost where \\(N_{t_j} = \\frac{R^{-1}g_{t_j} {g_{t_j}}^T }{{g_{t_j}}^T R^{-1} g_{t_j}}\\) Parameter update for every time step based on probability average Final updation of parameter New value of parameter Given: immediate cost: \\(r_t = q_t + {l_t}^T R l_t\\), terminal cost: \\(\\phi _{t_K}\\), stochastic policy: \\(a_t = (g_t)^T(l + \\epsilon _{t})\\), basis function: \\(g_{t_i}\\), initial parameter l and variance in mean-zero noise: \\(\\sum _{\\epsilon }\\).",
              "Initially after rollout, equation (25) is used to compute the probability at time \\(t_i\\) for each trajectory and cost is computed by (26).",
              "Then in every step, parameter update is calculated based on (27).",
              "Equation (28) is used as a final average of parameter updating.",
              "Then, change in parameter is added to the old value of the parameter given by (29).",
              "Salient features of this algorithm are: (a) updated equation have no numerical instabilities (b) scalable to a higher dimension.",
              "Deep-Q network (DQN) As the state and action become very large in number or continuous, memory required by Q-learning becomes inevitable.",
              "Thus, mnih et.",
              "al.",
              "in 2013 presented an integrated framework of deep learning and Q-learning that solves the sample correlation and memory limitation.",
              "In 2015 (Mnih et al.",
              "2015b), authors proposed a framework of the double-network structure.",
              "Its salient features are: (a) deep convolutional neural network (CNN), state-action value Q(s,a) is represented by Q(s,a;",
              "l) and parametrized by l.",
              "It solves the memory limitation up-to some extent (b) experience replay is used to solve the correlation of samples (c) a separate target network is used to handle the TD targets.",
              "It estimates the TD target and state-action values.",
              "Thus, the weights l are updated by (30), Weighted Behaviour Q-Learning (WBQL) Algorithm In multi-robot formations, each robot must interact with each other and the environment based on information gain.",
              "In article (Lin et al.",
              "2013), these capabilities are regarded as self-awareness behavior.",
              "Thus, the authors proposed an algorithm that is based on a self-awareness mechanism.",
              "Here, weights are used to mark individual behavior as relative importance.",
              "Q-learning is used to update the weights, i.",
              "e., Policy learning by weighting exploration with the returns (PoWER) Algorithm A deterministic mean policy is defined as: \\({\\hat{a}} = l^T \\phi _{s,t}\\).",
              "Parameter l and basis function \\(\\phi\\) for policy is derived from the motor primitive formulation.",
              "A stochastic policy is obtained by adding exploration \\(\\epsilon (s,t)\\) to deterministic policy.",
              "Thus, the obtained policy \\(\\pi (a_t|s_t,t)\\) is transformed as (32), Here, gaussian exploration is used, i.",
              "e., \\(\\epsilon (\\phi (s,t))\\) \\(\\approx\\) \\(N(\\epsilon |0, \\sum )\\).",
              "Without structure exploration, actions become random.",
              "Thus, it can create a strain or pressure on the joints of a robot, which can be dangerous to the robot.",
              "Thus, in article (Kober and Peters 2011), authors used structured form state-dependent exploration as (33), Thus, the resulted policy is defined by (34), Hence, update rule for a parameter is derived using resulted policy and it is given by (35), where \\(Z(s,t) = \\phi {(s,t)} \\phi {(s,t)}^T (\\phi {(s,t)}^T {\\hat{\\sum }} \\phi {(s,t)})^{-1}\\).",
              "Here, importance sampling is used to reduce the overall-number of roll-outs.",
              "Covariance Matrix Adaptation Evolution Strategy (CMA-ES) Algorithm In article (Hansen and Ostermeier 2001), the authors presented a self-adaption of mutation distribution based on cumulation and de-randomization.",
              "Here, the mutation strategy is adopted such that it favors the previous mutation in future selections.",
              "If this approach performed more rigorously, resulted in a de-randomized self-adaption scheme.",
              "This scheme is known as covariance matrix adaption (CMA).",
              "Its performance is improved by using cumulation.",
              "Complete framework results in the CMA-ES algorithm.",
              "It is applied for solving problems which are described as MDPs (Heidrich-Meisner and Igel 2008).",
              "It is showing its applicability on balancing tasks such as double cart-pole and it outperforms the policy gradient and stochastic search methods.",
              "Quantum Inspired RL (QiRL) Algorithm Forming a policy for the selection of action is a complex task in robotic systems. In literature (Dong et al.",
              "2010), \\(\\epsilon\\)-greedy, Boltzmann exploration, etc.",
              ", is presented for action selection, but these methods have inherent exploration and exploitation dilemma.",
              "In article (Dong et al.",
              "2010), quantum-inspired RL is proposed to address this issue.",
              "For a selection of probabilistic action and probability of \u201cgood\u201d and \u201cbad\u201d action based on reward are adopted by quantum measurement and amplitude amplification (a phenomenon in quantum computing) respectively.",
              "Here, policy is defined as a mapping of states to actions as, \\(f(s) = \\pi : S \\rightarrowtail A\\).",
              "The corresponding action is probabilistic in nature (based on the quantum phenomenon) and it is given by (36), Equation (38) means, state s have the action set as \\(\\{\\ |a_1>, \\ldots |a_n> \\}\\), the agent will select the eigen-action \\(|a_n>\\) with probability \\(|\\alpha _n|^2\\).",
              "Energy-Efficiency and Continuous-Movement Control (\\(E^2CMC\\) ) Algorithm In article Zeng et al.",
              "(2016), the authors proposed an \\(E^2CMC\\) algorithm for continuous movement control of drones with energy efficiency.",
              "Here, information like drone-cell location, energy consumption, and coverage is transmitted to the cloud for central computing.",
              "The problem is set up as MDP.",
              "Thus, the observations by the agent are set of coverage fairness and energy consumption.",
              "Actions are set off moving distance, yaw angle, and a pitch angle of drone-cells.",
              "Likewise, the reward is designed based on the consumption of energy.",
              "The penalty for boundary limitation is also included.",
              "If the connection of the drone is lost, then the corresponding movement is canceled.",
              "Procedure for \\(E^2CMC\\) algorithm is: Initialize Parameters of critic evaluation network \\(Q(s,a|l^Q)\\) and actor evaluation network \\(\\mu (s,a|l^{\\mu })\\), Parameters of critic target networks \\(Q(s,a|l^{Q'})\\) and actor target network \\(\\mu (s,a|l^{\\mu '})\\), buffer replay F and drone-cell graph R.",
              "Perform roll-outs select probabilistic action as \\(a_t = \\mu (s_t|l^{\\mu }) + N_t\\) and get next state and reward.",
              "Store the transition of states (\\(s_t,a_t,r_t,s_{t+1}\\)) in replay buffer F.",
              "Update the parameters \\(l^Q\\) by minimizing the loss function and parameters \\(l^{\\mu }\\) using a gradient.",
              "Fuzzy Controller Design A Control architecture is proposed by Hasegawa et al.",
              "(1999), mechanism maps a table that interrelates robot state variable to control inputs.",
              "This helps in the transfer of knowledge to form fuzzy rules.",
              "Block diagram of fuzzy-based RL is shown in Fig.",
              "8.",
              "Salient Features of given topology are: A RL algorithm generates a wide range of continuous real-value actions.",
              "Reinforcement signal is self-scaled so it prevents parameters from overshooting when the system receives a large reinforcement value.",
              "Fuzzy controller (Hasegawa et al.",
              "1999) As per literature, some authors have proposed different topologies for tuning of fuzzy controller parameters (Dai et al.",
              "2005).",
              "Given architecture has comprised of a Q estimator network (QEN) and Takagi\u2013Sugeno-type fuzzy inference system (TSK-FIS).",
              "TD methods and gradient-descent algorithm are used for tuning of controller parameters.",
              "Coordination Mechanism between Multi-agents In article (Abul et al.",
              "2000), independent coordination-mechanism based on RL is proposed for coordinating between multiple agents.",
              "Two coordinate mechanism is presented: Perceptual Co-ordinate Mechanism Co-ordination information learned from environment.",
              "Observing Co-ordinate Mechanism Rewards obtained by nearby agents are noted.",
              "Thus, noted reward from the environment and its own reward are used for restructuring of optimal policy.",
              "The salient feature of the mechanism is that the other agents present in the environment are also included in the state description.",
              "It helps in the increment of joint rewards in a multiagent system.",
              "An adversarial food-collecting world (AFCW) environment is used for showing the effectiveness of the coordination mechanism between agents for survival in hostile environments.",
              "AFCW environment is shown in Fig.",
              "9, where, agents, enemy, food and obstacles are represented by letter A, E, F and black blocks respectively.",
              "Legal movement of agents and enemies are pre-defined in (Abul et al.",
              "2000).",
              "Agents are said to be learned coordination if every agent tried to maximize total accumulated reward.",
              "Multi-agent coordination Designing of Reward Function The interaction of the agent with the environment generates a trajectory and data.",
              "A subset of data (\\(I^C\\)) is chosen and applied to the input of the controller, it generates the next action which is applied to the actuators.",
              "Likewise, another subset of data (\\(I^R\\)) is taken (this can be overlap with previous input \\(I^C\\)), and that is used for evaluation of the performance of the learning agent.",
              "RL algorithm is used for the updating of controller parameters.",
              "It leads to an overall improvement in the effectiveness of agent performance, herein RL is used to compute a reinforcement function.",
              "The primary target of function is to provide correct knowledge of learning tasks and behavior of agent to the learning algorithm.",
              "The basic aim of the learning system is to improve the performance of an overall system by maximizing the reward function.",
              "As per literature, the function is designed through a trial and error approach.",
              "However, some authors (Bonarini et al.",
              "2001) provides a complete engineering perspective for designing the reward function.",
              "Which is used to generate the control input for complex tasks, such as robotic, autonomous systems, etc.",
              "A complete framework of learning with reward function is shown in Fig.",
              "10.",
              "Learning from reward function Integration of Meta-heuristic with RL Integration of genetic programming with RL is proposed for learning of effective actions for adaption of a robot to real environment (Kamio and Iba 2005).",
              "The complete frame-chart is shown in Fig.",
              "11.",
              "The frame-chart shows that RL and genetic programming are feedback from outside and inner loop respectively.",
              "It speedup the convergence speed and adaption of a real robot to a stochastic environment simultaneously.",
              "In literature, some authors also proposed an ant optimizer based fuzzy controller, and rules are learned from RL.",
              "Framechart of integration of GP with RL (Kamio and Iba 2005) Gait Synthesis of walking patterns & Sensory ControlStair-climbing gait and sensor control strategy are considered for feed-forward control and feedback control (parameter of the controller is adjusted by RL) respectively for control of humanoid robots (Fu and Chen 2008).",
              "Impedance Learning by Actor-Critic Algorithm Modified learning strategy based on control theory and reinforcement learning for skill the motor is presented in (Kim et al.",
              "2009).",
              "In proposing an impedance controller, parameters are modified using actor-critic based RL.",
              "Basically, in a proposed mechanism, two structures are developed, first one is the actor structure that determines the policy for the selection of action and the second one is the critic structure that evaluates whether the selected action is good or bad.",
              "A framework of the proposed mechanism is presented in Fig.",
              "12.",
              "Framework of Impedance Learning (Kim et al.",
              "2009) Deep neural-network trained using RL Zero-bias and zero-variance in samples can lead to learning high-performance policy.",
              "In (Hwangbo et al.",
              "2017), a framework is proposed for control of quad-rotor based on a deep neural network which is trained using RL.",
              "The Deep neural network has two hidden layers.",
              "Each layer has 64 nodes with \\(\\tanh\\) function.",
              "Parameters of the neural network are tuned using the natural gradient descent algorithm.",
              "Monte-Carlo samples are used for the estimation of the value function.",
              "Shematic View of DeepRL in multi-aerial Robot (Viseras and Garcia 2019) Information-gain mechanism based on DeepRL DeepRL is used to coordinate between aerial robots to either mapping or gathering information about unknown terrain.",
              "The key challenge is that robots need to perceive their current states through sensors that are imperfect in nature.",
              "In order to address this issue, the authors have proposed a framework as shown in Fig.",
              "13 (Viseras and Garcia 2019).",
              "In this paper, a lot of different mechanisms proposed by different authors and their application in robotic applications are surveyed.",
              "Sometimes, it is very difficult to find the appropriate method that results in a better control policy for problem-solving.",
              "However, we can use intuition for the selection of methods in advance from an actor, critic, and actor-critic techniques.",
              "If a type of control policy is learned for continuous space, then the critic method is not appropriate.",
              "Whereas, if policy learned for finite and countable space, choose the critic method.",
              "Although the choice between actor-critic and actor methods is simple.",
              "If the problem is presented as stationary MDPs then actor-critic methods should be used.",
              "Because it provides a lower-variance.",
              "However, actor methods are more robust in a non-stationary environment.",
              "In these techniques, the choice of better parameterization for a policy is an important question because it highly influences the performance of learning.",
              "Dimensionality is also a significant concern.",
              "As the number of the state increases, learning of the agent becomes computationally difficult.",
              "Thus, in literature, many authors have tried to reduce the complexity of dimension (O\u2019Flaherty and Egerstedt 2014;",
              "Polat et al.",
              "2002;",
              "Colome\u0301 and Torras 2018;",
              "Lasheng et al.",
              "2012).",
              "In some cases, the authors have presented an algorithm that uses a hybridization of a continuous and discrete form of the complex physical robotic system.",
              "These are based on an abstraction of learning boundary-action pairs that mitigate the curse of dimensionality.",
              "In traditional RL, the estimate of the Q-value function is used for designing policy and action taken in a particular state by the agent.",
              "Due to the uncertainty present in the estimated Q-value, the agent can trap inside a local optimum.",
              "It may occur due to insufficient exploration.",
              "Hence, the dilemma between exploration and exploitation is present.",
              "Therefore, in article (Iwata et al.",
              "2004), authors have proposed a new criterion based on a ratio of return loss to information gain.",
              "This forms a strategy of action taken in a particular state.",
              "Purely exploitation and exploration leads to an optimal local solution quickly and degrades the overall performance of learning respectively.",
              "Therefore, the goal of the algorithm is to find an optimal policy without trapping in local optima.",
              "It can be achieved by transforming the goal into a search problem.",
              "In article (Guo et al.",
              "2004), metropolis criterion is used in simulated annealing (SA) algorithm.",
              "It is applied to a search procedure in order to find a balance between exploration and exploitation.",
              "Hence, integration of SA with Q-learning resulted in a balance between exploration and exploitation.",
              "Exploration will decay gradually when the solution is approaching optimum value.",
              "It can be applied in robotics for balancing exploration and exploitation as a future scope.",
              "Automatic learning for robots is done by the data-driven controller using RL, but the significant drawback is that agent requires many interactions with the environment for learning of the controller parameters.",
              "In order to reduce the required number of interactions before reaching an optimal solution, a domain expert is needed to reshape the policies, it may yield a reduction in the computational cost requirement.",
              "However, it may be difficult to find the appropriate domain expert.",
              "And it may also be possible that the dynamics of the model are not known completely.",
              "Therefore, the control of the robot becomes very difficult.",
              "So, it is advisable to learn the model through probabilistic modeling, non-parametric Gaussian process transition method and go for multi-fidelity simulators (Deisenroth et al.",
              "2013a;",
              "Cutler et al.",
              "2015).",
              "In most cases, the robot uses a visual feedback signal but the presence of disturbances (like signal interference or dust) makes it difficult for controlling the robot.",
              "Thus, in literature authors have proposed a mechanism for effective control of the robot (Li et al.",
              "2017b;",
              "Sharma et al.",
              "2018;",
              "Zhang et al.",
              "2019).",
              "Another interesting area is to develop new approaches based on DeepRL for unstructured data.",
              "It can help in the control of humanoid robots.",
              "DeepRL for feedback control requires new approaches such that the stability can be assured in the sense of Lyapunov.",
              "As Bayesian optimization is a global search method, though till now it does not well scale up to large parameter policy space and applicable only to low dimensional.",
              "Thus, there is further need for an investigation that how to use Bayesian optimization to apply for high dimensional parameter space like deep neural networks.",
              "The robot can autonomously learn from demonstrations, instruction, and advice.",
              "Here, human feedback can reduce the number of trials because it can help in the reduction of total incorrect actions.",
              "However, as a future scope, a methodology that includes the demonstrations and human feedback, or an integrated approach of advice and feedbacks needs to investigate.",
              "And also it is needed for further investigation of agent learning from facial expression as well.",
              "The agent can learn either implicitly or explicitly from human feedback.",
              "In the future, humans and robots will interact with each other frequently.",
              "However, learning from human feedback is a very complex task as compared to traditional RL because it is based on environmental feedback.",
              "Therefore, there is a need of understanding human behavior before developing a new topology so that agents can effectively learn from feedback.",
              "Thus, a proper multi-coordination and human\u2013robot ecosystem need to develop.",
              "RL could be effective in real-robot like human-level abilities.",
              "If the robot\u2019s cognitive structure is suitably pre-programmed with a decomposition of a task into easy learned behaviors or skills.",
              "There can be a possibility of a new learning policy.",
              "Further, the learning process can be speedup by the reuse of data and experience replay.",
              "Mostly, RL is applicable to sequential decision-making problems. Likewise for multi-task problems integrated Q-learning and knowledge transfer yields a better control policy.",
              "But, it has significant drawbacks of long-time exploration.",
              "Therefore, integration of Deep learning with RL for the multi-task problem can provide better control policy in less time.",
              "And also there is a need for a new policy framework to develop more advanced autonomous robots.",
              "Like in recent times, Neuro-evolution is emerging as a powerful tool since computation power increased.",
              "It improves the capabilities of a neural network that includes learning of hyper-parameters, architecture, rules of learning and activation functions, etc.",
              "Therefore, researchers found that neuro-evolution is more competitive than gradient-based methods to train a neural network for RL problems. When the neuro-evolution technique combined with DeepRL could help in progress towards the development of artificial general intelligence (AGI) framework.",
              "This framework when applied to the robotic application, it leads to more advanced intelligence and that can be the future research direction.",
              "Biological and artificial systems need to achieve goals for their survival.",
              "Neuromorphic is an engineering field that makes a bridge between device physics and behavior inspired by the brain\u2019s building blocks, such as spiking neural networks.",
              "A recent development in neuromorphic hardware yields a platform for brain-inspired learning algorithms. Likewise, biological retinas-based neuromorphic vision sensors already changing the landscape of the computer vision field.",
              "It has a greater impact on robotics as well.",
              "Thus, the focus should be more on the deeper insights of the brain.",
              "In the near future, it can lead to the development of RL based artificial agents that can solve complex real-world problems. We have discussed the motivation of reinforcement learning, where most of the learning problems are complex due to the stochastic environment.",
              "In this paper, we have provided a comprehensive survey on the application of RL algorithms in robotics, which includes land, water, and air-based applications.",
              "Firstly, we have introduced a detailed explanation of various RL mechanisms such as Actor-critic, Human-centered, DeepRL, multi-agent, etc.",
              "Then briefly explain the various application of RL.",
              "Then, discussed various methodology/algorithms developed by authors in literature.",
              "In the latter part, we have expressed our view on the challenges faced by RL algorithms with different applications and also discuss future scope.",
              "Differential topology like neuro-evolution, spiking neural networks, modification in cognitive architecture, etc.",
              ", can be used to improve the learning of robots.",
              "Neuro-evolution is a methodology in which the architecture of the artificial neural networks has evolved with time.",
              "Thus, as future scope, integration of neuro-evolution with RL algorithm can provide a better optimal policy for robots.",
              "Moving forward from robotic application based on RL, surveyed learning mechanisms in this paper is also well suited for application in larger prospective fields such as power system, communication, aerospace, etc.",
              ", where RL can make system autonomous.",
              "Abul O, Polat F, Alhajj R (2000) Multiagent reinforcement learning using function approximation.",
              "IEEE Trans Syst Man Cybern Part C (Appl Rev) 30(4):485\u2013497 Google Scholar Adam S, Busoniu L, Babuska R (2011) Experience replay for real-time reinforcement learning control.",
              "IEEE Trans Syst Man Cybern Part C (Appl Rev) 42(2):201\u2013212 Google Scholar Ansari Y, Manti M, Falotico E, Cianchetti M, Laschi C (2017) Multiobjective optimization for stiffness and position control in a soft robot arm module.",
              "IEEE Robot Autom Lett 3(1):108\u2013115 Google Scholar Antonelo EA, Schrauwen B (2014) On learning navigation behaviors for small mobile robots with reservoir computing architectures.",
              "IEEE Trans Neural Netw Learn Syst 26(4):763\u2013780 MathSciNet Google Scholar Arulkumaran K, Deisenroth MP, Brundage M, Bharath AA (2017) Deep reinforcement learning: a brief survey.",
              "IEEE Signal Process Mag 34(6):26\u201338 Google Scholar Averbeck BB, Costa VD (2017) Motivational neural circuits underlying reinforcement learning.",
              "Nat Neurosci 20(4):505\u2013512 Google Scholar Baird L (1995) Residual algorithms: reinforcement learning with function approximation.",
              "In: Machine learning proceedings 1995, Elsevier, pp 30\u201337 Baird III LC, Moore AW (1999) Gradient descent for general reinforcement learning.",
              "In: Advances in neural information processing systems, pp 968\u2013974 Barto AG, Sutton RS, Anderson CW (1983) Neuron like adaptive elements that can solve difficult learning control problems. IEEE Trans Syst Man Cybern 5:834\u2013846 Google Scholar Bejar E, Moran A (2019) A preview neuro-fuzzy controller based on deep reinforcement learning for backing up a truck-trailer vehicle.",
              "In: 2019 IEEE canadian conference of electrical and computer engineering (CCECE), IEEE, pp 1\u20134 Beom HR, Cho HS (1995) A sensor-based navigation for a mobile robot using fuzzy logic and reinforcement learning.",
              "IEEE Trans Syst Man Cybern 25(3):464\u2013477 Google Scholar Bertsekas DP (1995) Dynamic programming and optimal control.",
              "Athena scientific, Belmont MATH Google Scholar Bertsekas DP (2018) Feature-based aggregation and deep reinforcement learning: a survey and some new implementations.",
              "IEEE/CAA J Autom Sin 6(1):1\u201331 MathSciNet Google Scholar Bo\u0308hmer W, Springenberg JT, Boedecker J, Riedmiller M, Obermayer K (2015) Autonomous learning of state representations for control: an emerging field aims to autonomously learn state representations for reinforcement learning agents from their real-world sensor observations.",
              "KI-Ku\u0308nstliche Intelligenz 29(4):353\u2013362 Google Scholar Bonarini A, Bonacina C, Matteucci M (2001) An approach to the design of reinforcement functions in real world, agent-based applications.",
              "IEEE Trans Syst Man Cybern Part B (Cybern) 31(3):288\u2013301 Google Scholar Bowling M, Veloso M (2001) Rational and convergent learning in stochastic games.",
              "Int Joint Conf Artif Intell 17:1021\u20131026 Google Scholar Bowling M, Veloso M (2002) Multiagent learning using a variable learning rate.",
              "Artif Intell 136(2):215\u2013250 MathSciNet MATH Google Scholar Boyan JA (2002) Technical update: least-squares temporal difference learning.",
              "Mach Learn 49(2\u20133):233\u2013246 MATH Google Scholar Bradtke SJ, Ydstie BE, Barto AG (1994) Adaptive linear quadratic control using policy iteration.",
              "In: Proceedings of 1994 American control conference-ACC\u201994, IEEE, vol 3, pp 3475\u20133479 Breyer M, Furrer F, Novkovic T, Siegwart R, Nieto J (2019) Comparing task simplifications to learn closed-loop object picking using deep reinforcement learning.",
              "IEEE Robot Autom Lett 4(2):1549\u20131556 Google Scholar Bu L, Babu R, De Schutter B et al (2008) A comprehensive survey of multiagent reinforcement learning.",
              "IEEE Trans Syst Man Cybern Part C (Appl Rev) 38(2):156\u2013172 Google Scholar Caarls W, Schuitema E (2015) Parallel online temporal difference learning for motor control.",
              "IEEE Trans Neural Netw Learn Syst 27(7):1457\u20131468 MathSciNet Google Scholar Cao X, Sun C, Yan M (2019) Target search control of auv in underwater environment with deep reinforcement learning.",
              "IEEE Access 7:96549\u201396559 Google Scholar Carlucho I, De Paula M, Villar SA, Acosta GG (2017) Incremental q-learning strategy for adaptive pid control of mobile robots.",
              "Expert Syst Appl 80:183\u2013199 Google Scholar Carlucho I, De Paula M, Wang S, Petillot Y, Acosta GG (2018) Adaptive low-level control of autonomous underwater vehicles using deep reinforcement learning.",
              "Robot Auton Syst 107:71\u201386 Google Scholar Chalvatzaki G, Papageorgiou XS, Maragos P, Tzafestas CS (2019) Learn to adapt to human walking: a model-based reinforcement learning approach for a robotic assistant rollator.",
              "IEEE Robot Autom Lett 4(4):3774\u20133781 Google Scholar Cheng Y, Zhang W (2018) Concise deep reinforcement learning obstacle avoidance for underactuated unmanned marine vessels.",
              "Neurocomputing 272:63\u201373 Google Scholar Colome\u0301 A, Torras C (2018) Dimensionality reduction for dynamic movement primitives and application to bimanual manipulation of clothes.",
              "IEEE Trans Robot 34(3):602\u2013615 Google Scholar Cruz F, Magg S, Weber C, Wermter S (2016) Training agents with interactive reinforcement learning and contextual affordances.",
              "IEEE Trans Cogn Dev Syst 8(4):271\u2013284 Google Scholar Cutler M, Walsh TJ, How JP (2015) Real-world reinforcement learning via multifidelity simulators.",
              "IEEE Trans Robot 31(3):655\u2013671 Google Scholar Da Silva B, Konidaris G, Barto A (2012) Learning parameterized skills.",
              "Preprint arXiv:12066398 Dai X, Li CK, Rad AB (2005) An approach to tune fuzzy controllers based on reinforcement learning for autonomous vehicle control.",
              "IEEE Trans Intell Transp Syst 6(3):285\u2013293 Google Scholar Dayan P, Niv Y (2008) Reinforcement learning: the good, the bad and the ugly.",
              "Curr Opin Neurobiol 18(2):185\u2013196 Google Scholar de Bruin T, Kober J, Tuyls K, Babus\u030cka R (2018) Integrating state representation learning into deep reinforcement learning.",
              "IEEE Robot Autom Lett 3(3):1394\u20131401 MATH Google Scholar Deisenroth M, Rasmussen CE (2011) Pilco: a model-based and data-efficient approach to policy search.",
              "In: Proceedings of the 28th international conference on machine learning (ICML-11), pp 465\u2013472 Deisenroth MP, Fox D, Rasmussen CE (2013a) Gaussian processes for data-efficient learning in robotics and control.",
              "IEEE Trans Pattern Anal Mach Intell 37(2):408\u2013423 Google Scholar Deisenroth MP, Neumann G, Peters J et al (2013b) A survey on policy search for robotics.",
              "Found Trends Robot 2(1\u20132):1\u2013142 Google Scholar Deng Z, Guan H, Huang R, Liang H, Zhang L, Zhang J (2017) Combining model-based \\(q\\)-learning with structural knowledge transfer for robot skill learning.",
              "IEEE Trans Cogn Dev Syst 11(1):26\u201335 Google Scholar Dong D, Chen C, Chu J, Tarn TJ (2010) Robust quantum-inspired reinforcement learning for robot navigation.",
              "IEEE/ASME Trans Mech 17(1):86\u201397 Google Scholar Doroodgar B, Liu Y, Nejat G (2014) A learning-based semi-autonomous controller for robotic exploration of unknown disaster scenes while searching for victims. IEEE Trans Cybern 44(12):2719\u20132732 Google Scholar Doshi-Velez F, Pfau D, Wood F, Roy N (2013) Bayesian nonparametric methods for partially-observable reinforcement learning.",
              "IEEE Trans Pattern Anal Mach Intell 37(2):394\u2013407 Google Scholar Duan Y, Cui BX, Xu XH (2012) A multi-agent reinforcement learning approach to robot soccer.",
              "Artif Intell Rev 38(3):193\u2013211 Google Scholar El-Fakdi A, Carreras M (2013) Two-step gradient-based reinforcement learning for underwater robotics behavior learning.",
              "Robot Auton Syst 61(3):271\u2013282 Google Scholar Er MJ, Deng C (2005) Obstacle avoidance of a mobile robot using hybrid learning approach.",
              "IEEE Trans Ind Electron 52(3):898\u2013905 Google Scholar Falco P, Attawia A, Saveriano M, Lee D (2018) On policy learning robust to irreversible events: an application to robotic in-hand manipulation.",
              "IEEE Robot Autom Lett 3(3):1482\u20131489 Google Scholar Farahmand AM, Ahmadabadi MN, Lucas C, Araabi BN (2009) Interaction of culture-based learning and cooperative co-evolution and its application to automatic behavior-based system design.",
              "IEEE Trans Evol Comput 14(1):23\u201357 Google Scholar Faust A, Ruymgaart P, Salman M, Fierro R, Tapia L (2014) Continuous action reinforcement learning for control-affine systems with unknown dynamics.",
              "IEEE/CAA J Autom Sin 1(3):323\u2013336 Google Scholar Foglino F, Christakou CC, Leonetti M (2019) An optimization framework for task sequencing in curriculum learning.",
              "In: 2019 Joint IEEE 9th international conference on development and learning and epigenetic robotics (ICDL-EpiRob), IEEE, pp 207\u2013214 Frost G, Maurelli F, Lane DM (2015) Reinforcement learning in a behaviour-based control architecture for marine archaeology.",
              "In: OCEANS 2015-Genova, IEEE, pp 1\u20135 Fu C, Chen K (2008) Gait synthesis and sensory control of stair climbing for a humanoid robot.",
              "IEEE Trans Ind Electron 55(5):2111\u20132120 Google Scholar Gordon GJ (1995) Stable function approximation in dynamic programming.",
              "In: Machine learning proceedings 1995, Elsevier, pp 261\u2013268 Gosavi A (2009) Reinforcement learning: a tutorial survey and recent advances.",
              "INFORMS J Comput 21(2):178\u2013192 MathSciNet MATH Google Scholar Gottipati SK, Seo K, Bhatt D, Mai V, Murthy K, Paull L (2019) Deep active localization.",
              "IEEE Robot Autom Lett 4(4):4394\u20134401 Google Scholar Greenwald A, Hall K, Serrano R (2003) Correlated q-learning.",
              "ICML 3:242\u2013249 Google Scholar Grigorescu S, Trasnea B, Marina L, Vasilcoi A, Cocias T (2019) Neurotrajectory: a neuroevolutionary approach to local state trajectory learning for autonomous vehicles.",
              "Preprint arXiv:190610971 Grondman I, Busoniu L, Lopes GA, Babuska R (2012) A survey of actor-critic reinforcement learning: standard and natural policy gradients.",
              "IEEE Trans Syst Man Cybern Part C (Appl Rev) 42(6):1291\u20131307 Google Scholar Gu D, Hu H (2007) Integration of coordination architecture and behavior fuzzy learning in quadruped walking robots.",
              "IEEE Trans Syst Man Cybern Part C (Appl Rev) 37(4):670\u2013681 Google Scholar Gullapalli V (1990) A stochastic reinforcement learning algorithm for learning real-valued functions.",
              "Neural Netw 3(6):671\u2013692 Google Scholar Guo M, Liu Y, Malec J (2004) A new q-learning algorithm based on the metropolis criterion.",
              "IEEE Trans Syst Man Cybern Part B (Cybern) 34(5):2140\u20132143 Google Scholar Hansen N, Ostermeier A (2001) Completely derandomized self-adaptation in evolution strategies.",
              "Evol Comput 9(2):159\u2013195 Google Scholar Hasegawa Y, Fukuda T, Shimojima K (1999) Self-scaling reinforcement learning for fuzzy logic controller-applications to motion control of two-link brachiation robot.",
              "IEEE Trans Ind Electron 46(6):1123\u20131131 Google Scholar Hazara M, Kyrki V (2019) Transferring generalizable motor primitives from simulation to real world.",
              "IEEE Robot Autom Lett 4(2):2172\u20132179 Google Scholar He W, Li Z, Chen CP (2017) A survey of human-centered intelligent robots: issues and challenges.",
              "IEEE/CAA J Autom Sin 4(4):602\u2013609 Google Scholar Heidrich-Meisner V, Igel C (2008) Evolution strategies for direct policy search.",
              "In: International conference on parallel problem solving from nature, Springer, pp 428\u2013437 Ho MK, Littman ML, Cushman F, Austerweil JL (2015) Teaching with rewards and punishments: Reinforcement or communication?",
              "In: CogSci Hu H, Song S, Chen CP (2019) Plume tracing via model-free reinforcement learning method.",
              "IEEE Trans Neural Netw Learn Syst Hu J, Wellman MP (2003) Nash q-learning for general-sum stochastic games.",
              "J Mach Learn Res 4:1039\u20131069 MathSciNet MATH Google Scholar Hu J, Zhang H, Song L (2018) Reinforcement learning for decentralized trajectory design in cellular uav networks with sense-and-send protocol.",
              "IEEE Internet of Things Journal Huang R, Cheng H, Qiu J, Zhang J (2019) Learning physical human\u2013robot interaction with coupled cooperative primitives for a lower exoskeleton.",
              "IEEE Trans Autom Scie Eng Huang Z, Xu X, He H, Tan J, Sun Z (2017) Parameterized batch reinforcement learning for longitudinal control of autonomous land vehicles.",
              "IEEE Trans Syst Man Cybern Syst 49(4):730\u2013741 Google Scholar Hung SM, Givigi SN (2016) A q-learning approach to flocking with uavs in a stochastic environment.",
              "IEEE Trans Cybern 47(1):186\u2013197 Google Scholar Hwang KS, Lo CY, Liu WL (2009) A modular agent architecture for an autonomous robot.",
              "IEEE Trans Instrum Meas 58(8):2797\u20132806 Google Scholar Hwang KS, Lin JL, Yeh KH (2015) Learning to adjust and refine gait patterns for a biped robot.",
              "IEEE Trans Syst Man Cybern Syst 45(12):1481\u20131490 Google Scholar Hwangbo J, Sa I, Siegwart R, Hutter M (2017) Control of a quadrotor with reinforcement learning.",
              "IEEE Robot Autom Lett 2(4):2096\u20132103 Google Scholar Iwata K, Ikeda K, Sakai H (2004) A new criterion using information gain for action selection strategy in reinforcement learning.",
              "IEEE Trans Neural Netw 15(4):792\u2013799 Google Scholar Juang CF, Hsu CH (2009) Reinforcement ant optimized fuzzy controller for mobile-robot wall-following control.",
              "IEEE Trans Ind Electron 56(10):3931\u20133940 Google Scholar Kaelbling LP, Littman ML, Moore AW (1996) Reinforcement learning: a survey.",
              "J Artif Intell Res 4:237\u2013285 Google Scholar Kamio S, Iba H (2005) Adaptation technique for integrating genetic programming and reinforcement learning for real robots.",
              "IEEE Trans Evol Comput 9(3):318\u2013333 Google Scholar Khamassi M, Velentzas G, Tsitsimis T, Tzafestas C (2018) Robot fast adaptation to changes in human engagement during simulated dynamic social interaction with active exploration in parameterized reinforcement learning.",
              "IEEE Trans Cogn Dev Syst 10(4):881\u2013893 Google Scholar Kim B, Park J, Park S, Kang S (2009) Impedance learning for robotic contact tasks using natural actor-critic algorithm.",
              "IEEE Trans Syst Man Cybern Part B (Cybern) 40(2):433\u2013443 Google Scholar Kiumarsi B, Vamvoudakis KG, Modares H, Lewis FL (2017) Optimal and autonomous control using reinforcement learning: a survey.",
              "IEEE Trans Neural Netw Learn Syst 29(6):2042\u20132062 MathSciNet Google Scholar Kober J, Peters J (2011) Policy search for motor primitives in robotics.",
              "Mach Learn 84:171\u2013203 MathSciNet MATH Google Scholar Kober J, Bagnell JA, Peters J (2013) Reinforcement learning in robotics: a survey.",
              "Int J Robot Res 32(11):1238\u20131274 Google Scholar Koc\u0327 O, Peters J (2019) Learning to serve: an experimental study for a new learning from demonstrations framework.",
              "IEEE Robot Autom Lett 4(2):1784\u20131791 Google Scholar Konda VR, Tsitsiklis JN (2000) Actor-critic algorithms. In: Advances in neural information processing systems, pp 1008\u20131014 Koryakovskiy I, Kudruss M, Vallery H, Babus\u030cka R, Caarls W (2018) Model-plant mismatch compensation using reinforcement learning.",
              "IEEE Robot Autom Lett 3(3):2471\u20132477 Google Scholar La HM, Lim R, Sheng W (2014) Multirobot cooperative learning for predator avoidance.",
              "IEEE Trans Control Syst Technol 23(1):52\u201363 Google Scholar Lambert NO, Drew DS, Yaconelli J, Levine S, Calandra R, Pister KS (2019) Low-level control of a quadrotor with deep model-based reinforcement learning.",
              "IEEE Robot Autom Lett 4(4):4224\u20134230 Google Scholar Lasheng Y, Zhongbin J, Kang L (2012) Research on task decomposition and state abstraction in reinforcement learning.",
              "Artif Intell Rev 38(2):119\u2013127 Google Scholar Le TP, Ngo VA, Jaramillo PM, Chung T (2019) Importance sampling policy gradient algorithms in reproducing kernel hilbert space.",
              "Artif Intell Rev 52(3):2039\u20132059 Google Scholar Li G, Gomez R, Nakamura K, He B (2019) Human-centered reinforcement learning: a survey.",
              "IEEE Trans Hum Mach Syst Li THS, Su YT, Lai SW, Hu JJ (2010) Walking motion generation, synthesis, and control for biped robot by using pgrl, lpi, and fuzzy logic.",
              "IEEE Trans Syst Man Cybern Part B (Cybern) 41(3):736\u2013748 Google Scholar Li Z, Liu J, Huang Z, Peng Y, Pu H, Ding L (2017a) Adaptive impedance control of human-robot cooperation using reinforcement learning.",
              "IEEE Trans Ind Electron 64(10):8013\u20138022 Google Scholar Li Z, Zhao T, Chen F, Hu Y, Su CY, Fukuda T (2017b) Reinforcement learning of manipulation and grasping using dynamical movement primitives for a humanoidlike mobile manipulator.",
              "IEEE/ASME Trans Mech 23(1):121\u2013131 Google Scholar Lin JL, Hwang KS, Wang YL (2013) A simple scheme for formation control based on weighted behavior learning.",
              "IEEE Trans Neural Netw Learn Syst 25(6):1033\u20131044 Google Scholar Lin Y, Makedon F, Xu Y (2011) Episodic task learning in markov decision processes.",
              "Artif Intell Rev 36(2):87\u201398 Google Scholar Littman ML (2015) Reinforcement learning improves behaviour from evaluative feedback.",
              "Nature 521(7553):445\u2013451 Google Scholar Liu S, Ngiam KY, Feng M (2019) Deep reinforcement learning for clinical decision support: a brief survey.",
              "Preprint arXiv:190709475 Luo B, Liu D, Huang T, Liu J (2017) Output tracking control based on adaptive dynamic programming with multistep policy evaluation.",
              "IEEE Trans Syst Man Cybern Syst Luo B, Yang Y, Liu D (2018) Adaptive q-learning for data-based optimal output regulation with experience replay.",
              "IEEE Trans Cybern 48(12):3337\u20133348 Google Scholar Luo B, Yang Y, Liu D, Wu HN (2019) Event-triggered optimal control with performance guarantees using adaptive dynamic programming.",
              "IEEE Trans Neural Netw Learn Syst 31(1):76\u201388 MathSciNet Google Scholar Lv L, Zhang S, Ding D, Wang Y (2019) Path planning via an improved dqn-based learning policy.",
              "IEEE Access Madden MG, Howley T (2004) Transfer of experience between reinforcement learning environments with progressive difficulty.",
              "Artif Intell Rev 21(3\u20134):375\u2013398 MATH Google Scholar Markova VD, Shopov VK (2019) Knowledge transfer in reinforcement learning agent.",
              "In: 2019 international conference on information technologies (InfoTech), IEEE, pp 1\u20134 McPartland M, Gallagher M (2010) Reinforcement learning in first person shooter games.",
              "IEEE Trans Comput Intell AI Games 3(1):43\u201356 Google Scholar Meeden LA (1996) An incremental approach to developing intelligent neural network controllers for robots.",
              "IEEE Trans Syst Man Cybern Part B (Cybern) 26(3):474\u2013485 Google Scholar Melo FS, Meyn SP, Ribeiro MI (2008) An analysis of reinforcement learning with function approximation.",
              "In: Proceedings of the 25th international conference on Machine learning, ACM, pp 664\u2013671 Mnih V, Kavukcuoglu K, Silver D, Rusu AA, Veness J, Bellemare MG, Graves A, Riedmiller M, Fidjeland AK, Ostrovski G et al (2015a) Human-level control through deep reinforcement learning.",
              "Nature 518(7540):529 Google Scholar Mnih V, Kavukcuoglu K, Silver D, Rusu AA, Veness J, Bellemare MG, Graves A, Riedmiller M, Fidjeland AK, Ostrovski G et al (2015b) Human-level control through deep reinforcement learning.",
              "Nature 518(7540):529\u2013533 Google Scholar Modares H, Ranatunga I, Lewis FL, Popa DO (2015) Optimized assistive human\u2013robot interaction using reinforcement learning.",
              "IEEE Trans Cybern 46(3):655\u2013667 Google Scholar Modares H, Lewis FL, Kang W, Davoudi A (2017) Optimal synchronization of heterogeneous nonlinear systems with unknown dynamics.",
              "IEEE Trans Autom Control 63(1):117\u2013131 MathSciNet MATH Google Scholar Muelling K, Kober J, Peters J (2010) Learning table tennis with a mixture of motor primitives.",
              "In: 2010 10th IEEE-RAS international conference on humanoid robots, IEEE, pp 411\u2013416 Neftci E, Averbeck B (2019) Reinforcement learning in artificial and biological systems. Nat Mach Intell.",
              "https://doi.",
              "org/10.",
              "1038/s42256-019-0025-4 Article Google Scholar Neftci EO, Averbeck BB (2002) Reinforcement learning in artificial and biological systems. Environment p 3 Ng AY, Harada D, Russell S (1999) Policy invariance under reward transformations: theory and application to reward shaping.",
              "ICML 99:278\u2013287 Google Scholar Nguyen ND, Nguyen T, Nahavandi S (2017) System design perspective for human-level agents using deep reinforcement le arning: a survey.",
              "IEEE Access 5:27091\u201327102 Google Scholar Nguyen TT, Nguyen ND, Nahavandi S (2018) Deep reinforcement learning for multi-agent systems: a review of challenges, solutions and applications.",
              "Preprint arXiv:181211794 O\u2019Flaherty R, Egerstedt M (2014) Low-dimensional learning for complex robots.",
              "IEEE Trans Autom Sci Eng 12(1):19\u201327 Google Scholar Ohnishi M, Wang L, Notomista G, Egerstedt M (2019) Barrier-certified adaptive reinforcement learning with applications to brushbot navigation.",
              "IEEE Trans Robot 35(5):1186\u20131205 Google Scholar Palomeras N, El-Fakdi A, Carreras M, Ridao P (2012) Cola2: a control architecture for auvs. IEEE J Ocean Eng 37(4):695\u2013716 Google Scholar Parunak HVD (1999) Industrial and practical applications of dai.",
              "Multiagent systems: a modern approach to distributed artificial intelligence pp 337\u2013421 Peters J, Schaal S (2008) Reinforcement learning of motor skills with policy gradients.",
              "Neural netw 21(4):682\u2013697 Google Scholar Peters J, Vijayakumar S, Schaal S (2005) Natural actor-critic.",
              "In: European conference on machine learning, Springer, pp 280\u2013291 Peters J, Mulling K, Altun Y (2010) Relative entropy policy search.",
              "In: Twenty-Fourth AAAI conference on artificial intelligence Plaza MG, Marti\u0301nez-Mari\u0301n T, Prieto SS, Luna DM (2009) Integration of cell-mapping and reinforcement-learning techniques for motion planning of car-like robots.",
              "IEEE Trans Instrum Meas 58(9):3094\u20133103 Google Scholar Polat F et al (2002) Learning intelligent behavior in a non-stationary and partially observable environment.",
              "Artif Intell Rev 18(2):97\u2013115 Google Scholar Puterman ML (2014) Markov decision processes: discrete stochastic dynamic programming.",
              "John Wiley & Sons Rescorla R, Wagner A, Black AH, Prokasy WF (1972) Classical conditioning ii: current research and theory pp 64\u201399 Ribeiro C (2002) Reinforcement learning agents.",
              "Artif Intell Rev 17(3):223\u2013250 MATH Google Scholar Riedmiller M, Peters J, Schaal S (2007) Evaluation of policy gradient methods and variants on the cart-pole benchmark.",
              "In: 2007 IEEE international symposium on approximate dynamic programming and reinforcement learning, IEEE, pp 254\u2013261 Rombokas E, Malhotra M, Theodorou EA, Todorov E, Matsuoka Y (2012) Reinforcement learning and synergistic control of the act hand.",
              "IEEE/ASME Trans Mech 18(2):569\u2013577 Google Scholar Roveda L, Pallucca G, Pedrocchi N, Braghin F, Tosatti LM (2017) Iterative learning procedure with reinforcement for high-accuracy force tracking in robotized tasks.",
              "IEEE Trans Ind Inform 14(4):1753\u20131763 Google Scholar Rummery GA, Niranjan M (1994) On-line Q-learning using connectionist systems, vol 37.",
              "University of Cambridge, Department of Engineering Cambridge, England Rylatt M, Czarnecki C, Routen T (1998) Connectionist learning in behaviour-based mobile robots: a survey.",
              "Artif Intell Rev 12(6):445\u2013468 Google Scholar Sallab AE, Abdou M, Perot E, Yogamani S (2017) Deep reinforcement learning framework for autonomous driving.",
              "Electron Imaging 19:70\u201376 Google Scholar dos Santos SRB, Givigi SN, Nascimento CL (2015) Autonomous construction of multiple structures using learning automata: description and experimental validation.",
              "IEEE Syst J 9(4):1376\u20131387 Google Scholar Santucci VG, Baldassarre G, Cartoni E (2019) Autonomous reinforcement learning of multiple interrelated tasks.",
              "Preprint arXiv:190601374 Schaul T, Horgan D, Gregor K, Silver D (2015) Universal value function approximators.",
              "In: International conference on machine learning, pp 1312\u20131320 Sharma R, Gopal M (2008) A markov game-adaptive fuzzy controller for robot manipulators.",
              "IEEE Trans Fuzzy Syst 16(1):171\u2013186 Google Scholar Sharma RS, Nair RR, Agrawal P, Behera L, Subramanian VK (2018) Robust hybrid visual servoing using reinforcement learning and finite-time adaptive fosmc.",
              "IEEE Syst J Shi H, Li X, Hwang KS, Pan W, Xu G (2016) Decoupled visual servoing with fuzzyq-learning.",
              "IEEE Trans Ind Inform 14(1):241\u2013252 Google Scholar Silver D, Lever G, Heess N, Degris T, Wierstra D, Riedmiller M (2014) Deterministic policy gradient algorithms Stanley KO, Clune J, Lehman J, Miikkulainen R (2019) Designing neural networks through neuroevolution.",
              "Nat Mach Intell 1(1):24\u201335 Google Scholar Stone P, Veloso M (2000) Multiagent systems: a survey from a machine learning perspective.",
              "Auton Robots 8(3):345\u2013383 Google Scholar Stulp F, Buchli J, Ellmer A, Mistry M, Theodorou EA, Schaal S (2012) Model-free reinforcement learning of impedance control in stochastic environments.",
              "IEEE Trans Auton Mental Dev 4(4):330\u2013341 Google Scholar Such FP, Madhavan V, Conti E, Lehman J, Stanley KO, Clune J (2017) Deep neuroevolution: genetic algorithms are a competitive alternative for training deep neural networks for reinforcement learning.",
              "Preprint arXiv:171206567 Sutton RS (1988) Learning to predict by the methods of temporal differences.",
              "Mach Learn 3(1):9\u201344 Google Scholar Sutton RS (1992) A special issue of machine learning on reinforcement learning.",
              "Mach Learn 8 Sutton RS, Barto AG (2018) Reinforcement learning: an introduction.",
              "MIT press Sutton RS, McAllester DA, Singh SP, Mansour Y (2000) Policy gradient methods for reinforcement learning with function approximation.",
              "In: Advances in neural information processing systems, pp 1057\u20131063 Tenorio-Gonzalez AC, Morales EF, Villasen\u0303or-Pineda L (2010) Dynamic reward shaping: training a robot by voice.",
              "In: Ibero-American conference on artificial intelligence, Springer, pp 483\u2013492 Theodorou E, Buchli J, Schaal S (2010) A generalized path integral control approach to reinforcement learning.",
              "J Mach Learn Res 11:3137\u20133181 MathSciNet MATH Google Scholar Thomaz AL, Breazeal C (2008) Teachable robots: understanding human teaching behavior to build more effective robot learners.",
              "Artif Intell 172(6\u20137):716\u2013737 Google Scholar Truong XT, Ngo TD (2017) Toward socially aware robot navigation in dynamic and crowded environments: a proactive social motion model.",
              "IEEE Trans Autom Sci Eng 14(4):1743\u20131760 Google Scholar Tsitsiklis JN, Van Roy B (1996) Feature-based methods for large scale dynamic programming.",
              "Mach Learn 22(1\u20133):59\u201394 MATH Google Scholar Tsitsiklis JN, Van Roy B (1997) Analysis of temporal-diffference learning with function approximation.",
              "In: Advances in neural information processing systems, pp 1075\u20131081 Turan M, Almalioglu Y, Gilbert HB, Mahmood F, Durr NJ, Araujo H, Sar\u0131 AE, Ajay A, Sitti M (2019) Learning to navigate endoscopic capsule robots.",
              "IEEE Robot Autom Lett 4(3):3075\u20133082 Google Scholar Tzafestas SG, Rigatos GG (2002) Fuzzy reinforcement learning control for compliance tasks of robotic manipulators.",
              "IEEE Trans Syst Man Cybern Part B (Cybern) 32(1):107\u2013113 Google Scholar Van Hasselt H, Guez A, Silver D (2016) Deep reinforcement learning with double q-learning.",
              "In: Thirtieth AAAI conference on artificial intelligence, IEEE, pp 2094\u20132100 Viseras A, Garcia R (2019) Deepig: multi-robot information gathering with deep reinforcement learning.",
              "IEEE Robot Autom Lett 4(3):3059\u20133066 Google Scholar Vlassis N (2007) A concise introduction to multiagent systems and distributed artificial intelligence.",
              "Synth Lect Artif Intell Mach Learn 1(1):1\u201371 MATH Google Scholar Wang C, Wang J, Shen Y, Zhang X (2019) Autonomous navigation of uavs in large-scale complex environments: a deep reinforcement learning approach.",
              "IEEE Trans Veh Technol 68(3):2124\u20132136 Google Scholar Wang J, Xu X, Liu D, Sun Z, Chen Q (2013) Self-learning cruise control using kernel-based least squares policy iteration.",
              "IEEE Trans Control Syst Technol 22(3):1078\u20131087 Google Scholar Wang JP, Shi YK, Zhang WS, Thomas I, Duan SH (2018a) Multitask policy adversarial learning for human-level control with large state spaces.",
              "IEEE Trans Ind Inform 15(4):2395\u20132404 Google Scholar Wang S, Chaovalitwongse W, Babuska R (2012) Machine learning algorithms in bipedal robot control.",
              "IEEE Trans Syst Man Cybern Part C (Appl Rev) 42(5):728\u2013743 Google Scholar Wang Y, Lang H, De Silva CW (2010) A hybrid visual servo controller for robust grasping by wheeled mobile robots.",
              "IEEE/ASME Trans Mech 15(5):757\u2013769 Google Scholar Wang Y, He H, Sun C (2018b) Learning to navigate through complex dynamic environment with modular deep reinforcement learning.",
              "IEEE Trans Games 10(4):400\u2013412 Google Scholar Watkins CJ, Dayan P (1992) Q-learning.",
              "Mach Learn 8(3\u20134):279\u2013292 MATH Google Scholar Watkins CJCH (1989) Learning from delayed rewards Whitbrook AM, Aickelin U, Garibaldi JM (2007) Idiotypic immune networks in mobile-robot control.",
              "IEEE Trans Syst Man Cybern Part B (Cybern) 37(6):1581\u20131598 Google Scholar Williams RJ (1992) Simple statistical gradient-following algorithms for connectionist reinforcement learning.",
              "Mach Learn 8(3\u20134):229\u2013256 MATH Google Scholar Witten IH (1977) An adaptive optimal controller for discrete-time markov environments.",
              "Inf Control 34(4):286\u2013295 MathSciNet MATH Google Scholar Wu C, Ju B, Wu Y, Lin X, Xiong N, Xu G, Li H, Liang X (2019) Uav autonomous target search based on deep reinforcement learning in complex disaster scene.",
              "IEEE Access 7:117227\u2013117245 Google Scholar Xi A, Mudiyanselage TW, Tao D, Chen C (2019) Balance control of a biped robot on a rotating platform based on efficient reinforcement learning.",
              "IEEE/CAA J Autom Sin 6(4):938\u2013951 MathSciNet Google Scholar Xiao L, Xie C, Min M, Zhuang W (2017) User-centric view of unmanned aerial vehicle transmission against smart attacks.",
              "IEEE Trans Veh Technol 67(4):3420\u20133430 Google Scholar Xu X, Liu C, Yang SX, Hu D (2011) Hierarchical approximate policy iteration with binary-tree state space decomposition.",
              "IEEE Trans Neural Netw 22(12):1863\u20131877 Google Scholar Yang E, Gu D (2004) Multiagent reinforcement learning for multi-robot systems: a survey.",
              "Tech.",
              "rep.",
              ", tech.",
              "rep Yang X, He H, Liu D (2017) Event-triggered optimal neuro-controller design with reinforcement learning for unknown nonlinear systems. IEEE Trans Syst Man Cybern Syst Yang Z, Merrick K, Jin L, Abbass HA (2018) Hierarchical deep reinforcement learning for continuous action control.",
              "IEEE Trans Neural Netw Learn Syst 29(11):5174\u20135184 MathSciNet Google Scholar Ye C, Yung NH, Wang D (2003) A fuzzy controller with supervised learning assisted reinforcement learning algorithm for obstacle avoidance.",
              "IEEE Trans Syst Man Cybern Part B (Cybern) 33(1):17\u201327 Google Scholar Yin S, Zhao S, Zhao Y, Yu FR (2019) Intelligent trajectory design in uav-aided communications with reinforcement learning.",
              "IEEE Trans Veh Technol 68(8):8227\u20138231 Google Scholar Yu C, Zhang M, Ren F, Tan G (2015a) Multiagent learning of coordination in loosely coupled multiagent systems. IEEE Trans Cybern 45(12):2853\u20132867 Google Scholar Yu J, Wang C, Xie G (2015b) Coordination of multiple robotic fish with applications to underwater robot competition.",
              "IEEE Trans Ind Electron 63(2):1280\u20131288 Google Scholar Yung NH, Ye C (1999) An intelligent mobile vehicle navigator based on fuzzy logic and reinforcement learning.",
              "IEEE Trans Syst Man Cybern Part B (Cybern) 29(2):314\u2013321 Google Scholar Zalama E, Gomez J, Paul M, Peran JR (2002) Adaptive behavior navigation of a mobile robot.",
              "IEEE Trans Syst Man Cybern Part A Syst Hum 32(1):160\u2013169 Google Scholar Zeng Y, Zhang R, Lim TJ (2016) Wireless communications with unmanned aerial vehicles: opportunities and challenges.",
              "IEEE Commun Mag 54(5):36\u201342 Google Scholar Zhang H, Jiang H, Luo Y, Xiao G (2016) Data-driven optimal consensus control for discrete-time multi-agent systems with unknown dynamics using reinforcement learning method.",
              "IEEE Trans Ind Electron 64(5):4091\u20134100 Google Scholar Zhang J, Tai L, Yun P, Xiong Y, Liu M, Boedecker J, Burgard W (2019) Vr-goggles for robots: real-to-sim domain adaptation for visual control.",
              "IEEE Robot Autom Lett 4(2):1148\u20131155 Google Scholar Zhou L, Yang P, Chen C, Gao Y (2016) Multiagent reinforcement learning with sparse interactions by negotiation and knowledge transfer.",
              "IEEE Trans Cybern 47(5):1238\u20131250 Google Scholar Zhu J, Zhu J, Wang Z, Guo S, Xu C (2018) Hierarchical decision and control for continuous multitarget problem: policy evaluation with action delay.",
              "IEEE Trans Neural Netw Learn Syst 30(2):464\u2013473 MathSciNet Google Scholar Zhu Y, Mottaghi R, Kolve E, Lim JJ, Gupta A, Fei-Fei L, Farhadi A (2017) Target-driven visual navigation in indoor scenes using deep reinforcement learning.",
              "In: 2017 IEEE international conference on robotics and automation (ICRA), IEEE, pp 3357\u20133364 Download references Department of Electrical Engineering, MNIT, Jaipur, India Bharat Singh, Rajesh Kumar & Vinay Pratap Singh You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar Correspondence to Bharat Singh.",
              "Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.",
              "Reprints and Permissions Singh, B.",
              ", Kumar, R.",
              "& Singh, V.",
              "P.",
              "Reinforcement learning in robotic applications: a comprehensive survey.",
              "Artif Intell Rev 55, 945\u2013990 (2022).",
              "https://doi.",
              "org/10.",
              "1007/s10462-021-09997-9 Download citation Accepted: 29 March 2021 Published: 20 April 2021 Issue Date: February 2022 DOI: https://doi.",
              "org/10.",
              "1007/s10462-021-09997-9 Anyone you share the following link with will be able to read this content: Sorry, a shareable link is not currently available for this article.",
              "Provided by the Springer Nature SharedIt content-sharing initiative Avoid common mistakes on your manuscript.",
              "Advertisement 205.",
              "172.",
              "168.",
              "145 University of Massachusetts Amherst W.",
              "E.",
              "B.",
              "Du Bois Library (8200177774) - NorthEast Research Libraries (NERL) (8200828607) \u00a9 2023 Springer Nature"
            ]
          },
          {
            "title": "[2102.02915] How to Train Your Robot with Deep Reinforcement Learning ...",
            "url": "https://arxiv.org/abs/2102.02915",
            "content": [
              "[2102.02915] How to Train Your Robot with Deep Reinforcement Learning ...",
              "Help | Advanced Search arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.",
              "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy.",
              "arXiv is committed to these values and only works with partners that adhere to them.",
              "Have an idea for a project that will add value for arXiv's community?",
              "Learn more about arXivLabs.",
              "arXiv Operational Status Get status notifications via email or slack"
            ]
          }
        ],
        "One of the most notable examples of reinforcement learning is AlphaStar, a program that learned to play the game of StarCraft II at a superhuman level by competing against itself and other players.": [
          {
            "title": "Grandmaster level in StarCraft II using multi-agent reinforcement learning",
            "url": "https://www.nature.com/articles/s41586-019-1724-z",
            "content": [
              "Grandmaster level in StarCraft II using multi-agent reinforcement learning",
              "Thank you for visiting nature.",
              "com.",
              "You are using a browser version with limited support for CSS.",
              "To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer).",
              "In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.",
              "Advertisement Nature volume 575, pages 350\u2013354 (2019)Cite this article 112k Accesses 1240 Citations 1011 Altmetric Metrics details Many real-world applications require artificial agents to compete and coordinate with other agents in complex environments.",
              "As a stepping stone to this goal, the domain of StarCraft has emerged as an important challenge for artificial intelligence research, owing to its iconic and enduring status among the most difficult professional esports and its relevance to the real world in terms of its raw complexity and multi-agent challenges.",
              "Over the course of a decade and numerous competitions1,2,3, the strongest agents have simplified important aspects of the game, utilized superhuman capabilities, or employed hand-crafted sub-systems4.",
              "Despite these advantages, no previous agent has come close to matching the overall skill of top StarCraft players.",
              "We chose to address the challenge of StarCraft using general-purpose learning methods that are in principle applicable to other complex domains: a multi-agent reinforcement learning algorithm that uses data from both human and agent games within a diverse league of continually adapting strategies and counter-strategies, each represented by deep neural networks5,6.",
              "We evaluated our agent, AlphaStar, in the full game of StarCraft II, through a series of online games against human players.",
              "AlphaStar was rated at Grandmaster level for all three StarCraft races and above 99.",
              "8% of officially ranked human players.",
              "You have full access to this article via your institution.",
              "StarCraft is a real-time strategy game in which players balance high-level economic decisions with individual control of hundreds of units.",
              "This domain raises important game-theoretic challenges: it features a vast space of cyclic, non-transitive strategies and counter-strategies;",
              "discovering novel strategies is intractable with naive self-play exploration methods;",
              "and those strategies may not be effective when deployed in real-world play with humans.",
              "Furthermore, StarCraft has a combinatorial action space, a planning horizon that extends over thousands of real-time decisions, and imperfect information7.",
              "Each game consists of tens of thousands of time-steps and thousands of actions, selected in real-time throughout approximately ten minutes of gameplay.",
              "At each step t, our agent AlphaStar receives an observation ot that includes a list of all observable units and their attributes.",
              "This information is imperfect;",
              "the game includes only opponent units seen by the player\u2019s own units, and excludes some opponent unit attributes outside the camera view.",
              "Each action at is highly structured: it selects what action type, out of several hundred (for example, move or build worker);",
              "who to issue that action to, for any subset of the agent\u2019s units;",
              "where to target, among locations on the map or units within the camera view;",
              "and when to observe and act next (Fig.",
              "1a).",
              "This representation of actions results in approximately 1026 possible choices at each step.",
              "Similar to human players, a special action is available to move the camera view, so as to gather more information.",
              "a, AlphaStar observes the game through an overview map and list of units.",
              "To act, the agent outputs what action type to issue (for example, build), who it is applied to, where it targets, and when the next action will be issued.",
              "Actions are sent to the game through a monitoring layer that limits action rate.",
              "AlphaStar contends with delays from network latency and processing time.",
              "b, AlphaStar is trained via both supervised learning and reinforcement learning.",
              "In supervised learning (bottom), the parameters are updated to optimize Kullback\u2013Leibler (KL) divergence between its output and human actions sampled from a collection of replays.",
              "In reinforcement learning (top), human data are used to sample the statistic z, and agent experience is collected to update the policy and value outputs via reinforcement learning (TD(\u03bb), V-trace, UPGO) combined with a KL loss towards the supervised agent.",
              "c, Three pools of agents, each initialized by supervised learning, were subsequently trained with reinforcement learning.",
              "As they train, these agents intermittently add copies of themselves\u2014\u2018players\u2019 that are frozen at a specific point\u2014to the league.",
              "The main agents train against all of these past players, as well as themselves.",
              "The league exploiters train against all past players.",
              "The main exploiters train against the main agents.",
              "Main exploiters and league exploiters can be reset to the supervised agent when they add a player to the league.",
              "Images from StarCraft reproduced with permission from Blizzard Entertainment.",
              "Humans play StarCraft under physical constraints that limit their reaction time and the rate of their actions.",
              "The game was designed with those limitations in mind, and removing those constraints changes the nature of the game.",
              "We therefore chose to impose constraints upon AlphaStar: it suffers from delays due to network latency and computation time;",
              "and its actions per minute (APM) are limited, with peak statistics substantially lower than those of humans (Figs.",
              "2c, 3g for performance analysis).",
              "AlphaStar\u2019s play with this interface and these constraints was approved by a professional player (see \u2018Professional player statement\u2019 in Methods).",
              "a, On Battle.",
              "net, StarCraft II players are divided into seven leagues, from Bronze to Grandmaster, according to their ratings (MMR).",
              "We played three variants of AlphaStar on Battle.",
              "net: AlphaStar Supervised, AlphaStar Mid, and AlphaStar Final.",
              "The supervised agent was rated in the top 16% of human players, the midpoint agent within the top 0.",
              "5%, and the final agent, on average, within the top 0.",
              "15%, achieving a Grandmaster level rating for all three races.",
              "b, MMR ratings of AlphaStar Final per race (from top to bottom: Protoss, Terran, Zerg) versus opponents encountered on Battle.",
              "net (from left to right: all races combined, Protoss, Terran, Zerg).",
              "Note that per-race data are limited;",
              "AlphaStar won all Protoss versus Terran games.",
              "c, Distribution of effective actions per minute (EPM) as reported by StarCraft II for both AlphaStar Final (blue) and human players (red).",
              "Dashed lines show mean values.",
              "Icons reproduced with permission from Blizzard Entertainment.",
              "These experiments use a simplified setup: one map (Kairos Junction), one race match-up (Protoss versus Protoss), reinforcement learning and league experiments limited to 1010 steps, only main agents, and a 50%\u201350% mix of self-play and PFSP, unless stated otherwise (see Methods).",
              "The first column shows Elo ratings24 against ablation test agents (each rating was estimated with 11,000 full games of StarCraft II).",
              "a, b, Comparing different league compositions using Elo of the main agents (a) and relative population performance of the whole leagues (b), which measures exploitability.",
              "c, d, Comparing different multi-agent learning algorithms using Elo (c) and a proxy for forgetting: the minimum win rate against all past versions, averaged over time (d).",
              "Naive self-play has a high Elo, but is more forgetful.",
              "See Extended Data Fig.",
              "5 for more in-depth comparison.",
              "e, Ablation study of the different mechanisms to use human data.",
              "Human init, supervised learning initialization of parameters of the neural network.",
              "g, APM limits relative to those used in AlphaStar.",
              "Reducing APM substantially reduces performance.",
              "Unexpectedly, increasing APM also reduces performance, possibly because the agent spends more effort on refining micro-tactics than on learning diverse strategies.",
              "f, h, Comparison of architectures using the win rate of supervised agents (trained in Protoss versus all) against the built-in elite bot.",
              "j, Elo scores of StarCraft II built-in bots.",
              "Ratings are anchored by a bot that never acts.",
              "i, k, Reinforcement learning ablations, measured by training a best response against fixed opponents to avoid multi-agent dynamics.",
              "To address the complexity and game-theoretic challenges of StarCraft, AlphaStar uses a combination of new and existing general-purpose techniques for neural network architectures, imitation learning, reinforcement learning, and multi-agent learning.",
              "Further details about these techniques are given in the Methods.",
              "Central to AlphaStar is a policy \\({\\pi }_{\\theta }({a}_{t}\\,|\\,{s}_{t},z)={\\mathbb{P}}[{a}_{t}\\,|\\,{s}_{t},z]\\), represented by a neural network with parameters \u03b8 that receives all observations st = (o1:t, a1:t \u2212 1) from the start of the game as inputs, and selects actions as outputs.",
              "The policy is also conditioned on a statistic z that summarizes a strategy sampled from human data (for example, a build order).",
              "Our agent architecture consists of general-purpose neural network components that handle StarCraft\u2019s raw complexity.",
              "Observations of player and opponent units are processed using a self-attention mechanism8.",
              "To integrate spatial and non-spatial information, we introduce scatter connections.",
              "To deal with partial observability, the temporal sequence of observations is processed by a deep long short-term memory (LSTM) system9.",
              "To manage the structured, combinatorial action space, the agent uses an auto-regressive policy7,10,11 and recurrent pointer network12.",
              "Extended Data Fig.",
              "3 summarizes the architecture and Fig.",
              "3f shows an ablation of each component.",
              "Agent parameters were initially trained by supervised learning.",
              "Games were sampled from a publicly available dataset of anonymized human replays.",
              "The policy was then trained to predict each action at, conditioned either solely on st, or also on z.",
              "This results in a diverse set of strategies that reflects the modes of human play.",
              "The agent parameters were subsequently trained by a reinforcement learning algorithm that is designed to maximize the win rate (that is, compute a best response) against a mixture of opponents.",
              "The choice of opponent is determined by a multi-agent procedure, described below.",
              "AlphaStar\u2019s reinforcement learning algorithm is based on a policy gradient algorithm similar to advantage actor\u2013critic13.",
              "Updates were applied asynchronously14 on replayed experiences15.",
              "This requires an approach known as off-policy learning5, that is, updating the current policy from experience generated by a previous policy.",
              "Our solution is motivated by the observation that, in large action spaces, the current and previous policies are highly unlikely to match over many steps.",
              "We therefore use a combination of techniques that can learn effectively despite the mismatch: temporal difference learning (TD(\u03bb))16, clipped importance sampling (V-trace)14, and a new self-imitation17 algorithm (UPGO) that moves the policy towards trajectories with better-than-average reward.",
              "To reduce variance, during training only, the value function is estimated using information from both the player\u2019s and the opponent\u2019s perspectives.",
              "Figure 3i, k analyses the relative importance of these components.",
              "One of the main challenges in StarCraft is to discover novel strategies.",
              "Consider a policy that has learned to build and utilize the micro-tactics of ground units.",
              "Any deviation that builds and naively uses air units will reduce performance.",
              "It is highly improbable that naive exploration will execute a precise sequence of instructions, over thousands of steps, that constructs air units and effectively utilizes their micro-tactics.",
              "To address this issue, and to encourage robust behaviour against likely human play, we utilize human data.",
              "Each agent is initialized to the parameters of the supervised learning agent.",
              "Subsequently, during reinforcement learning, we either condition the agent on a statistic z, in which case agents receive a reward for following the strategy corresponding to z, or train the agent unconditionally, in which case the agent is free to choose its own strategy.",
              "Agents also receive a penalty whenever their action probabilities differ from the supervised policy.",
              "This human exploration ensures that a wide variety of relevant modes of play continue to be explored throughout training.",
              "Figure 3e shows the importance of human data in AlphaStar.",
              "To address the game-theoretic challenges, we introduce league training, an algorithm for multi-agent reinforcement learning (Fig.",
              "1b, c).",
              "Self-play algorithms, similar to those used in chess and Go18, learn rapidly but may chase cycles (for example, where A defeats B, and B defeats C, but A loses to C) indefinitely without making progress19.",
              "Fictitious self-play (FSP)20,21,22 avoids cycles by computing a best response against a uniform mixture of all previous policies;",
              "the mixture converges to a Nash equilibrium in two-player zero-sum games20.",
              "We extend this approach to compute a best response against a non-uniform mixture of opponents.",
              "This league of potential opponents includes a diverse range of agents (Fig.",
              "4d), as well as their policies from both current and previous iterations.",
              "At each iteration, each agent plays games against opponents sampled from a mixture policy specific to that agent.",
              "The parameters of the agent are updated from the outcomes of those games by the actor\u2013critic reinforcement learning procedure described above.",
              "a, Training Elo scores of agents in the league during the 44 days of training.",
              "Each point represents a past player, evaluated against the entire league and the elite built-in bot (whose Elo is set to 0).",
              "b, Proportion of validation agents that beat the main agents in more than 80 out of 160 games.",
              "This value increased steadily over time, which shows the robustness of league training to unseen strategies.",
              "c, The Nash distribution (mixture of the least exploitable players) of the players in the league, as training progressed.",
              "It puts the most weight on recent players, suggesting that the latest strategies largely dominate earlier ones, without much forgetting or cycling.",
              "For example, player 40 was part of the Nash distribution from its creation at day 20 until 5 days later, when it was completely dominated by newer agents.",
              "d, Average number of each unit built by the Protoss agents over the course of league training, normalized by the most common unit.",
              "Unlike the main agents, the exploiters rapidly explore different unit compositions.",
              "Worker units have been removed for clarity.",
              "The league consists of three distinct types of agent, differing primarily in their mechanism for selecting the opponent mixture.",
              "First, the main agents utilize a prioritized fictitious self-play (PFSP) mechanism that adapts the mixture probabilities proportionally to the win rate of each opponent against the agent;",
              "this provides our agent with more opportunities to overcome the most problematic opponents.",
              "With fixed probability, a main agent is selected as an opponent;",
              "this recovers the rapid learning of self-play (Fig.",
              "3c).",
              "Second, main exploiter agents play only against the current iteration of main agents.",
              "Their purpose is to identify potential exploits in the main agents;",
              "the main agents are thereby encouraged to address their weaknesses.",
              "Third, league exploiter agents use a similar PFSP mechanism to the main agents, but are not targeted by main exploiter agents.",
              "Their purpose is to find systemic weaknesses of the entire league.",
              "Both main exploiters and league exploiters are periodically reinitialized to encourage more diversity and may rapidly discover specialist strategies that are not necessarily robust against exploitation.",
              "Figure 3b analyses the choice of agents within the league.",
              "In StarCraft, each player chooses one of three races\u2014Terran, Protoss or Zerg\u2014each with distinct mechanics.",
              "We trained the league using three main agents (one for each StarCraft race), three main exploiter agents (one for each race), and six league exploiter agents (two for each race).",
              "Each agent was trained using 32 third-generation tensor processing units (TPUs23) over 44 days.",
              "During league training almost 900 distinct players were created.",
              "We evaluated the three main Terran, Protoss and Zerg AlphaStar agents using the unconditional policy on the official online matchmaking system Battle.",
              "net.",
              "Each agent was assessed at three different snapshots during training: after supervised training only (AlphaStar Supervised), after 27 days of league training (AlphaStar Mid), and after 44 days of league training (AlphaStar Final).",
              "AlphaStar Supervised and AlphaStar Mid were evaluated starting from an unranked rating on Battle.",
              "net for 30 and 60 games, respectively, for each race;",
              "AlphaStar Final was evaluated from AlphaStar Mid\u2019s rating for an additional 30 games for each race.",
              "The Battle.",
              "net matchmaking procedure selected maps and opponents.",
              "Matches were played under blind conditions: AlphaStar was not provided with the opponent\u2019s identity, and played under an anonymous account.",
              "These conditions were selected to estimate AlphaStar\u2019s strength under approximately stationary conditions, but do not directly measure its susceptibility to exploitation under repeated play.",
              "AlphaStar Final achieved ratings of 6,275 Match Making Rating (MMR) for Protoss, 6,048 MMR for Terran and 5,835 MMR for Zerg, placing it above 99.",
              "8% of ranked human players, and at Grandmaster level for all three races (Fig.",
              "2a, Extended Data Fig.",
              "7 (analysis), Supplementary Data, Replays (game replays)).",
              "AlphaStar Supervised reached an average rating of 3,699, which places it above 84% of human players and shows the effectiveness of supervised learning.",
              "To further analyse AlphaStar we also ran several internal ablations (Fig.",
              "3) and evaluations (Fig.",
              "4).",
              "For multi-agent dynamics, we ran a round-robin tournament of all players throughout league training and a second tournament of main agents against held-out validation agents trained to follow specific human strategies.",
              "The main agent performance improved steadily across all three races.",
              "The performance of the main exploiters actually reduced over time and main agents performed better against the held-out validation agents, both of which suggest that the main agent grew increasingly robust.",
              "The league Nash equilibrium over all players at each point in time assigns small probabilities to players from previous iterations, suggesting that the learning algorithm does not cycle or regress.",
              "Finally, the unit composition changed throughout league training, which indicates a diverse strategic progression.",
              "AlphaStar is the first agent to achieve Grandmaster level in StarCraft II, and the first to reach the highest league of human players in a widespread professional esport without simplification of the game.",
              "Like StarCraft, real-world domains such as personal assistants, self-driving cars, or robotics require real-time decisions, over combinatorial or structured action spaces, given imperfectly observed information.",
              "Furthermore, similar to StarCraft, many applications have complex strategy spaces that contain cycles or hard exploration landscapes, and agents may encounter unexpected strategies or complex edge cases when deployed in the real world.",
              "The success of AlphaStar in StarCraft II suggests that general-purpose machine learning algorithms may have a substantial effect on complex real-world problems. StarCraft is a real-time strategy game that takes place in a science fiction universe.",
              "The franchise, from Blizzard Entertainment, comprises StarCraft: Brood War and StarCraft II.",
              "In this paper, we used StarCraft II.",
              "Since StarCraft was released in 1998, there has been a strong competitive community with tens of millions of dollars of prize money.",
              "The most common competitive setting of StarCraft II is 1v1, where each player chooses one of the three available races\u2014Terran, Protoss, and Zerg\u2014which all have distinct units and buildings, exhibit different mechanics, and necessitate different strategies when playing for and against.",
              "There is also a Random race, where the game selects the player\u2019s race at random.",
              "Players begin with a small base and a few worker units, which gather resources to build additional units and buildings, scout the opponent, and research new technologies.",
              "A player is defeated if they lose all buildings.",
              "There is no universally accepted notion of fairness in real-time human\u2013computer matches, so our match conditions, interface, camera view, action rate limits, and delays were developed in consultation with professional StarCraft II players and Blizzard employees.",
              "AlphaStar\u2019s play under these conditions was professional-player approved (see the Professional Player Statement, below).",
              "At each agent step, the policy receives an observation ot and issues an action at (Extended Data Tables 1, 2) through the game interface.",
              "There can be several game time-steps (each 45 ms) per agent step.",
              "Humans play StarCraft through a screen that displays only part of the map along with a high-level view of the entire map (to avoid information overload, for example).",
              "The agent interacts with the game through a similar camera-like interface, which naturally imposes an economy of attention, so that the agent chooses which area it fully sees and interacts with.",
              "The agent can move the camera as an action.",
              "Opponent units outside the camera have certain information hidden, and the agent can only target within the camera for certain actions (for example, building structures).",
              "AlphaStar can target locations more accurately than humans outside the camera, although less accurately within it because target locations (selected on a 256 \u00d7 256 grid) are treated the same inside and outside the camera.",
              "Agents can also select sets of units anywhere, which humans can do less flexibly using control groups.",
              "In practice, the agent does not seem to exploit these extra capabilities (see the Professional Player Statement, below), because of the human prior.",
              "Ablation data in Fig.",
              "3h shows that using this camera view reduces performance.",
              "Humans are physically limited in the number of actions per minute (APM) they can execute.",
              "Our agent has a monitoring layer that enforces APM limitations.",
              "This introduces an action economy that requires actions to be prioritized.",
              "Agents are limited to executing at most 22 non-duplicate actions per 5-s window.",
              "Converting between actions and the APM measured by the game is non-trivial, and agent actions are hard to compare with human actions (computers can precisely execute different actions from step to step).",
              "See Fig.",
              "2c and Extended Data Fig.",
              "1 for APM details.",
              "Humans are limited in how quickly they react to new information;",
              "AlphaStar has two sources of delays.",
              "First, in real-time evaluation (not training), AlphaStar has a delay of about 110 ms between when a frame is observed and when an action is executed, owing to latency, observation processing, and inference.",
              "Second, because agents decide ahead of time when to observe next (on average 370 ms, but possibly multiple seconds), they may react late to unexpected situations.",
              "The distribution of these delays is shown in Extended Data Fig.",
              "2.",
              "Games have been a focus of artificial intelligence research for decades as a stepping stone towards more general applications.",
              "Classic board games such as chess25 and Go26 have been mastered using general-purpose reinforcement learning and planning algorithms18.",
              "Reinforcement learning methods have achieved substantial successes in video games such as those on the Atari platform27, Super Mario Bros28, Quake III Arena Capture the Flag29, and Dota 230.",
              "Real-time strategy (RTS) games are recognized for their game-theoretic and domain complexities31.",
              "Many sub-problems of RTS games, for example, micromanagement, base economy, or build order optimization, have been studied in depth7,32,33,34,35, often in small-scale environments36,37.",
              "For the combined challenge, the StarCraft domain has emerged by consensus as a research focus1,7.",
              "StarCraft: Brood War has an active competitive AI research community38, and most bots combine rule-based heuristics with other AI techniques such as search4,39, data-driven build-order selection40, and simulation41.",
              "Reinforcement learning has also been studied to control units in the game7,34,42,43,44, and imitation learning has been proposed to learn unit and building compositions45.",
              "Most recently, deep learning has been used to predict future game states46.",
              "StarCraft II similarly has an active bot community3 since the release of a public application programming interface (API)7.",
              "No StarCraft bots have defeated professional players, or even high-level casual players47, and the most successful bots have used superhuman capabilities, such as executing tens of thousands of APM or viewing the entire map at once.",
              "These capabilities make comparisons against humans hard, and invalidate certain strategies.",
              "Some of the most recent approaches use reinforcement learning to play the full game, with hand-crafted, high-level actions48, or rule-based systems with machine learning incrementally replacing components43.",
              "By contrast, AlphaStar uses a model-free, end-to-end learning approach to playing StarCraft II that sidesteps the difficulties of search-based methods that result from imperfect models, and is applicable to any domain that shares some of the challenges present in StarCraft.",
              "Dota 2 is a modern competitive team game that shares some complexities of RTS games such as StarCraft (including imperfect information and large time horizons).",
              "Recently, OpenAI Five defeated a team of professional Dota 2 players and 99.",
              "4% of online players30.",
              "The hero units of OpenAI Five are controlled by a team of agents, trained together with a scaled up version of PPO49, based on handcrafted rewards.",
              "However, unlike AlphaStar, some game rules were simplified, players were restricted to a subset of heroes, agents used hard-coded sub-systems for certain aspects of the game, and agents did not limit their perception to a camera view.",
              "AlphaStar relies on imitation learning combined with reinforcement learning, which has been used several times in the past.",
              "Similarly to the training pipeline of AlphaStar, the original AlphaGo initialized a policy network by supervised learning from human games, which was then used as a prior in Monte-Carlo tree search26.",
              "Similar to our statistic z, other work attempted to train reward functions from human preferences and use them to guide reinforcement learning50,51 or learned goals from human intervention52.",
              "Related to the league, recent progress in multi-agent research has led to agents performing at human level in the Capture the Flag team mode of Quake III Arena29.",
              "These results were obtained using population-based training of several agents competing with each other, which used pseudo-reward evolution to deal with the hard credit assignment problem.",
              "Similarly, the Policy Space Response Oracle framework53 is related to league training, although league training specifies unique targets for approximate best responses (that is, PFSP and exploiters).",
              "The policy of AlphaStar is a function \u03c0\u03b8(at | st,z) that maps all previous observations and actions st = o1:t, a1:t \u2212 1 (defined in Extended Data Tables 1, 2) and z (representing strategy statistics) to a probability distribution over actions at for the current step.",
              "\u03c0\u03b8 is implemented as a deep neural network with the following structure.",
              "The observations ot are encoded into vector representations, combined, and processed by a deep LSTM9, which maintains memory between steps.",
              "The action arguments at are sampled auto-regressively10, conditioned on the outputs of the LSTM and the observation encoders.",
              "There is a value function for each of the possible rewards (see Reinforcement learning).",
              "Architecture components were chosen and tuned with respect to their performance in supervised learning, and include many recent advances in deep learning architectures7,8,12,54,55.",
              "A high-level overview of the agent architecture is given in Extended Data Fig.",
              "3, with more detailed descriptions in Supplementary Data, Detailed Architecture.",
              "AlphaStar has 139 million weights, but only 55 million weights are required during inference.",
              "Ablation Fig.",
              "3f compares the impact of scatter connections, transformer, and pointer network.",
              "Each agent is initially trained through supervised learning on replays to imitate human actions.",
              "Supervised learning is used both to initialize the agent and to maintain diverse exploration56.",
              "Because of this, the primary goal is to produce a diverse policy that captures StarCraft\u2019s complexities.",
              "We use a dataset of 971,000 replays played on StarCraft II versions 4.",
              "8.",
              "2 to 4.",
              "8.",
              "6 by players with MMR scores (Blizzard\u2019s metric, similar to Elo) greater than 3,500, that is, from the top 22% of players.",
              "Instructions for downloading replays can be found at https://github.",
              "com/Blizzard/s2client-proto.",
              "The observations and actions are returned by the game\u2019s raw interface (Extended Data Tables 1, 2).",
              "We train one policy for each race, with the same architecture as the one used during reinforcement learning.",
              "From each replay, we extract a statistic z that encodes each player\u2019s build order, defined as the first 20 constructed buildings and units, and cumulative statistics, defined as the units, buildings, effects, and upgrades that were present during a game.",
              "We condition the policy on z in both supervised and reinforcement learning, and in supervised learning we set z to zero 10% of the time.",
              "To train the policy, at each step we input the current observations and output a probability distribution over each action argument (Extended Data Table 2).",
              "For these arguments, we compute the KL divergence between human actions and the policy\u2019s outputs, and apply updates using the Adam optimizer57.",
              "We also apply L2 regularization58.",
              "The pseudocode of the supervised training algorithm can be found in Supplementary Data, Pseudocode.",
              "We further fine-tune the policy using only winning replays with MMR above 6,200 (16,000 games).",
              "Fine-tuning improved the win rate against the built-in elite bot from 87% to 96% in Protoss versus Protoss games.",
              "The fine-tuned supervised agents were rated at 3,947 MMR for Terran, 3,607 MMR for Protoss and 3,544 MMR for Zerg.",
              "They are capable of building all units in the game, and are qualitatively diverse from game to game (Extended Data Fig.",
              "4).",
              "We apply reinforcement learning to improve the performance of AlphaStar based on agent-versus-agent games.",
              "We use the match outcome (\u22121 on a loss, 0 on a draw and +1 on a win) as the terminal reward rT, without a discount to accurately reflect the true goal of winning games.",
              "Following the actor\u2013critic paradigm14, a value function V\u03b8(st, z) is trained to predict rt, and used to update the policy \u03c0\u03b8(at | st, z).",
              "StarCraft poses several challenges when viewed as a reinforcement learning problem: exploration is difficult, owing to domain complexity and reward sparsity;",
              "policies need to be capable of executing diverse strategies throughout training;",
              "and off-policy learning is difficult, owing to large time horizons and the complex action space.",
              "We use human data to aid in exploration and to preserve strategic diversity throughout training.",
              "First, we initialize the policy parameters to the supervised policy and continually minimize the KL divergence between the supervised and current policy59,60.",
              "Second, we train the main agents with pseudo-rewards to follow a strategy statistic z, which we randomly sample from human data.",
              "These pseudo-rewards measure the edit distance between sampled and executed build orders, and the Hamming distance between sampled and executed cumulative statistics (see Supplementary Data, Detailed Architecture).",
              "Each type of pseudo-reward is active (that is, non-zero) with probability 25%, and separate value functions and losses are computed for each pseudo-reward.",
              "We found our use of human data to be critical in achieving good performance with reinforcement learning (Fig.",
              "3e).",
              "New trajectories are generated by actors.",
              "Asynchronously, model parameters are updated by learners, using a replay buffer that stores trajectories.",
              "Because of this, AlphaStar is subject to off-policy data, which potentially requires off-policy corrections.",
              "We found that existing off-policy correction methods14,61 can be inefficient in large, structured action spaces such as that used for StarCraft, because distinct actions can result in similar (or even identical) behaviour.",
              "We addressed this by using a hybrid approach that combines off-policy corrections for the policy (which avoids instability), with an uncorrected update of the value function (which introduces bias but reduces variance).",
              "Specifically, the policy is updated using V-trace and the value estimates are updated using TD(\u03bb)5 (ablation in Fig.",
              "3i).",
              "When applying V-trace to the policy in large action spaces, the off-policy corrections truncate the trace early;",
              "to mitigate this problem, we assume independence between the action type, delay, and all other arguments, and so update the components of the policy separately.",
              "To decrease the variance of the value estimates, we also use the opponent\u2019s observations as input to the value functions (ablation in Fig.",
              "3k).",
              "Note that these are used only during training, as value functions are unnecessary during evaluation.",
              "In addition to the V-trace policy update, we introduce an upgoing policy update (UPGO), which updates the policy parameters in the direction of where is an upgoing return, Q(st,at,z) is an action-value estimate, \\({\\rho }_{t}=min\\left(\\frac{{\\pi }_{\\theta }({a}_{t}|{s}_{t},z)}{{\\pi }_{{\\theta }^{^{\\prime} }}({a}_{t}|{s}_{t},z)},1\\right)\\) is a clipped importance ratio, and \\({\\pi }_{{\\theta }^{^{\\prime} }}\\) is the policy that generated the trajectory in the actor.",
              "Similar to self-imitation learning17, the idea is to update the policy from partial trajectories with better-than-expected returns by bootstrapping when the behaviour policy takes a worse-than-average action (ablation in Fig.",
              "3i).",
              "Owing to the difficulty of approximating Q(st, at, z) over the large action space of StarCraft, we estimate action-values with a one-step target, Q(st, at, z) = rt + V\u03b8(st + 1, z).",
              "The overall loss is a weighted sum of the policy and value function losses described above, corresponding to the win-loss reward rt as well as pseudo-rewards based on human data, the KL divergence loss with respect to the supervised policy, and the standard entropy regularization loss13.",
              "We optimize the overall loss using Adam57.",
              "The pseudocode of the reinforcement learning algorithm can be found in Supplementary Data, Pseudocode.",
              "League training is a multi-agent reinforcement learning algorithm that is designed both to address the cycles commonly encountered during self-play training and to integrate a diverse range of strategies.",
              "During training, we populate the league by regularly saving the parameters from our agents (that are being trained by the RL algorithm) as new players (which have fixed, frozen parameters).",
              "We also continuously re-evaluate the internal payoff estimation, giving agents up-to-date information about their performance against all players in the league (see evaluators in Extended Data Fig.",
              "6).",
              "Our self-play algorithm plays games between the latest agents for all three races.",
              "This approach may chase cycles in strategy space and does not work well in isolation (Fig.",
              "3d).",
              "FSP20,21,22 avoids cycles by playing against all previous players in the league.",
              "However, many games are wasted against players that are defeated in almost 100% of games.",
              "Consequently, we introduce PFSP.",
              "Instead of uniformly sampling opponents in the league, we use a matchmaking mechanism to provide a good learning signal.",
              "Given a learning agent A, we sample the frozen opponent B from a candidate set \\({\\mathscr{C}}\\) with probability Where f: [0, 1] \u2192 [0, \u221e) is some weighting function.",
              "Choosing fhard(x) = (1 \u2212 x)p makes PFSP focus on the hardest players, where \\(p\\in {{\\mathbb{R}}}_{+}\\) controls how entropic the resulting distribution is.",
              "As fhard(1) = 0, no games are played against opponents that the agent already beats.",
              "By focusing on the hardest players, the agent must beat everyone in the league rather than maximizing average performance, which is even more important in highly non-transitive games such as StarCraft (Extended Data Fig.",
              "8), where the pursuit of the mean win rate might lead to policies that are easy to exploit.",
              "This scheme is used as the default weighting of PFSP.",
              "Consequently, on the theoretical side, one can view fhard as a form of smooth approximation of max\u2013min optimization, as opposed to max\u2013avg, which is imposed by FSP.",
              "In particular, this helps with integrating information from exploits, as these are strong but rare counter strategies, and a uniform mixture would be able to just ignore them (Extended Data Fig.",
              "5).",
              "Only playing against the hardest opponents can waste games against much stronger opponents, so PFSP also uses an alternative curriculum, fvar(x) = x(1 \u2212 x), where the agent preferentially plays against opponents around its own level.",
              "We use this curriculum for main exploiters and struggling main agents.",
              "During training we used three agent types that differ only in the distribution of opponents they train against, when they are snapshotted to create a new player, and the probability of resetting to the supervised parameters.",
              "Main agents are trained with a proportion of 35% SP, 50% PFSP against all past players in the league, and an additional 15% of PFSP matches against forgotten main players the agent can no longer beat and past main exploiters.",
              "If there are no forgotten players or strong exploiters, the 15% is used for self-play instead.",
              "Every 2 \u00d7 109 steps, a copy of the agent is added as a new player to the league.",
              "Main agents never reset.",
              "League exploiters are trained using PFSP and their frozen copies are added to the league when they defeat all players in the league in more than 70% of games, or after a timeout of 2 \u00d7 109 steps.",
              "At this point there is a 25% probability that the agent is reset to the supervised parameters.",
              "The intuition is that league exploiters identify global blind spots in the league (strategies that no player in the league can beat, but that are not necessarily robust themselves).",
              "Main exploiters play against main agents.",
              "Half of the time, and if the current probability of winning is lower than 20%, exploiters use PFSP with fvar weighting over players created by the main agents.",
              "This forms a curriculum that facilitates learning.",
              "Otherwise there is enough learning signal and it plays against the current main agents.",
              "These agents are added to the league whenever all three main agents are defeated in more than 70% of games, or after a timeout of 4 \u00d7 109 steps.",
              "They are then reset to the supervised parameters.",
              "Main exploiters identify weaknesses of main agents, and consequently make them more robust.",
              "For more details refer to the Supplementary Data, Pseudocode.",
              "In order to train the league, we run a large number of StarCraft II matches in parallel and update the parameters of the agents on the basis of data from those games.",
              "To manage this, we developed a highly scalable training setup with different types of distributed workers.",
              "For every training agent in the league, we run 16,000 concurrent StarCraft II matches and 16 actor tasks (each using a TPU v3 device with eight TPU cores23) to perform inference.",
              "The game instances progress asynchronously on preemptible CPUs (roughly equivalent to 150 processors with 28 physical cores each), but requests for agent steps are batched together dynamically to make efficient use of the TPU.",
              "Using TPUs for batched inference provides large efficiency gains over previous work14,29.",
              "Actors send sequences of observations, actions, and rewards over the network to a central 128-core TPU learner worker, which updates the parameters of the training agent.",
              "The received data are buffered in memory and replayed twice.",
              "The learner worker performs large-batch synchronous updates.",
              "Each TPU core processes a mini-batch of four sequences, for a total batch size of 512.",
              "The learner processes about 50,000 agent steps per second.",
              "The actors update their copy of the parameters from the learner every 10 s.",
              "We instantiate 12 separate copies of this actor\u2013learner setup: one main agent, one main exploiter and two league exploiter agents for each StarCraft race.",
              "One central coordinator maintains an estimate of the payoff matrix, samples new matches on request, and resets main and league exploiters.",
              "Additional evaluator workers (running on the CPU) are used to supplement the payoff estimates.",
              "See Extended Data Fig.",
              "6 for an overview of the training setup.",
              "AlphaStar agents were evaluated against humans on Battle.",
              "net, Blizzard\u2019s online matchmaking system based on MMR ratings, on StarCraft II balance patch 4.",
              "9.",
              "3.",
              "AlphaStar Final was rated at Grandmaster level, above 99.",
              "8% of human players who were active enough in the past months to be placed into a league on the European server (about 90,000 players).",
              "AlphaStar played only opponents who opted to participate in the experiment (the majority of players opted in)62, used an anonymous account name, and played on four maps: Cyber Forest, Kairos Junction, King\u2019s Cove, and New Repugnancy.",
              "Blizzard updated the map pool a few weeks before testing.",
              "Instead of retraining AlphaStar, we simply played on the four common maps that were kept in the pool of seven available maps.",
              "Humans also must select at least four maps and frequently play under anonymous account names.",
              "Each agent ran on a single high-end consumer GPU.",
              "We evaluated at three points during training: supervised, midpoint, and final.",
              "For the supervised and midpoint evaluations, each agent began with a fresh, unranked account.",
              "Their MMR was updated on Battle.",
              "net as for humans.",
              "The supervised and midpoint evaluations played 30 and 60 games, respectively.",
              "The midpoint evaluation was halted while still increasing because the anonymity constraint was compromised after 50 games.",
              "For the final Battle.",
              "net evaluation, we used several accounts to parallelize the games and help to avoid identification.",
              "The MMRs of our accounts were seeded randomly from the distribution of combined, estimated, midpoint MMRs.",
              "Consequently, we no longer used the iterative MMR estimation provided in Battle.",
              "net, and instead used the underlying probabilistic model provided by Blizzard: given our rating r with uncertainty u, and opponent rating ri with uncertainty ui \u2208 [0.",
              "1, 1.",
              "0], the probability of the outcome oi \u2208 {\u22121, 1} is where \u03a6 is the cumulative distribution function (CDF) of a standard Gaussian distribution, and where we used Battle.",
              "net\u2019s minimum uncertainties u = ui = 0.",
              "1.",
              "Under independent and identically distributed (IID) assumptions of match results and a uniform prior over MMRs, we can compute our rating as \\(\\begin{array}{cc}\\mathop{\\mathrm{argmax}}\\limits_{r\\in {\\mathbb{N}}}{\\mathbb{P}}[r\\,| \\,{\\rm{r}}{\\rm{e}}{\\rm{s}}{\\rm{u}}{\\rm{l}}{\\rm{t}}{\\rm{s}}] & =\\,\\mathop{\\mathrm{argmax}}\\limits_{r\\in {\\mathbb{N}}}{\\mathbb{P}}[{\\rm{r}}{\\rm{e}}{\\rm{s}}{\\rm{u}}{\\rm{l}}{\\rm{t}}{\\rm{s}}\\,| \\,r]U(r)\\\\ & =\\,\\mathop{\\mathrm{argmax}}\\limits_{r\\in {\\mathbb{N}}}\\mathop{\\prod }\\limits_{i=1}^{N}{\\mathbb{P}}[{o}_{i}\\,| \\,r,{r}_{i}]\\end{array}\\)We validated our MMR computation on the 200 most recent matches of Dario \u2018TLO\u2019 Wu\u0308nsch, a professional StarCraft II player, and obtained an MMR estimate of 6,334;",
              "the average MMR reported by Battle.",
              "net was 6,336.",
              "In December 2018, we played two five-game series against StarCraft II professional players Grzegorz \u2018MaNa\u2019 Komincz and Dario \u2018TLO\u2019 Wu\u0308nsch, although TLO did not play the same StarCraft II race that he plays professionally.",
              "These games took place with a different, preliminary version of AlphaStar63.",
              "In particular, the agent did not have a limited camera, was less restricted in how often it could act, and played for and against a single StarCraft II race on a single map.",
              "AlphaStar won all ten games in both five-game series, although an early camera prototype lost a follow-up game against MaNa.",
              "For validation agents, we validated league robustness against a set of 17 strategies trained using only main agents and no exploiters, and fixing z to a hand-curated set of interesting strategies (for example, a cannon rush or early flying units).",
              "Ablation test agents included the validation agents, and the first (that is, weaker) 20 main and 20 league exploiter Protoss agents created by full league training.",
              "For fixed opponents, to evaluate our reinforcement learning algorithms, we computed the best response against a uniform mixed strategy composed of the first ten league exploiter Protoss agents created by league training.",
              "To compute internal Elo ratings of the league, we added the built-in bots, and used them to estimate Elo with the following model: where r1 and r2 are the Elo ratings of both players.",
              "As the Elo rating has no intrinsic absolute scale, we ground it by setting the rating of the built-in elite bot to 0.",
              "RPP is the expected outcome of the meta-game between two populations after they reach the Nash equilibrium19.",
              "Given a payoff matrix between all agents in leagues A and B of sizes N and M, respectively, PAB \u2208 [0, 1]N \u00d7 M: where Nash(X) \u2208 [0, 1]K is a vector of probabilities assigned to playing each agent, in league X of size K, in the Nash equilibrium.",
              "High RPP means that league A consists of agents that can form a mixed strategy that can exploit agents from league B, while not being too exploitable by any mixed strategy from league B.",
              "To address the complexity and game-theoretic challenges of StarCraft, AlphaStar uses a combination of new and existing general-purpose techniques for neural network architectures, imitation learning, reinforcement learning, and multi-agent learning.",
              "These techniques and their combination are widely applicable.",
              "The neural network architecture components, including the new scatter connections, are all generally applicable to any domain whose observations comprise a combination of images, lists, and sets, all of which are present in StarCraft.",
              "AlphaStar\u2019s action space is defined as a set of functions with typed arguments.",
              "Any domain which defines a similar API can be tackled with the same decomposition of complex, structured action spaces, whose joint probability is decomposed via the chain rule (akin to, for example, language modelling10 or theorem proving).",
              "Imitation learning for AlphaStar requires a large number of human demonstrations to be effective, and thus is applicable only to those domains that provide such a set of demonstrations.",
              "Using a latent variable z to induce exploration is not specific to StarCraft, but the particular choice of statistics required domain knowledge.",
              "In particular, we chose z to encode openings and units in StarCraft.",
              "Pseudo-rewards were based on appropriate distance metrics for these statistics, such as edit distance or Hamming distance.",
              "AlphaStar\u2019s underlying reinforcement learning algorithm can be applied to any reinforcement learning environment.",
              "The use of an opponent\u2019s observations for a lower-variance baseline and new components, such as hybrid off-policy learning, UPGO, and distillation towards an imitation policy, are also widely applicable.",
              "Last, we propose a new multi-agent training regime with different kinds of exploiters whose purpose is to strengthen the main agents.",
              "Together with PFSP, these are all general-purpose techniques that can be applied to any multiplayer domain.",
              "The following quote describes our interface and limitations from StarCraft II professional player Dario \u2018TLO\u2019 Wu\u0308nsch (who is part of the team and an author of this paper).",
              "\u201cThe limitations that have been put in place for AlphaStar now mean that it feels very different from the initial show match in January.",
              "While AlphaStar has excellent and precise control it doesn\u2019t feel superhuman\u2014certainly not on a level that a human couldn\u2019t theoretically achieve.",
              "It is better in some aspects than humans and then also worse in others, but of course there are going to be unavoidable differences between AlphaStar and human players.",
              "I\u2019ve had the pleasure of providing consultation to the AlphaStar team to help ensure that DeepMind\u2019s system does not have any unfair advantages over human players.",
              "Overall, it feels very fair, like it is playing a \u2018real\u2019 game of StarCraft and doesn\u2019t completely throw the balance off by having unrealistic capabilities.",
              "Now that it has limited camera view, when I multi-task it doesn\u2019t always catch everything at the same time, so that aspect also feels very fair and more human-like.",
              "\u201d Further information on research design is available in the Nature Research Reporting Summary linked to this paper.",
              "All the games that AlphaStar played online can be found in the file \u2018replays.",
              "zip\u2019 in the Supplementary Data, and the raw data from the Battle.",
              "net experiment can be found in \u2018bnet.",
              "json\u2019 in the Supplementary Data.",
              "The StarCraft II environment was open sourced in 2017 by Blizzard and DeepMind7.",
              "All the human replays used for imitation learning can be found at https://github.",
              "com/Blizzard/s2client-proto.",
              "The pseudocode for the supervised learning, reinforcement learning, and multi-agent learning components of AlphaStar can be found in the file \u2018pseudocode.",
              "zip\u2019 in the Supplementary Data.",
              "All the neural architecture details and hyper-parameters can be found in the file \u2018detailed-architecture.",
              "txt\u2019 in the Supplementary Data.",
              "AIIDE StarCraft AI Competition.",
              "https://www.",
              "cs.",
              "mun.",
              "ca/dchurchill/starcraftaicomp/.",
              "Student StarCraft AI Tournament and Ladder.",
              "https://sscaitournament.",
              "com/.",
              "Starcraft 2 AI ladder.",
              "https://sc2ai.",
              "net/.",
              "Churchill, D.",
              ", Lin, Z.",
              "& Synnaeve, G.",
              "An analysis of model-based heuristic search techniques for StarCraft combat scenarios.",
              "in Artificial Intelligence and Interactive Digital Entertainment Conf.",
              "(AAAI, 2017).",
              "Sutton, R.",
              "& Barto, A.",
              "Reinforcement Learning: An Introduction (MIT Press, 1998).",
              "LeCun, Y.",
              ", Bengio, Y.",
              "& Hinton, G.",
              "Deep learning.",
              "Nature 521, 436\u2013444 (2015).",
              "Article ADS CAS Google Scholar Vinyals, O.",
              "et al.",
              "StarCraft II: a new challenge for reinforcement learning.",
              "Preprint at https://arxiv.",
              "org/abs/1708.",
              "04782 (2017).",
              "Vaswani, A.",
              "et al.",
              "Attention is all you need.",
              "Adv.",
              "Neural Information Process.",
              "Syst.",
              "30, 5998\u20136008 (2017).",
              "Google Scholar Hochreiter, S.",
              "& Schmidhuber, J.",
              "Long short-term memory.",
              "Neural Comput.",
              "9, 1735\u20131780 (1997).",
              "Article CAS Google Scholar Mikolov, T.",
              ", Karafiat, M.",
              ", Burget, L.",
              ", Cernocky, J.",
              "& Khudanpur, S.",
              "Recurrent neural network based language model.",
              "INTERSPEECH-2010 1045\u20131048 (2010).",
              "Google Scholar Metz, L.",
              ", Ibarz, J.",
              ", Jaitly, N.",
              "& Davidson, J.",
              "Discrete sequential prediction of continuous actions for deep RL.",
              "Preprint at https://arxiv.",
              "org/abs/1705.",
              "05035v3 (2017).",
              "Vinyals, O.",
              ", Fortunato, M.",
              "& Jaitly, N.",
              "Pointer networks.",
              "Adv.",
              "Neural Information Process.",
              "Syst.",
              "28, 2692\u20132700 (2015).",
              "Google Scholar Mnih, V.",
              "et al.",
              "Asynchronous methods for deep reinforcement learning.",
              "Proc.",
              "Machine Learning Res.",
              "48, 1928\u20131937 (2016).",
              "Google Scholar Espeholt, L.",
              "et al.",
              "IMPALA: scalable distributed deep-RL with importance weighted actor-learner architectures.",
              "Proc.",
              "Machine Learning Res.",
              "80, 1407\u20131416 (2018).",
              "Google Scholar Wang, Z.",
              "et al.",
              "Sample efficient actor-critic with experience replay.",
              "Preprint at https://arxiv.",
              "org/abs/1611.",
              "01224v2 (2017).",
              "Sutton, R.",
              "Learning to predict by the method of temporal differences.",
              "Mach.",
              "Learn.",
              "3, 9\u201344 (1988).",
              "Google Scholar Oh, J.",
              ", Guo, Y.",
              ", Singh, S.",
              "& Lee, H.",
              "Self-Imitation Learning.",
              "Proc.",
              "Machine Learning Res.",
              "80, 3875\u20133884 (2018).",
              "Google Scholar Silver, D.",
              "et al.",
              "A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play.",
              "Science 362, 1140\u20131144 (2018).",
              "Article ADS MathSciNet CAS Google Scholar Balduzzi, D.",
              "et al.",
              "Open-ended learning in symmetric zero-sum games.",
              "Proc.",
              "Machine Learning Res.",
              "97, 434\u2013443 (2019).",
              "Google Scholar Brown, G.",
              "W.",
              "Iterative solution of games by fictitious play.",
              "Act.",
              "Anal.",
              "Prod.",
              "Alloc.",
              "13, 374\u2013376 (1951).",
              "MathSciNet MATH Google Scholar Leslie, D.",
              "S.",
              "& Collins, E.",
              "J.",
              "Generalised weakened fictitious play.",
              "Games Econ.",
              "Behav.",
              "56, 285\u2013298 (2006).",
              "Article MathSciNet Google Scholar Heinrich, J.",
              ", Lanctot, M.",
              "& Silver, D.",
              "Fictitious self-play in extensive-form games.",
              "Proc.",
              "Intl Conf.",
              "Machine Learning 32, 805\u2013813 (2015).",
              "Google Scholar Jouppi, N.",
              "P.",
              "et al.",
              "In-datacenter performance analysis of a tensor processing unit.",
              "Preprint at https://arxiv.",
              "org/abs/1704.",
              "04760v1 (2017).",
              "Elo, A.",
              "E.",
              "The Rating of Chessplayers, Past and Present (Arco, 2017).",
              "Campbell, M.",
              ", Hoane, A.",
              "& Hsu, F.",
              "Deep Blue.",
              "Artif.",
              "Intell.",
              "134, 57\u201383 (2002).",
              "Article Google Scholar Silver, D.",
              "et al.",
              "Mastering the game of Go with deep neural networks and tree search.",
              "Nature 529, 484\u2013489 (2016).",
              "Article ADS CAS Google Scholar Mnih, V.",
              "et al.",
              "Human-level control through deep reinforcement learning.",
              "Nature 518, 529\u2013533 (2015).",
              "Article ADS CAS Google Scholar Pathak, D.",
              ", Agrawal, P.",
              ", Efros, A.",
              "A.",
              "& Darrell, T.",
              "Curiosity-driven exploration by self-supervised prediction.",
              "Proc.",
              "IEEE Conf.",
              "Computer Vision Pattern Recognition Workshops 16\u201317 (IEEE, 2017).",
              "Jaderberg, M.",
              "et al.",
              "Human-level performance in 3D multiplayer games with population-based reinforcement learning.",
              "Science 364, 859\u2013865 (2019).",
              "Article ADS MathSciNet CAS Google Scholar OpenAI OpenAI Five.",
              "https://blog.",
              "openai.",
              "com/openai-five/ (2018).",
              "Buro, M.",
              "Real-time strategy games: a new AI research challenge.",
              "Intl Joint Conf.",
              "Artificial Intelligence 1534\u20131535 (2003).",
              "Samvelyan, M.",
              "et al.",
              "The StarCraft multi-agent challenge.",
              "Intl Conf.",
              "Autonomous Agents and MultiAgent Systems 2186\u20132188 (2019).",
              "Zambaldi, V.",
              "et al.",
              "Relational deep reinforcement learning.",
              "Preprint at https://arxiv.",
              "org/abs/1806.",
              "01830v2 (2018).",
              "Usunier, N.",
              ", Synnaeve, G.",
              ", Lin, Z.",
              "& Chintala, S.",
              "Episodic exploration for deep deterministic policies: an application to StarCraft micromanagement tasks.",
              "Preprint at https://arxiv.",
              "org/abs/1609.",
              "02993v3 (2017).",
              "Weber, B.",
              "G.",
              "& Mateas, M.",
              "Case-based reasoning for build order in real-time strategy games.",
              "AIIDE \u201909 Proc.",
              "5th AAAI Conf.",
              "Artificial Intelligence and Interactive Digital Entertainment 106\u2013111 (2009).",
              "Buro, M.",
              "ORTS: a hack-free RTS game environment.",
              "Intl Conf.",
              "Computers and Games 280\u2013291 (Springer, 2002).",
              "Churchill, D.",
              "SparCraft: open source StarCraft combat simulation.",
              "https://code.",
              "google.",
              "com/archive/p/sparcraft/ (2013).",
              "Weber, B.",
              "G.",
              "AIIDE 2010 StarCraft competition.",
              "Artificial Intelligence and Interactive Digital Entertainment Conf.",
              "(2010).",
              "Uriarte, A.",
              "& Ontan\u0303o\u0301n, S.",
              "Improving Monte Carlo tree search policies in StarCraft via probabilistic models learned from replay data.",
              "Artificial Intelligence and Interactive Digital Entertainment Conf.",
              "101\u2013106 (2016).",
              "Hsieh, J.",
              "-L.",
              "& Sun, C.",
              "-T.",
              "Building a player strategy model by analyzing replays of real-time strategy games.",
              "IEEE Intl Joint Conf.",
              "Neural Networks 3106\u20133111 (2008).",
              "Synnaeve, G.",
              "& Bessiere, P.",
              "A Bayesian model for plan recognition in RTS games applied to StarCraft.",
              "Artificial Intelligence and Interactive Digital Entertainment Conf.",
              "79\u201384 (2011).",
              "Shao, K.",
              ", Zhu, Y.",
              "& Zhao, D.",
              "StarCraft micromanagement with reinforcement learning and curriculum transfer learning.",
              "IEEE Trans.",
              "Emerg.",
              "Top.",
              "Comput.",
              "Intell.",
              "3, 73\u201384 (2019).",
              "Google Scholar Facebook CherryPi.",
              "https://torchcraft.",
              "github.",
              "io/TorchCraftAI/.",
              "Berkeley Overmind.",
              "https://www.",
              "icsi.",
              "berkeley.",
              "edu/icsi/news/2010/10/klein-berkeley-overmind (2010).",
              "Justesen, N.",
              "& Risi, S.",
              "Learning macromanagement in StarCraft from replays using deep learning.",
              "IEEE Conf.",
              "Computational Intelligence and Games (CIG) 162\u2013169 (2017).",
              "Synnaeve, G.",
              "et al.",
              "Forward modeling for partial observation strategy games\u2014a StarCraft defogger.",
              "Adv.",
              "Neural Information Process.",
              "Syst.",
              "31, 10738\u201310748 (2018).",
              "Google Scholar Farooq, S.",
              "S.",
              ", Oh, I.",
              "-S.",
              ", Kim, M.",
              "-J.",
              "& Kim, K.",
              "J.",
              "StarCraft AI competition report.",
              "AI Mag.",
              "37, 102\u2013107 (2016).",
              "Article Google Scholar Sun, P.",
              "et al.",
              "TStarBots: defeating the cheating level builtin AI in StarCraft II in the full game.",
              "Preprint at https://arxiv.",
              "org/abs/1809.",
              "07193v3 (2018).",
              "Schulman, J.",
              ", Wolski, F.",
              ", Dhariwal, P.",
              ", Radford, A.",
              "& Klimov, O.",
              "Proximal policy optimization algorithms. Preprint at https://arxiv.",
              "org/abs/1707.",
              "06347v2 (2017).",
              "Ibarz, B.",
              "et al.",
              "Reward learning from human preferences and demonstrations in Atari.",
              "Adv.",
              "Neural Information Process.",
              "Syst.",
              "31, 8011\u20138023 (2018).",
              "Nair, A.",
              ", McGrew, B.",
              ", Andrychowicz, M.",
              ", Zaremba, W.",
              "& Abbeel, P.",
              "Overcoming exploration in reinforcement learning with demonstrations.",
              "IEEE Intl Conf.",
              "Robotics and Automation 6292\u20136299 (2018).",
              "Christiano, P.",
              "F.",
              "et al.",
              "Deep reinforcement learning from human preferences.",
              "Adv.",
              "Neural Information Process.",
              "Syst.",
              "30, 4299\u20134307 (2017).",
              "Lanctot, M.",
              "et al.",
              "A unified game-theoretic approach to multiagent reinforcement learning.",
              "Adv.",
              "Neural Information Process.",
              "Syst.",
              "30, 4190\u20134203 (2017).",
              "Perez, E.",
              ", Strub, F.",
              ", De Vries, H.",
              ", Dumoulin, V.",
              "& Courville, A.",
              "FiLM: visual reasoning with a general conditioning layer.",
              "Preprint at https://arxiv.",
              "org/abs/1709.",
              "07871v2 (2018).",
              "He, K.",
              ", Zhang, X.",
              ", Ren, S.",
              "& Sun, J.",
              "Deep residual learning for image recognition.",
              "Proc.",
              "IEEE Conf.",
              "Computer Vision and Pattern Recognition 770\u2013778 (2016).",
              "Hinton, G.",
              ", Vinyals, O.",
              "& Dean, J.",
              "Distilling the knowledge in a neural network.",
              "Preprint at https://arxiv.",
              "org/abs/1503.",
              "02531v1 (2015).",
              "Kingma, D.",
              "P.",
              "& Ba, J.",
              "Adam: a method for stochastic optimization.",
              "Preprint at https://arxiv.",
              "org/abs/1412.",
              "6980v9 (2014).",
              "Bishop, C.",
              "M.",
              "Pattern Recognition and Machine Learning (Springer, 2006).",
              "Rusu, A.",
              "A.",
              "et al.",
              "Policy distillation.",
              "Preprint at https://arxiv.",
              "org/abs/1511.",
              "06295 (2016).",
              "Parisotto, E.",
              ", Ba, J.",
              "& Salakhutdinov, R.",
              "Actor-mimic: deep multitask and transfer reinforcement learning.",
              "Preprint at https://arxiv.",
              "org/abs/1511.",
              "06342 (2016).",
              "Precup, D.",
              ", Sutton, R.",
              "S.",
              "& Singh, S.",
              "P.",
              "Eligibility traces for off-policy policy evaluation.",
              "ICML \u201900 Proc.",
              "17th Intl Conf.",
              "Machine Learning 759\u2013766 (2016).",
              "DeepMind Research on Ladder.",
              "https://starcraft2.",
              "com/en-us/news/22933138 (2019).",
              "Vinyals, O.",
              "et al.",
              "AlphaStar: mastering the real-time strategy game StarCraft II https://deepmind.",
              "com/blog/article/alphastar-mastering-real-time-strategy-game-starcraft-ii (DeepMind, 2019).",
              "Download references We thank Blizzard for creating StarCraft and for their continued support of the research environment, and for enabling AlphaStar to participate in Battle.",
              "net.",
              "In particular, we thank A.",
              "Hudelson, C.",
              "Lee, K.",
              "Calderone, and T.",
              "Morten.",
              "We also thank StarCraft II professional players G.",
              "\u2018MaNa\u2019 Komincz and D.",
              "\u2018Kelazhur\u2019 Schwimer for their StarCraft expertise and advice.",
              "We thank A.",
              "Cain, A.",
              "Razavi, D.",
              "Toyama, D.",
              "Balduzzi, D.",
              "Fritz, E.",
              "Aygu\u0308n, F.",
              "Strub, G.",
              "Ostrovski, G.",
              "Alain, H.",
              "Tang, J.",
              "Sanchez, J.",
              "Fildes, J.",
              "Schrittwieser, J.",
              "Novosad, K.",
              "Simonyan, K.",
              "Kurach, P.",
              "Hamel, R.",
              "Barreira, S.",
              "Reed, S.",
              "Bartunov, S.",
              "Mourad, S.",
              "Gaffney, T.",
              "Hubert, the team that created PySC2 and the whole DeepMind Team, with special thanks to the research platform team, comms and events teams, for their support, ideas, and encouragement.",
              "These authors contributed equally: Oriol Vinyals, Igor Babuschkin, Wojciech M.",
              "Czarnecki, Michae\u0308l Mathieu, Andrew Dudzik, Junyoung Chung, David H.",
              "Choi, Richard Powell, Timo Ewalds, Petko Georgiev, Junhyuk Oh, Dan Horgan, Manuel Kroiss, Ivo Danihelka, Aja Huang, Laurent Sifre, Trevor Cai, John P.",
              "Agapiou, Chris Apps, David Silver DeepMind, London, UK Oriol Vinyals, Igor Babuschkin, Wojciech M.",
              "Czarnecki, Michae\u0308l Mathieu, Andrew Dudzik, Junyoung Chung, David H.",
              "Choi, Richard Powell, Timo Ewalds, Petko Georgiev, Junhyuk Oh, Dan Horgan, Manuel Kroiss, Ivo Danihelka, Aja Huang, Laurent Sifre, Trevor Cai, John P.",
              "Agapiou, Max Jaderberg, Alexander S.",
              "Vezhnevets, Re\u0301mi Leblond, Tobias Pohlen, Valentin Dalibard, David Budden, Yury Sulsky, James Molloy, Tom L.",
              "Paine, Caglar Gulcehre, Ziyu Wang, Tobias Pfaff, Yuhuai Wu, Roman Ring, Dani Yogatama, Katrina McKinney, Oliver Smith, Tom Schaul, Timothy Lillicrap, Koray Kavukcuoglu, Demis Hassabis, Chris Apps & David Silver Team Liquid, Utrecht, Netherlands Dario Wu\u0308nsch You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar O.",
              "V.",
              ", I.",
              "B.",
              ", W.",
              "M.",
              "C.",
              ", M.",
              "M.",
              ", A.",
              "D.",
              ", J.",
              "C.",
              ", D.",
              "H.",
              "C.",
              ", R.",
              "P.",
              ", T.",
              "E.",
              ", P.",
              "G.",
              ", J.",
              "O.",
              ", D.",
              "Horgan, M.",
              "K.",
              ", I.",
              "D.",
              ", A.",
              "H.",
              ", L.",
              "S.",
              ", T.",
              "C.",
              ", J.",
              "P.",
              "A.",
              ", C.",
              "A.",
              ", and D.",
              "S.",
              "contributed equally.",
              "O.",
              "V.",
              ", I.",
              "B.",
              ", W.",
              "M.",
              "C.",
              ", M.",
              "M.",
              ", A.",
              "D.",
              ", J.",
              "C.",
              ", D.",
              "H.",
              "C.",
              ", R.",
              "P.",
              ", T.",
              "E.",
              ", P.",
              "G.",
              ", J.",
              "O.",
              ", D.",
              "Horgan, M.",
              "K.",
              ", I.",
              "D.",
              ", A.",
              "H.",
              ", L.",
              "S.",
              ", T.",
              "C.",
              ", J.",
              "P.",
              "A.",
              ", C.",
              "A.",
              ", R.",
              "L.",
              ", M.",
              "J.",
              ", V.",
              "D.",
              ", Y.",
              "S.",
              ", A.",
              "S.",
              "V.",
              ", D.",
              "B.",
              ", T.",
              "L.",
              "P.",
              ", C.",
              "G.",
              ", Z.",
              "W.",
              ", T.",
              "Pfaff, T.",
              "Pohlen, Y.",
              "W.",
              ", and D.",
              "S.",
              "designed and built AlphaStar with advice from T.",
              "S.",
              "and T.",
              "L.",
              "J.",
              "M.",
              "and R.",
              "R.",
              "contributed to software engineering.",
              "D.",
              "W.",
              "and D.",
              "Y.",
              "provided expertise in the StarCraft II domain.",
              "K.",
              "K.",
              ", D.",
              "Hassabis, K.",
              "M.",
              ", O.",
              "S.",
              ", and C.",
              "A.",
              "managed the project.",
              "D.",
              "S.",
              ", W.",
              "M.",
              "C.",
              ", O.",
              "V.",
              ", J.",
              "O.",
              ", I.",
              "B.",
              ", and D.",
              "H.",
              "C.",
              "wrote the paper with contributions from M.",
              "M.",
              ", J.",
              "C.",
              ", D.",
              "Horgan, L.",
              "S.",
              ", R.",
              "L.",
              ", T.",
              "C.",
              ", T.",
              "S.",
              ", and T.",
              "L.",
              "O.",
              "V.",
              "and D.",
              "S.",
              "led the team.",
              "Correspondence to Oriol Vinyals or David Silver.",
              "M.",
              "J.",
              ", W.",
              "M.",
              "C.",
              ", O.",
              "V.",
              ", and D.",
              "S.",
              "have filed provisional patent application 62/796,567 about the contents of this manuscript.",
              "The remaining authors declare no competing interests.",
              "Publisher\u2019s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.",
              "Peer review information Nature thanks Dave Churchill, Santiago Ontanon and the other, anonymous, reviewer(s) for their contribution to the peer review of this work.",
              "Top, win probability of AlphaStar Supervised against itself, when applying various agent action rate limits.",
              "Our limit does not affect supervised performance and is acceptable when compared to humans.",
              "Bottom, distributions of APMs of AlphaStar Final (blue) and humans (red) during games on Battle.",
              "net.",
              "Dashed lines show mean values.",
              "Left, distribution of delays between when the game generates an observation and when the game executes the corresponding agent action.",
              "Right, distribution of how long agents request to wait without observing between observations.",
              "A detailed description is provided in the Supplementary Data, Detailed Architecture.",
              "Units built by Protoss AlphaStar Supervised (left) and AlphaStar Final (right) over multiple self-play games.",
              "AlphaStar Supervised can build every unit.",
              "PFSP-based training outperforms FSP under all measures considered: it has a stronger population measured by relative population performance, provides a less exploitable solution, and has better final agent performance against the corresponding league.",
              "Diagram of the training setup for the entire league.",
              "Top, visualization of all the matches played by AlphaStar Final (right) and matches against opponents above 4,500 MMR of AlphaStar Mid (left).",
              "Each Gaussian represents an opponent MMR (with uncertainty): AlphaStar won against opponents shown in green and lost to those shown in red.",
              "Blue is our MMR estimate, and black is the MMR reported by StarCraft II.",
              "The orange background is the Grandmaster league range.",
              "Bottom, win probability versus gap in MMR.",
              "The shaded grey region shows MMR model predictions when players\u2019 uncertainty is varied.",
              "The red and blue line are empirical win rates for players above 6,000 MMR and AlphaStar Final, respectively.",
              "Both human and AlphaStar win rates closely follow the MMR model.",
              "Blue means a row agent wins, red loses, and white draws.",
              "The main agents behave transitively: the more recent agents win consistently against older main agents and exploiters.",
              "Interactions between exploiters are highly non-transitive: across the full payoff, there are around 3,000,000 rock\u2013paper\u2013scissor cycles (with requirement of at least 70% win rates to form a cycle) that involve at least one exploiter, and around 200 that involve only main agents.",
              "This zipped file contains the pseudocode, StarCraft II replay files, detailed neural network architecture and raw data from the Battle.",
              "net experiment.",
              "Reprints and Permissions Vinyals, O.",
              ", Babuschkin, I.",
              ", Czarnecki, W.",
              "M.",
              "et al.",
              "Grandmaster level in StarCraft II using multi-agent reinforcement learning.",
              "Nature 575, 350\u2013354 (2019).",
              "https://doi.",
              "org/10.",
              "1038/s41586-019-1724-z Download citation Received: 30 August 2019 Accepted: 10 October 2019 Published: 30 October 2019 Issue Date: 14 November 2019 DOI: https://doi.",
              "org/10.",
              "1038/s41586-019-1724-z Anyone you share the following link with will be able to read this content: Sorry, a shareable link is not currently available for this article.",
              "Provided by the Springer Nature SharedIt content-sharing initiative By submitting a comment you agree to abide by our Terms and Community Guidelines.",
              "If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate.",
              "You have full access to this article via your institution.",
              "Advertisement Nature (Nature) ISSN 1476-4687 (online) ISSN 0028-0836 (print) \u00a9 2023 Springer Nature Limited Sign up for the Nature Briefing newsletter \u2014 what matters in science, free to your inbox daily."
            ]
          },
          {
            "title": "AlphaStar Unplugged: Large-Scale Offline Reinforcement Learning",
            "url": "https://arxiv.org/abs/2308.03526",
            "content": [
              "AlphaStar Unplugged: Large-Scale Offline Reinforcement Learning",
              "Help | Advanced Search arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.",
              "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy.",
              "arXiv is committed to these values and only works with partners that adhere to them.",
              "Have an idea for a project that will add value for arXiv's community?",
              "Learn more about arXivLabs.",
              "arXiv Operational Status Get status notifications via email or slack"
            ]
          },
          {
            "title": "DeepMind&#39;s &#39;Starcraft II&#39; AI Is Now Better Than 99.98% of Human ... - VICE",
            "url": "https://www.vice.com/en/article/vb5ny9/deepminds-starcraft-ii-ai-is-now-better-than-9998-of-human-players",
            "content": [
              "DeepMind&#39;s &#39;Starcraft II&#39; AI Is Now Better Than 99.98% of Human ... - VICE",
              "DeepMind has trained an AI agent that plays StarCraft II at the Grandmaster level\u2014better than 99.",
              "98 percent of human players, the machine-learning-focused Google spinoff announced in a new paper AlphaStar, the AI in question, achieved its Grandmaster status the old fashioned way: grinding through dozens of matches against human opponents, the paper, published on Wednesday in Nature, explains.",
              "This isn\u2019t DeepMind\u2019s first foray into designing AI to play StarCraft II.",
              "AlphaStar took on human opponents in a series of high profile games in January.",
              "AlphaStar crushed its human competition, but the AI was still operating with some restrictions\u2014it only knew how to play Protoss, one of Starcraft II\u2019s three factions, and could only play against Protoss.",
              "But now those restrictions are gone.",
              "AlphaStar can handle Zerg, Protoss, and Terran.",
              "AlphaStar worked its way up the European StarCraft II ladder on Battle.",
              "net, Blizzard\u2019s online gaming network.",
              "In a July blog post, Blizzard informed players competing in Europe that they may encounter the bot, but that it would remain anonymous during games, and allowed players to opt out of competing against AlphaStart.",
              "\u201cThe majority of players opted in,\u201d researchers noted in their article.",
              "The AI system was designed to match the physical limitations of a human opponent.",
              "AlphaStar viewed each match through what researchers called a \u201ccamera-like interface\u201d similar to how humans see the game\u2019s playing field, meaning that the AI didn\u2019t have perfect, omnipresent knowledge of the game and had to \u201cchoose\u201d where to focus its attention.",
              "Its actions per minute (APM) were also restricted, meaning it could only perform a set amount of tasks every second.",
              "AlphStar could only complete 22 non-duplicate actions in a five second window, putting it in league with human players.",
              "DeepMind also added a 110 millisecond delay between observing a frame and executing an action, which accounted for human latency.",
              "Human pros who played against the AI approved of this approach.",
              "\u201cWhile AlphaStar has excellent and precise control, it doesn\u2019t feel superhuman\u2014certainly not on a level that a human couldn\u2019t theoretically achieve,\u201d Dario \u2018TLO\u2019 Wu\u0308nsch, a Team Liquid Starcraft II pro, said in a statement.",
              "\u201cOverall, it feels very fair\u2014like it is playing a \u2018real\u2019 game of StarCraft.",
              "\u201d DeepMind spokespeople weren\u2019t immediately available to comment.",
              "AlphaStar is based on a deep learning architecture that \u201clearns\u201d to complete tasks\u2014in this case, play Starcraft II well\u2014after hoovering up a ton of data.",
              "DeepMind trained AlphaStar in phases, the researchers explain in the paper.",
              "It started by making the AI \u201cwatch\u201d 971,000 StarCraft II replays.",
              "Each replay involved players with a high Match Making Ranking (MMR)\u2014the number Blizzard assigns to a player based on their skill level.",
              "Because of this, AlphaStar was watching replays from the top 22% of StarCraft II players.",
              "After AlphStar watched those replays, DeepMind added 16,000 more replays from games with players at even higher MMRs.",
              "Then, DeepMind created a league full of AI challengers and pit AlphaStar against itself to get even better at the game.",
              "To create a diverse opponent base, the team froze instances of AlphaStar at various points in its training and entered them into the game as new opponents.",
              "Throughout this process, DeepMind peeled off instances of AlphaStar and send them to Battle.",
              "net for evaluation using anonymous accounts.",
              "The first AlphaStar entered Battle.",
              "net after watching replays, but before participating in an AI league, and played 30 games.",
              "A more developed AlphaStar version was pulled out of competition after 50 games because, the paper notes, its cover was blown.",
              "The last iteration\u2014AlphaStar Final\u2014used several fake accounts to help keep the AIs anonymous.",
              "It was this AI that achieved Grandmaster level, the highest ranking available in StarCraft II.",
              "According to StarCraft II pros, more exciting than the ranking are the ways AlphaStar Final innovated on existing tactics and strategy.",
              "\u201cIt was also exciting to see the agent develop its own strategies differently from the human players\u2014like the way AlphaStar builds more workers than its base can support early in the game in preparation for later expansion,\u201d Team Liquid player Grzegorz \u201cMaNa\u201d Komincz said in a statement.",
              "\u201cThe caps on the actions it can take and the camera view restrictions now make for compelling games\u2014even though, as a pro, I can still spot some of the system\u2019s weaknesses.\"",
              "DeepMind\u2019s researchers believe StarCraft II is a stepping stone to greater and more complex problems. AlphaStar\u2019s ability to handle a game as complicated as StarCraft II is a sign that artificial intelligence may be able to manage complex problems, such as navigating America\u2019s roads in a self-driving car.",
              "\u201cThe game\u2019s complexity is much greater than chess, because players control hundreds of units;",
              "more complex than Go, because there are 10^26 possible choices for every move;",
              "and players have less information about their opponents than in poker,\u201dDavid Silver, principal research scientist at DeepMind, said in a statement.",
              "By signing up, you agree to the Terms of Use and Privacy Policy & to receive electronic communications from Vice Media Group, which may include marketing promotions, advertisements and sponsored content."
            ]
          }
        ],
        "Computer vision has made significant progress in tasks such as face detection and recognition, object detection and segmentation, scene understanding, pose estimation, image synthesis, and more.": [
          {
            "title": "Pose Estimation: The Ultimate Overview in 2024 - viso.ai",
            "url": "https://viso.ai/deep-learning/pose-estimation-ultimate-overview/",
            "content": [
              "Pose Estimation: The Ultimate Overview in 2024 - viso.ai",
              "Train Develop Deploy Operate Data Collection Building Blocks\u200b Device Enrollment Monitoring Dashboards Video Annotation\u200b Application Editor\u200b Device Management Remote Maintenance Model Training Application Library Deployment Manager Unified Security Center AI Model Library Configuration Manager IoT Edge Gateway Privacy-preserving AI Ready to get started?",
              "Viso Suite is the all-in-one solution for teams to build, deliver, scale computer vision applications.",
              "Viso Suite is the world\u2019s only end-to-end computer vision platform.",
              "Request a demo.",
              "Pose estimation is a fundamental task in computer vision and artificial intelligence (AI) that involves detecting and tracking the position and orientation of human body parts in images or videos.",
              "This article will explore the latest advances in pose estimation algorithms and AI vision techniques, their applications and use cases, and their limitations.",
              "About us: Viso.",
              "ai provides the leading end-to-end Computer Vision Platform Viso Suite.",
              "Our solution enables organizations worldwide to build and deliver computer vision applications at scale.",
              "Get a demo for your company.",
              "Human pose estimation and tracking is a computer vision task that includes detecting, associating, and tracking semantic key points.",
              "Examples of semantic key points are \u201cright shoulders,\u201d \u201cleft knees,\u201d.",
              "Object pose estimation uses a trained model to detect and track the keypoints of objects such as cars.",
              "Examples of such key points are \u201cleft brake lights of vehicles.",
              "\u201d The performance of semantic keypoint tracking in live video footage requires high computational resources, which has been limiting the accuracy of pose estimation.",
              "With the latest advances in hardware and model efficiency, new applications with real-time requirements are becoming possible and economically feasible.",
              "Today, the most powerful image processing models are based on convolutional neural networks (CNNs).",
              "Hence, state-of-the-art methods are typically based on designing the CNN architecture tailored particularly for object or human pose inference applications.",
              "All approaches for pose estimation can be grouped into bottom-up and top-down methods.",
              "Bottom-up methods estimate each body joint first and then group them to form a unique pose.",
              "Bottom-up methods were pioneered with DeepCut (a method we will cover later in more detail).",
              "Top-down methods run a person detector first and estimate body joints within the detected bounding boxes.",
              "In traditional object detection, people are only perceived as a bounding box (a square).",
              "By performing pose detection and pose tracking, computers can develop an understanding of human body language.",
              "However, conventional pose-tracking methods are neither fast enough nor robust enough to occlusions to be viable.",
              "High-performing real-time pose detection and tracking will drive some of the biggest trends in computer vision.",
              "For example, tracking the human pose in real time will enable computers to develop a finer-grained and more natural understanding of human behavior.",
              "This will have a big impact on various fields, for example, autonomous driving, sports, healthcare, and many more.",
              "Today, the majority of self-driving car accidents are caused by \u201crobotic\u201d driving, where the self-driving vehicle conducts an allowed but unexpected stop, and a human driver crashes into the self-driving car.",
              "With real-time human pose detection and tracking, the computers are able to understand and predict pedestrian behavior much better \u2013 allowing more natural driving.",
              "Human pose estimation aims at predicting the poses of human body parts and joints in images or videos.",
              "Since pose motions are often driven by some specific human actions, knowing the body pose of a human is critical for action recognition and video understanding.",
              "2D human pose estimation is used to estimate the 2D position or spatial location of human body keypoints from visuals such as images and videos.",
              "Traditional 2D human pose estimation methods use different hand-crafted feature extraction techniques for the individual body parts.",
              "Early computer vision works described the human body as a stick figure to obtain global pose structures.",
              "However, modern deep learning based approaches have achieved major breakthroughs by improving the performance significantly for both single-person and multi-person pose estimation.",
              "Some popular 2D human pose estimation methods include OpenPose, CPN, AlphaPose, and HRNet (we will cover them and others later in this article).",
              "3D Human Pose Estimation is used to predict the locations of body joints in 3D space.",
              "Besides the 3D pose, some methods also recover 3D human mesh from images or videos.",
              "This field has attracted much interest in recent years since it is used to provide extensive 3D structure information related to the human body.",
              "It can be applied to various applications, such as 3D animation industries, virtual or augmented reality, and 3D action prediction.",
              "3D human pose estimation can be performed on monocular images or videos (normal camera feeds).",
              "Using multiple viewpoints or additional sensors (IMU or LiDAR), 3D pose estimation can be applied with information fusion techniques, which is a very challenging task.",
              "While 2D human datasets can be easily obtained, collecting accurate 3D pose image annotation is time-consuming, and manual labeling is not practical and expensive.",
              "Therefore, although 3D pose tracking has made significant advancements in recent years, especially due to the progress made in 2D human pose estimation, there are still several challenges to overcome: Model generalization, robustness to occlusion, and computation efficiency.",
              "A popular library that uses neural networks for real-time 3D human pose estimation, even for multi-person use cases, is OpenPose.",
              "In human pose estimation, the location of human body parts is used to build a human body representation (such as a body skeleton pose) from visual input data.",
              "Therefore, human body modeling is an important aspect of human pose estimation.",
              "It is used to represent features and keypoints extracted from visual input data.",
              "Typically, a model-based approach is used to describe and infer human body poses and render 2D or 3D poses.",
              "Most methods use an N-joints rigid kinematic model where a human body is represented as an entity with joints and limbs, containing body kinematic structure and body shape information.",
              "There are three types of models for human body modeling: Human pose estimation is a challenging task as the body\u2019s appearance joins changes dynamically due to diverse forms of clothes, arbitrary occlusion, occlusions due to the viewing angle, and background contexts.",
              "Pose estimation needs to be robust to challenging real-world variations such as lighting and weather.",
              "Therefore, it is challenging for image processing models to identify fine-grained joint coordinates.",
              "It is especially difficult to track small and barely visible joints.",
              "Estimating the head pose of a person is a popular computer vision problem.",
              "Head pose estimation has multiple applications, such as aiding in gaze estimation, modeling attention, fitting 3D models to video, and performing face alignment.",
              "Traditionally head pose is computed with the use of keypoints from the target face and by solving the 2D to 3D pose correspondence problem with a mean human head model.",
              "The ability to recover the 3D pose of the head is a by-product of keypoint-based facial expression analysis that is based on the extraction of 2D facial keypoints with deep learning methods.",
              "Those methods are robust to occlusions and extreme pose changes.",
              "Most state-of-the-art methods focus on human body pose detection and tracking.",
              "However, some models were developed to be used with animals and cars (object pose estimation).",
              "Animal pose estimation comes with additional challenges, such as limited labeled data (need to collect data and annotate images manually) and a large number of self-occlusions.",
              "Therefore, datasets for animals are usually small and include limited animal species.",
              "When working with limited data available and small datasets, active learning and data augmentation provide useful methods.",
              "Both techniques help to train vision algorithms more effectively and reduce the annotation work for custom AI model training.",
              "Also, estimating the pose of multiple animals is a challenging computer vision problem due to frequent interactions that cause occlusions and complicate assigning detected key points to the correct individual.",
              "Also, it is challenging to have very similar-looking animals that interact more closely than humans typically would.",
              "To address those issues, transfer learning techniques have been developed to re-apply methods from humans to animals.",
              "An example is multi-animal pose estimation and tracking with DeepLabCut, a state-of-the-art, popular open-source pose estimation toolbox for animals and humans.",
              "Read more about animal pose tracking in our article about applications of computer vision in agriculture.",
              "Multi-frame human pose estimation in complicated situations is complex and requires high computing power.",
              "While human joint detectors show good performance for static images, their performances often come short when the ML models are applied to video sequences for real-time pose tracking.",
              "Some of the biggest challenges include handling motion blur, video defocus, pose occlusions, and the inability to capture temporal dependency among video frames.",
              "Applying conventional Recurrent Neural Networks (RNN) incurs empirical difficulties in modeling spatial contexts, especially for dealing with pose occlusions.",
              "State-of-the-art multi-frame human pose estimation frameworks, such as DCPose, leverage abundant temporal cues between video frames to facilitate keypoint detection.",
              "Pose estimation utilizes pose and orientation to predict and track the location of a person or object.",
              "Accordingly, pose estimation allows programs to estimate spatial positions (\u201cposes\u201d) of a body in an image or video.",
              "In general, most pose estimators are 2 steps frameworks that detect human bounding boxes and then estimate the pose within each box.",
              "Pose estimation operates by finding key points of a person or object.",
              "Taking a person, for example, the key points would be joints like the elbow, knees, wrists, etc.",
              "There are two types of pose estimation: multi-pose and single-pose.",
              "Single-pose estimation is used to estimate the poses of a single object in a given scene, while multi-pose estimation is used when detecting poses for multiple objects.",
              "Human pose estimation on the popular MS COCO Dataset can detect 17 different keypoints (classes).",
              "Each keypoint is annotated with three numbers (x,y,v), where x and y mark the coordinates, and v indicates if the keypoint is visible.",
              "\"nose\", \"left_eye\", \"right_eye\", \"left_ear\", \"right_ear\", \"left_shoulder\", \"right_shoulder\", \"left_elbow\", \"right_elbow\", \"left_wrist\", \"right_wrist\", \"left_hip\", \"right_hip\", \"left_knee\", \"right_knee\", \"left_ankle\", \"right_ankle\" With the rapid development of deep learning solutions in recent years, deep learning has been shown to outperform classical computer vision methods in various tasks, including image segmentation or object detection.",
              "Therefore, deep learning techniques brought significant advances and performance gains in pose estimation tasks.",
              "Next, we will list and review the popular human pose detection and tracking methods.",
              "Because pose estimation is an easily applicable computer vision technique, we can implement a custom pose estimator using existing architectures.",
              "The existing architectures for getting you started with developing a custom pose estimator include: Human pose estimation has been utilized in a wide range of applications, including human-computer interaction, action recognition, motion capture, movement analysis, augmented reality, sports and fitness, and robotics.",
              "Pose estimation has applications in lots of fields, some of which are listed below.",
              "A rather obvious application of pose estimation is tracking and measuring the human activity and movement.",
              "Architectures like DensePose, PoseNet, or OpenPose are often used for activity, gesture, or gait recognition.",
              "Examples of human activity tracking via the use of pose estimation include: As of today, pose estimation interfaced with augmented and virtual reality applications gives users a better online experience.",
              "For instance, users can virtually learn how to play games like tennis via virtual tutors who are pose represented.",
              "More so, pose estimators can also be interfaced with augmented reality-based applications.",
              "For example, The United States Army experiments with augmented reality programs to be used in combat.",
              "These programs aim to help soldiers distinguish between enemies and friendly troops, as well as improve night vision.",
              "Typical use cases of pose estimators are in the application of making robots learn certain crafts.",
              "In place of manually programming robots to follow trajectories, robots can be made to learn actions and movements by following the tutor\u2019s posture, look or appearance.",
              "Other applications of pose estimation are in-game applications, where human subjects auto-generate and inject poses into the game environment for an interactive gaming experience.",
              "For instance, Microsoft\u2019s Kinect used 3D pose estimation (using IR sensor data) to track the motion of the human players and to use it to render the actions of the characters virtually into the gaming environment.",
              "Pose estimation for objects is a major trend in computer vision.",
              "Object pose estimation allows gaining a more detailed understanding of objects compared to two-dimensional bounding boxes.",
              "Until now, pose estimation is still computationally very intensive and requires expensive AI hardware (often multiple NVIDIA GPUs) that is not practical for real-world use.",
              "New technologies and methods make it possible to decrease the size of AI models, making pose estimation algorithms less \u201cheavy\u201d and much more efficient.",
              "This is the basis for the real-world implementation of human pose detection.",
              "As a result, it becomes possible to deploy pose estimation algorithms to edge devices and perform on-device machine learning (Edge AI).",
              "Edge Inference makes the technology scalable, more robust for mission-critical applications (offline capability), and private (no visuals need to be sent to the cloud).",
              "An example of a lightweight pose estimation model for Edge ML is Lightweight OpenPose.",
              "The enterprise computer vision platform Viso Suite makes it possible to rapidly build and deliver pose estimation systems at scale.",
              "The end-to-end solution is used by global leaders to implement real-world pose estimation applications using common CCTV or USB cameras with various AI hardware and the latest processors.",
              "Pose estimation is a fascinating aspect of computer vision that can be applied in multiple fields, including technology, healthcare, business, and others.",
              "Aside from its prominence in modeling human characters via Deep Neural Networks that learn various key points, it is also used for security and surveillance systems. Other popular applications of computer vision include image classification, image segmentation, face detection, and object detection.",
              "If you enjoyed reading this article, we recommend exploring the following topics: Follow us It\u2019s only a matter of time until computers will surpass human vision.",
              "However, Computer Vision projects often fail due to the pitfalls of the real-world use of Computer Vision and visual AI in general.",
              "Edge Computing moves computing from the cloud to the network edge.",
              "On-device real-time data processing enables new applications.",
              "viso.",
              "ai Product Features Industries Resources About Get expert AI news 2x a month.",
              "Subscribe to the most read Computer Vision Blog.",
              "You can unsubscribe anytime.",
              "See our privacy policy.",
              "All-in-one Computer Vision Platform for businesses to build, deploy and scale real-world applications.",
              "We\u2019re always looking to improve, so please let us know why you are not interested in using Computer Vision with Viso Suite.",
              "Find some helpful information or get in touch: > Show me all features > Show me use cases > About the company viso.",
              "ai > I have a question"
            ]
          },
          {
            "title": "Scene Understanding | Papers With Code",
            "url": "https://paperswithcode.com/task/scene-understanding",
            "content": [
              "Scene Understanding | Papers With Code",
              "444 papers with code \u2022 3 benchmarks \u2022 42 datasets Scene Understanding is something that to understand a scene.",
              "For instance, iPhone has function that help eye disabled person to take a photo by discribing what the camera sees.",
              "This is an example of Scene Understanding.",
              "PaddlePaddle/PaddleSeg \u2022 \u2022 2 Nov 2015 We show that SegNet provides good performance with competitive inference time and more efficient inference memory-wise as compared to other architectures.",
              "PaddlePaddle/PaddleDetection \u2022 \u2022 1 May 2014 We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding.",
              "alexgkendall/caffe-segnet \u2022 9 Nov 2015 Semantic segmentation is an important tool for visual scene understanding and a meaningful measure of uncertainty is essential for decision making.",
              "CSAILVision/unifiedparsing \u2022 \u2022 ECCV 2018 In this paper, we study a new task called Unified Perceptual Parsing, which requires the machine vision systems to recognize as many visual concepts as possible from a given image.",
              "qubvel/segmentation_models \u2022 \u2022 14 Jun 2017 As a result they are huge in terms of parameters and number of operations;",
              "hence slow too.",
              "nianticlabs/monodepth2 \u2022 \u2022 4 Jun 2018 Per-pixel ground-truth depth data is challenging to acquire at scale.",
              "osmr/imgclsmob \u2022 \u2022 Transactions on Intelligent Transportation Systems (T-ITS) 2017 A comprehensive set of experiments on the publicly available Cityscapes dataset demonstrates that our system achieves an accuracy that is similar to the state of the art, while being orders of magnitude faster to compute than other architectures that achieve top precision.",
              "XingangPan/SCNN \u2022 \u2022 17 Dec 2017 Although CNN has shown strong capability to extract semantics from raw pixels, its capacity to capture spatial relationships of pixels across rows and columns of an image is not fully explored.",
              "facebookresearch/habitat-api \u2022 \u2022 ICLR 2020 We leverage this scaling to train an agent for 2.",
              "5 Billion steps of experience (the equivalent of 80 years of human experience) -- over 6 months of GPU-time training in under 3 days of wall-clock time with 64 GPUs.",
              "Nguyendat-bit/U-net \u2022 \u2022 1 Apr 2019 Scene understanding of high resolution aerial images is of great importance for the task of automated monitoring in various remote sensing applications."
            ]
          },
          {
            "title": "Object Pose Estimation using Mid-level Visual Representations",
            "url": "https://arxiv.org/abs/2203.01449",
            "content": [
              "Object Pose Estimation using Mid-level Visual Representations",
              "Help | Advanced Search arXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.",
              "Both individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy.",
              "arXiv is committed to these values and only works with partners that adhere to them.",
              "Have an idea for a project that will add value for arXiv's community?",
              "Learn more about arXivLabs.",
              "arXiv Operational Status Get status notifications via email or slack"
            ]
          }
        ],
        "Computer vision has enabled many applications such as face unlock, augmented reality, self-driving cars, medical imaging, and more.": [
          {
            "title": "Navigational technology used in self-driving cars aids brain surgery ...",
            "url": "https://hub.jhu.edu/2023/08/31/brain-surgery-navigation-visualization-endoscope/",
            "content": [
              "Navigational technology used in self-driving cars aids brain surgery ...",
              "By Jaimie Patterson Accessing the brain for neurosurgery involves drilling and cutting that can cause deep-brain anatomy to shift or become distorted.",
              "This can create discrepancies between pre-operative imaging and the actual state of the brain during a procedure.",
              "Current surgical navigation systems may assist in providing live guidance, but typically use pins and clamps to hold a patient's head firmly in place, which carries the risk of complications and can prolong recovery time.",
              "A team of researchers at the Imaging for Surgery, Therapy, and Radiology (I-STAR) Labs at Johns Hopkins University is working on a less invasive solution that doesn't require additional equipment or expose patients to the extra radiation or long scan times typically associated with live imaging.",
              "They have partnered with medical device company Medtronic and the National Institutes of Health to develop a real-time guidance system that uses an endoscope, a piece of equipment already commonly employed in neurosurgeries.",
              "Their work is described in in IEEE Transactions on Medical Robotics and Bionics.",
              "\"Our study demonstrates the superiority of this real-time 3D navigation method over current visualization techniques,\" says Prasad Vagdargi, a doctoral candidate at the I-STAR Labs and primary author of the study.",
              "Vagdargi is advised by Jeffrey Siewerdsen, professor of biomedical engineering with a joint appointment in the Department of Computer Science, and Gregory Hager, professor of computer science.",
              "The team's surgical guidance method builds on an advanced computer vision technique called simultaneous localization and mapping, or SLAM, which has also been used for navigation in self-driving cars.",
              "After calibrating an endoscopic video feed, the team's SLAM algorithm tracks important visual details in each frame and uses those details to determine where the endoscope camera is and how it's positioned.",
              "The algorithm then transforms those details into a 3D model of the object\u2014in this case, the inside of a patient's skull.",
              "This model is then overlaid with the real-world video feed to visualize targeted structures on-screen in real time.",
              "\"Think of it as a dynamic 3D map of a patient's brain that you can use to track and match deep brain deformation with preoperative imaging,\" Vagdargi says.",
              "\"Combining this map with an augmented reality overlay on the endoscopic video will help surgeons to visualize targets and critical anatomy well beyond the surface of the brain.\"",
              "The researchers have coined the term \"augmented endoscopy\" for this highly accurate, state-of-the-art method of live surgical visualization.",
              "Through a series of preclinical experiments, they demonstrated that this method is more than 16 times faster than previous computer vision techniques while still maintaining submillimeter accuracy.",
              "The team predicts that the improved accuracy afforded by augmented endoscopy may lead to reduced complications, shorter operation times, and therefore increased surgical efficiency\u2014not only in neurosurgeries but also in other endoscopic procedures across medical disciplines.",
              "The research team is currently collaborating with neurosurgeons at the Johns Hopkins Hospital in a clinical study with the goal of refining and validating their method for use in real operating rooms. The researchers are also expanding their approach by applying artificial intelligence and machine learning methods to further improve the speed and precision of future iterations of their algorithm.",
              "\"We believe our findings are very important and feel that augmented endoscopy is a technology whose time has now come,\" says Vagdargi.",
              "Study co-authors include colleagues in the Department of Biomedical Engineering, the Department of Computer Science, and the Department of Neurology and Neurosurgery at the Johns Hopkins Hospital, as well as industry collaborators at Medtronic.",
              "Posted in Health, Science+Technology Tagged neuroscience, biomedical engineering, computer science, artificial intelligence"
            ]
          },
          {
            "title": "Unlocking the Potential of Computer Vision: From Self-Driving Cars to ...",
            "url": "https://ensun.io/en/blog/computer-vision-techniques",
            "content": [
              "Unlocking the Potential of Computer Vision: From Self-Driving Cars to ...",
              "EN EN Digitalization by Isabelle Nentwich Jan 26, 2023 2 Min.",
              "Computer vision is a rapidly growing field that deals with the development of algorithms, models, and systems to interpret and understand visual information from the world around us.",
              "Whether it's recognizing faces in photos, tracking objects in videos, or even driving cars without human intervention, computer vision technology is making it possible to process and understand visual data like never before.",
              "Join us as we explore the latest developments and applications of computer vision and discover how this technology is changing the way we see and interact with the world.",
              "Share on 'Computer vision object tracking' is used in surveillance, autonomous vehicles, augmented reality, sports analysis, and more.",
              "It can detect and track objects in real-time, allowing for improved security, navigation, and decision making.",
              "It is also used in sports analysis to track player movements, to aid in training and performance evaluation.",
              "Computer vision in drones is used for tasks such as navigation, object detection, tracking, and mapping.",
              "It enables drones to navigate, identify and track objects, and create detailed maps of environments.",
              "It is used in agriculture, construction, and delivery services for crop monitoring, surveying, and package delivery.",
              "Computer vision and machine learning are closely related fields, computer vision provides the raw visual data while machine learning algorithms are used to make sense of the data.",
              "This combination is used to train models to recognize objects, identify patterns, and make predictions.",
              "It is used in a wide range of applications such as image and facial recognition, self-driving cars, and medical imaging analysis.",
              "Computer vision in augmented reality (AR) is used to track and interpret the user's environment, and to overlay digital content on it.",
              "It enables AR applications to register virtual objects with real-world environments, to track the user's head and hand movements and to adjust the virtual content accordingly.",
              "It is used in gaming, education, e-commerce and many other industries, to offer an immersive and interactive experience.",
              "Anomaly detection using computer vision refers to the process of identifying unusual or abnormal patterns, behaviors or events in visual data.",
              "It is used in various industries such as manufacturing, surveillance, and healthcare to detect and diagnose problems or detect unexpected events such as equipment failure or security breaches.",
              "These systems can be trained to recognize anomalies in images, videos or live streams, making it a powerful tool for monitoring and maintaining safety and security.",
              "Quickscout Start scouting!",
              "About Isabelle Nentwich Content-Marketing at ensun Share on DeepTech Feb 17, 2023 3 Min.",
              "DeepTech Jan 24, 2023 2 Min.",
              "Solution Ressources About Us copyright \u00a9 2023 ensun GmbH \u2022 Martinshardt 19 \u2022 57074 Siegen \u2022 Germany designed and coded by STEILAUFWAERTS No matter what you are looking for.",
              "Our scouting intelligence will find the right solution."
            ]
          },
          {
            "title": "8 Real-World Applications of Computer Vision in 2023 - Augmented Startups",
            "url": "https://www.augmentedstartups.com/blog/8-real-world-applications-of-computer-vision-a-comprehensive-guide",
            "content": [
              "8 Real-World Applications of Computer Vision in 2023 - Augmented Startups",
              "Computer vision is a subset of artificial intelligence that enables computers to interpret and understand the visual world.",
              "It's a technology that has come a long way in the past decade, and it's now used in a wide range of applications, from facial recognition to self-driving cars.",
              "In this article, we'll explore eight real-world applications of computer vision.",
              "Facial recognition is one of the most well-known applications of computer vision.",
              "It's used in security systems to identify individuals and grant them access to restricted areas.",
              "Facial recognition is also used in law enforcement to help identify suspects and missing persons.",
              "Facial recognition technology works by analyzing features such as the distance between the eyes, the shape of the jawline, and the position of the nose.",
              "Object detection and tracking is another popular application of computer vision.",
              "It's used in surveillance systems to detect and track objects such as cars and people.",
              "Object detection and tracking technology can also be used in retail stores to track customers and analyze their behavior.",
              "This technology works by using cameras to capture images of objects and then using algorithms to analyze the images and identify the objects.",
              "Autonomous vehicles, also known as self-driving cars, are a rapidly growing area of research and development.",
              "Computer vision plays a crucial role in enabling autonomous vehicles to navigate and respond to their surroundings.",
              "Autonomous vehicles use a combination of cameras, sensors, and GPS to detect and interpret the environment around them.",
              "Medical imaging is another area where computer vision is making a big impact.",
              "Computer vision technology can be used to analyze medical images such as X-rays and MRIs, allowing doctors to detect and diagnose conditions more accurately.",
              "Computer vision is also used in the development of prosthetics and other medical devices.",
              "Augmented reality is a technology that overlays digital information on the physical world.",
              "Computer vision plays a key role in enabling augmented reality applications to recognize and respond to the environment.",
              "Augmented reality is used in a wide range of applications, from gaming to advertising.",
              "Quality control and inspection is another area where computer vision is making a big impact.",
              "Computer vision technology can be used to detect defects in manufacturing processes and ensure that products meet quality standards.",
              "This technology is used in industries such as automotive, aerospace, and electronics.",
              "Sports analytics is an area where computer vision is becoming increasingly important.",
              "Computer vision technology can be used to track player movements and analyze their performance.",
              "This technology is used in sports such as basketball, soccer, and football.",
              "In agriculture, computer vision is being used to improve crop yields and reduce waste.",
              "One application of computer vision in agriculture is the use of drones equipped with computer vision technology to monitor crops and identify potential issues, such as pest infestations and nutrient deficiencies.",
              "Computer vision is also being used to develop new agricultural technologies, such as autonomous tractors and robotic harvesters.",
              "Computer vision is a rapidly growing field that has many real-world applications.",
              "From facial recognition to autonomous vehicles, computer vision is making a big impact in a wide range of industries.",
              "As technology continues to develop, we can expect to see even more exciting applications of computer vision in the future.",
              "Ready to up your computer vision game?",
              "Are you ready to harness the power of YOLO-NAS in your projects?",
              "Don't miss out on our upcoming YOLOv8 course, where we'll show you how to easily switch the model to YOLO-NAS using our Modular AS-One library.",
              "The course will also incorporate training so that you can maximize the benefits of this groundbreaking model.",
              "Sign up HERE to get notified when the course is available: https://www.",
              "augmentedstartups.",
              "com/YOLO+SignUp.",
              "Don't miss this opportunity to stay ahead of the curve and elevate your object detection skills!",
              "We are planning on launching this within weeks, instead of months because of AS-One, so get ready to elevate your skills and stay ahead of the curve!",
              "We hate SPAM.",
              "We will never sell your information, for any reason.",
              "YOLO-NAS Nano YOLO-NAS is the State-of-the-Art Object Detection Model Build 10+ YOLONAS + v8 Apps.",
              "Get Started in AI Access your free OpenCV and Foundations in AI Courses Recent Posts Follow Us \ud83d\ude80 Master the Fundamentals of AI & Computer Vision in 2 Weeks: Your FREE Starter Kit Awaits!",
              "We will never spam you!",
              "GDPR Compliant.",
              "Get started today before this once in a lifetime opportunity expires."
            ]
          }
        ],
        "Natural language processing has made progress in tasks such as machine translation, sentiment analysis, question answering, and text summarization.": [
          {
            "title": "Tracking Progress in Natural Language Processing | NLP-progress",
            "url": "http://nlpprogress.com/",
            "content": [
              "Tracking Progress in Natural Language Processing | NLP-progress",
              " For more tasks, datasets and results in Chinese, check out the Chinese NLP website.",
              "This document aims to track the progress in Natural Language Processing (NLP) and give an overview of the state-of-the-art (SOTA) across the most common NLP tasks and their corresponding datasets.",
              "It aims to cover both traditional and core NLP tasks such as dependency parsing and part-of-speech tagging as well as more recent ones such as reading comprehension and natural language inference.",
              "The main objective is to provide the reader with a quick overview of benchmark datasets and the state-of-the-art for their task of interest, which serves as a stepping stone for further research.",
              "To this end, if there is a place where results for a task are already published and regularly maintained, such as a public leaderboard, the reader will be pointed there.",
              "If you want to find this document again in the future, just go to nlpprogress.",
              "com or nlpsota.",
              "com in your browser.",
              "Results Results reported in published papers are preferred;",
              "an exception may be made for influential preprints.",
              "Datasets Datasets should have been used for evaluation in at least one published paper besides the one that introduced the dataset.",
              "Code We recommend to add a link to an implementation if available.",
              "You can add a Code column (see below) to the table if it does not exist.",
              "In the Code column, indicate an official implementation with Official.",
              "If an unofficial implementation is available, use Link (see below).",
              "If no implementation is available, you can leave the cell empty.",
              "If you would like to add a new result, you can just click on the small edit button in the top-right corner of the file for the respective task (see below).",
              "This allows you to edit the file in Markdown.",
              "Simply add a row to the corresponding table in the same format.",
              "Make sure that the table stays sorted (with the best result on top).",
              "After you\u2019ve made your change, make sure that the table still looks ok by clicking on the \u201cPreview changes\u201d tab at the top of the page.",
              "If everything looks good, go to the bottom of the page, where you see the below form.",
              "Add a name for your proposed change, an optional description, indicate that you would like to \u201cCreate a new branch for this commit and start a pull request\u201d, and click on \u201cPropose file change\u201d.",
              "For adding a new dataset or task, you can also follow the steps above.",
              "Alternatively, you can fork the repository.",
              "In both cases, follow the steps below: These are tasks and datasets that are still missing: You can extract all the data into a structured, machine-readable JSON format with parsed tasks, descriptions and SOTA tables.",
              "The instructions are in structured/README.",
              "md.",
              "Instructions for building the website locally using Jekyll can be found here.",
              "NLP-progress maintained by sebastianruder Published with GitHub Pages"
            ]
          },
          {
            "title": "Natural language processing: state of the art, current trends and ...",
            "url": "https://link.springer.com/article/10.1007/s11042-022-13428-4",
            "content": [
              "Natural language processing: state of the art, current trends and ...",
              " 133k Accesses 271 Citations 34 Altmetric Explore all metrics This article has been updated Natural language processing (NLP) has recently gained much attention for representing and analyzing human language computationally.",
              "It has spread its applications in various fields such as machine translation, email spam detection, information extraction, summarization, medical, and question answering etc.",
              "In this paper, we first distinguish four phases by discussing different levels of NLP and components of Natural Language Generation followed by presenting the history and evolution of NLP.",
              "We then discuss in detail the state of the art presenting the various applications of NLP, current trends, and challenges.",
              "Finally, we present a discussion on some available datasets, models, and evaluation metrics in NLP.",
              "Lei Wang, Chen Ma, .",
              ".",
              ".",
              "Jirong Wen Avoid common mistakes on your manuscript.",
              "A language can be defined as a set of rules or set of symbols where symbols are combined and used for conveying information or broadcasting the information.",
              "Since all the users may not be well-versed in machine specific language, Natural Language Processing (NLP) caters those users who do not have enough time to learn new languages or get perfection in it.",
              "In fact, NLP is a tract of Artificial Intelligence and Linguistics, devoted to make computers understand the statements or words written in human languages.",
              "It came into existence to ease the user\u2019s work and to satisfy the wish to communicate with the computer in natural language, and can be classified into two parts i.",
              "e. Natural Language Understanding or Linguistics and Natural Language Generation which evolves the task to understand and generate the text.",
              "Linguistics is the science of language which includes Phonology that refers to sound, Morphology word formation, Syntax sentence structure, Semantics syntax and Pragmatics which refers to understanding.",
              "Noah Chomsky, one of the first linguists of twelfth century that started syntactic theories, marked a unique position in the field of theoretical linguistics because he revolutionized the area of syntax (Chomsky, 1965) [23].",
              "Further, Natural Language Generation (NLG) is the process of producing phrases, sentences and paragraphs that are meaningful from an internal representation.",
              "The first objective of this paper is to give insights of the various important terminologies of NLP and NLG.",
              "In the existing literature, most of the work in NLP is conducted by computer scientists while various other professionals have also shown interest such as linguistics, psychologists, and philosophers etc.",
              "One of the most interesting aspects of NLP is that it adds up to the knowledge of human language.",
              "The field of NLP is related with different theories and techniques that deal with the problem of natural language of communicating with the computers.",
              "Few of the researched tasks of NLP are Automatic Summarization (Automatic summarization produces an understandable summary of a set of text and provides summaries or detailed information of text of a known type), Co-Reference Resolution (Co-reference resolution refers to a sentence or larger set of text that determines all words which refer to the same object), Discourse Analysis (Discourse analysis refers to the task of identifying the discourse structure of connected text i.",
              "e. the study of text in relation to social context),Machine Translation (Machine translation refers to automatic translation of text from one language to another),Morphological Segmentation (Morphological segmentation refers to breaking words into individual meaning-bearing morphemes), Named Entity Recognition (Named entity recognition (NER) is used for information extraction to recognized name entities and then classify them to different classes), Optical Character Recognition (Optical character recognition (OCR) is used for automatic text recognition by translating printed and handwritten text into machine-readable format), Part Of Speech Tagging (Part of speech tagging describes a sentence, determines the part of speech for each word) etc.",
              "Some of these tasks have direct real-world applications such as Machine translation, Named entity recognition, Optical character recognition etc.",
              "Though NLP tasks are obviously very closely interwoven but they are used frequently, for convenience.",
              "Some of the tasks such as automatic summarization, co-reference analysis etc.",
              "act as subtasks that are used in solving larger tasks.",
              "Nowadays NLP is in the talks because of various applications and recent developments although in the late 1940s the term wasn\u2019t even in existence.",
              "So, it will be interesting to know about the history of NLP, the progress so far has been made and some of the ongoing projects by making use of NLP.",
              "The second objective of this paper focus on these aspects.",
              "The third objective of this paper is on datasets, approaches, evaluation metrics and involved challenges in NLP.",
              "The rest of this paper is organized as follows.",
              "Section 2 deals with the first objective mentioning the various important terminologies of NLP and NLG.",
              "Section 3 deals with the history of NLP, applications of NLP and a walkthrough of the recent developments.",
              "Datasets used in NLP and various approaches are presented in Section 4, and Section 5 is written on evaluation metrics and challenges involved in NLP.",
              "Finally, a conclusion is presented in Section 6.",
              "NLP can be classified into two parts i.",
              "e., Natural Language Understanding and Natural Language Generation which evolves the task to understand and generate the text.",
              "Figure 1 presents the broad classification of NLP.",
              "The objective of this section is to discuss the Natural Language Understanding (Linguistic) (NLU) and the Natural Language Generation (NLG).",
              "Broad classification of NLP NLU enables machines to understand natural language and analyze it by extracting concepts, entities, emotion, keywords etc.",
              "It is used in customer care applications to understand the problems reported by customers either verbally or in writing.",
              "Linguistics is the science which involves the meaning of language, language context and various forms of the language.",
              "So, it is important to understand various important terminologies of NLP and different levels of NLP.",
              "We next discuss some of the commonly used terminologies in different levels of NLP.",
              "Phonology Phonology is the part of Linguistics which refers to the systematic arrangement of sound.",
              "The term phonology comes from Ancient Greek in which the term phono means voice or sound and the suffix \u2013logy refers to word or speech.",
              "In 1993 Nikolai Trubetzkoy stated that Phonology is \u201cthe study of sound pertaining to the system of language\u201d whereas Lass1998 [66]wrote that phonology refers broadly with the sounds of language, concerned with sub-discipline of linguistics, behavior and organization of sounds.",
              "Phonology includes semantic use of sound to encode meaning of any Human language.",
              "Morphology The different parts of the word represent the smallest units of meaning known as Morphemes.",
              "Morphology which comprises Nature of words, are initiated by morphemes.",
              "An example of Morpheme could be, the word precancellation can be morphologically scrutinized into three separate morphemes: the prefix pre, the root cancella, and the suffix -tion.",
              "The interpretation of morphemes stays the same across all the words, just to understand the meaning humans can break any unknown word into morphemes.",
              "For example, adding the suffix \u2013ed to a verb, conveys that the action of the verb took place in the past.",
              "The words that cannot be divided and have meaning by themselves are called Lexical morpheme (e.",
              "g.: table, chair).",
              "The words (e.",
              "g. -ed, \u2212ing, \u2212est, \u2212ly, \u2212ful) that are combined with the lexical morpheme are known as Grammatical morphemes (eg.",
              "Worked, Consulting, Smallest, Likely, Use).",
              "The Grammatical morphemes that occur in combination called bound morphemes (eg.",
              "-ed, \u2212ing) Bound morphemes can be divided into inflectional morphemes and derivational morphemes.",
              "Adding Inflectional morphemes to a word changes the different grammatical categories such as tense, gender, person, mood, aspect, definiteness and animacy.",
              "For example, addition of inflectional morphemes \u2013ed changes the root park to parked.",
              "Derivational morphemes change the semantic meaning of the word when it is combined with that word.",
              "For example, in the word normalize, the addition of the bound morpheme \u2013ize to the root normal changes the word from an adjective (normal) to a verb (normalize).",
              "Lexical In Lexical, humans, as well as NLP systems, interpret the meaning of individual words.",
              "Sundry types of processing bestow to word-level understanding \u2013 the first of these being a part-of-speech tag to each word.",
              "In this processing, words that can act as more than one part-of-speech are assigned the most probable part-of-speech tag based on the context in which they occur.",
              "At the lexical level, Semantic representations can be replaced by the words that have one meaning.",
              "In fact, in the NLP system the nature of the representation varies according to the semantic theory deployed.",
              "Therefore, at lexical level, analysis of structure of words is performed with respect to their lexical meaning and PoS.",
              "In this analysis, text is divided into paragraphs, sentences, and words.",
              "Words that can be associated with more than one PoS are aligned with the most likely PoS tag based on the context in which they occur.",
              "At lexical level, semantic representation can also be replaced by assigning the correct POS tag which improves the understanding of the intended meaning of a sentence.",
              "It is used for cleaning and feature extraction using various techniques such as removal of stop words, stemming, lemmatization etc.",
              "Stop words such as \u2018in\u2019, \u2018the\u2019, \u2018and\u2019 etc.",
              "are removed as they don\u2019t contribute to any meaningful interpretation and their frequency is also high which may affect the computation time.",
              "Stemming is used to stem the words of the text by removing the suffix of a word to obtain its root form.",
              "For example: consulting and consultant words are converted to the word consult after stemming, using word gets converted to us and driver is reduced to driv.",
              "Lemmatization does not remove the suffix of a word;",
              "in fact, it results in the source word with the use of a vocabulary.",
              "For example, in case of token drived, stemming results in \u201cdriv\u201d, whereas lemmatization attempts to return the correct basic form either drive or drived depending on the context it is used.",
              "Syntactic After PoS tagging done at lexical level, words are grouped to phrases and phrases are grouped to form clauses and then phrases are combined to sentences at syntactic level.",
              "It emphasizes the correct formation of a sentence by analyzing the grammatical structure of the sentence.",
              "The output of this level is a sentence that reveals structural dependency between words.",
              "It is also known as parsing which uncovers the phrases that convey more meaning in comparison to the meaning of individual words.",
              "Syntactic level examines word order, stop-words, morphology and PoS of words which lexical level does not consider.",
              "Changing word order will change the dependency among words and may also affect the comprehension of sentences.",
              "For example, in the sentences \u201cram beats shyam in a competition\u201d and \u201cshyam beats ram in a competition\u201d, only syntax is different but convey different meanings [139].",
              "It retains the stopwords as removal of them changes the meaning of the sentence.",
              "It doesn\u2019t support lemmatization and stemming because converting words to its basic form changes the grammar of the sentence.",
              "It focuses on identification on correct PoS of sentences.",
              "For example: in the sentence \u201cfrowns on his face\u201d, \u201cfrowns\u201d is a noun whereas it is a verb in the sentence \u201che frowns\u201d.",
              "Semantic On a semantic level, the most important task is to determine the proper meaning of a sentence.",
              "To understand the meaning of a sentence, human beings rely on the knowledge about language and the concepts present in that sentence, but machines can\u2019t count on these techniques.",
              "Semantic processing determines the possible meanings of a sentence by processing its logical structure to recognize the most relevant words to understand the interactions among words or different concepts in the sentence.",
              "For example, it understands that a sentence is about \u201cmovies\u201d even if it doesn\u2019t comprise actual words, but it contains related concepts such as \u201cactor\u201d, \u201cactress\u201d, \u201cdialogue\u201d or \u201cscript\u201d.",
              "This level of processing also incorporates the semantic disambiguation of words with multiple senses (Elizabeth D.",
              "Liddy, 2001) [68].",
              "For example, the word \u201cbark\u201d as a noun can mean either as a sound that a dog makes or outer covering of the tree.",
              "The semantic level examines words for their dictionary interpretation or interpretation is derived from the context of the sentence.",
              "For example: the sentence \u201cKrishna is good and noble.",
              "\u201d This sentence is either talking about Lord Krishna or about a person \u201cKrishna\u201d.",
              "That is why, to get the proper meaning of the sentence, the appropriate interpretation is considered by looking at the rest of the sentence [44].",
              "Discourse While syntax and semantics level deal with sentence-length units, the discourse level of NLP deals with more than one sentence.",
              "It deals with the analysis of logical structure by making connections among words and sentences that ensure its coherence.",
              "It focuses on the properties of the text that convey meaning by interpreting the relations between sentences and uncovering linguistic structures from texts at several levels (Liddy,2001) [68].",
              "The two of the most common levels are: Anaphora Resolution and Coreference Resolution.",
              "Anaphora resolution is achieved by recognizing the entity referenced by an anaphor to resolve the references used within the text with the same sense.",
              "For example, (i) Ram topped in the class.",
              "(ii) He was intelligent.",
              "Here i) and ii) together form a discourse.",
              "Human beings can quickly understand that the pronoun \u201che\u201d in (ii) refers to \u201cRam\u201d in (i).",
              "The interpretation of \u201cHe\u201d depends on another word \u201cRam\u201d presented earlier in the text.",
              "Without determining the relationship between these two structures, it would not be possible to decide why Ram topped the class and who was intelligent.",
              "Coreference resolution is achieved by finding all expressions that refer to the same entity in a text.",
              "It is an important step in various NLP applications that involve high-level NLP tasks such as document summarization, information extraction etc.",
              "In fact, anaphora is encoded through one of the processes called co-reference.",
              "Pragmatic Pragmatic level focuses on the knowledge or content that comes from the outside the content of the document.",
              "It deals with what speaker implies and what listener infers.",
              "In fact, it analyzes the sentences that are not directly spoken.",
              "Real-world knowledge is used to understand what is being talked about in the text.",
              "By analyzing the context, meaningful representation of the text is derived.",
              "When a sentence is not specific and the context does not provide any specific information about that sentence, Pragmatic ambiguity arises (Walton, 1996) [143].",
              "Pragmatic ambiguity occurs when different persons derive different interpretations of the text, depending on the context of the text.",
              "The context of a text may include the references of other sentences of the same document, which influence the understanding of the text and the background knowledge of the reader or speaker, which gives a meaning to the concepts expressed in that text.",
              "Semantic analysis focuses on literal meaning of the words, but pragmatic analysis focuses on the inferred meaning that the readers perceive based on their background knowledge.",
              "For example, the sentence \u201cDo you know what time is it?",
              "\u201d is interpreted to \u201cAsking for the current time\u201d in semantic analysis whereas in pragmatic analysis, the same sentence may refer to \u201cexpressing resentment to someone who missed the due time\u201d in pragmatic analysis.",
              "Thus, semantic analysis is the study of the relationship between various linguistic utterances and their meanings, but pragmatic analysis is the study of context which influences our understanding of linguistic expressions.",
              "Pragmatic analysis helps users to uncover the intended meaning of the text by applying contextual background knowledge.",
              "The goal of NLP is to accommodate one or more specialties of an algorithm or system.",
              "The metric of NLP assess on an algorithmic system allows for the integration of language understanding and language generation.",
              "It is even used in multilingual event detection.",
              "Rospocher et al.",
              "[112] purposed a novel modular system for cross-lingual event extraction for English, Dutch, and Italian Texts by using different pipelines for different languages.",
              "The system incorporates a modular set of foremost multilingual NLP tools.",
              "The pipeline integrates modules for basic NLP processing as well as more advanced tasks such as cross-lingual named entity linking, semantic role labeling and time normalization.",
              "Thus, the cross-lingual framework allows for the interpretation of events, participants, locations, and time, as well as the relations between them.",
              "Output of these individual pipelines is intended to be used as input for a system that obtains event centric knowledge graphs.",
              "All modules take standard input, to do some annotation, and produce standard output which in turn becomes the input for the next module pipelines.",
              "Their pipelines are built as a data centric architecture so that modules can be adapted and replaced.",
              "Furthermore, modular architecture allows for different configurations and for dynamic distribution.",
              "Ambiguity is one of the major problems of natural language which occurs when one sentence can lead to different interpretations.",
              "This is usually faced in syntactic, semantic, and lexical levels.",
              "In case of syntactic level ambiguity, one sentence can be parsed into multiple syntactical forms. Semantic ambiguity occurs when the meaning of words can be misinterpreted.",
              "Lexical level ambiguity refers to ambiguity of a single word that can have multiple assertions.",
              "Each of these levels can produce ambiguities that can be solved by the knowledge of the complete sentence.",
              "The ambiguity can be solved by various methods such as Minimizing Ambiguity, Preserving Ambiguity, Interactive Disambiguation and Weighting Ambiguity [125].",
              "Some of the methods proposed by researchers to remove ambiguity is preserving ambiguity, e.",
              "g. (Shemtov 1997;",
              "Emele & Dorna 1998;",
              "Knight & Langkilde 2000;",
              "Tong Gao et al.",
              "2015, Umber & Bajwa 2011) [39, 46, 65, 125, 139].",
              "Their objectives are closely in line with removal or minimizing ambiguity.",
              "They cover a wide range of ambiguities and there is a statistical element implicit in their approach.",
              "Natural Language Generation (NLG) is the process of producing phrases, sentences and paragraphs that are meaningful from an internal representation.",
              "It is a part of Natural Language Processing and happens in four phases: identifying the goals, planning on how goals may be achieved by evaluating the situation and available communicative sources and realizing the plans as a text (Fig.",
              "2).",
              "It is opposite to Understanding.",
              "Speaker and Generator Components of NLG To generate a text, we need to have a speaker or an application and a generator or a program that renders the application\u2019s intentions into a fluent phrase relevant to the situation.",
              "Components and Levels of Representation The process of language generation involves the following interweaved tasks.",
              "Content selection: Information should be selected and included in the set.",
              "Depending on how this information is parsed into representational units, parts of the units may have to be removed while some others may be added by default.",
              "Textual Organization: The information must be textually organized according to the grammar, it must be ordered both sequentially and in terms of linguistic relations like modifications.",
              "Linguistic Resources: To support the information\u2019s realization, linguistic resources must be chosen.",
              "In the end these resources will come down to choices of particular words, idioms, syntactic constructs etc.",
              "Realization: The selected and organized resources must be realized as an actual text or voice output.",
              "Application or Speaker This is only for maintaining the model of the situation.",
              "Here the speaker just initiates the process doesn\u2019t take part in the language generation.",
              "It stores the history, structures the content that is potentially relevant and deploys a representation of what it knows.",
              "All these forms the situation, while selecting subset of propositions that speaker has.",
              "The only requirement is the speaker must make sense of the situation [91].",
              "In the late 1940s the term NLP wasn\u2019t in existence, but the work regarding machine translation (MT) had started.",
              "In fact, Research in this period was not completely localized.",
              "Russian and English were the dominant languages for MT (Andreev,1967) [4].",
              "In fact, MT/NLP research almost died in 1966 according to the ALPAC report, which concluded that MT is going nowhere.",
              "But later, some MT production systems were providing output to their customers (Hutchins, 1986) [60].",
              "By this time, work on the use of computers for literary and linguistic studies had also started.",
              "As early as 1960, signature work influenced by AI began, with the BASEBALL Q-A systems (Green et al.",
              ", 1961) [51].",
              "LUNAR (Woods,1978) [152] and Winograd SHRDLU were natural successors of these systems, but they were seen as stepped-up sophistication, in terms of their linguistic and their task processing capabilities.",
              "There was a widespread belief that progress could only be made on the two sides, one is ARPA Speech Understanding Research (SUR) project (Lea, 1980) and other in some major system developments projects building database front ends.",
              "The front-end projects (Hendrix et al.",
              ", 1978) [55] were intended to go beyond LUNAR in interfacing the large databases.",
              "In early 1980s computational grammar theory became a very active area of research linked with logics for meaning and knowledge\u2019s ability to deal with the user\u2019s beliefs and intentions and with functions like emphasis and themes.",
              "By the end of the decade the powerful general purpose sentence processors like SRI\u2019s Core Language Engine (Alshawi,1992) [2] and Discourse Representation Theory (Kamp and Reyle,1993) [62] offered a means of tackling more extended discourse within the grammatico-logical framework.",
              "This period was one of the growing communities.",
              "Practical resources, grammars, and tools and parsers became available (for example: Alvey Natural Language Tools) (Briscoe et al.",
              ", 1987) [18].",
              "The (D)ARPA speech recognition and message understanding (information extraction) conferences were not only for the tasks they addressed but for the emphasis on heavy evaluation, starting a trend that became a major feature in 1990s (Young and Chase, 1998;",
              "Sundheim and Chinchor,1993) [131, 157].",
              "Work on user modeling (Wahlster and Kobsa, 1989) [142] was one strand in a research paper.",
              "Cohen et al.",
              "(2002) [28] had put forwarded a first approximation of a compositional theory of tune interpretation, together with phonological assumptions on which it is based and the evidence from which they have drawn their proposals.",
              "At the same time, McKeown (1985) [85] demonstrated that rhetorical schemas could be used for producing both linguistically coherent and communicatively effective text.",
              "Some research in NLP marked important topics for future like word sense disambiguation (Small et al.",
              ", 1988) [126] and probabilistic networks, statistically colored NLP, the work on the lexicon, also pointed in this direction.",
              "Statistical language processing was a major thing in 90s (Manning and Schuetze,1999) [75], because this not only involves data analysts.",
              "Information extraction and automatic summarizing (Mani and Maybury,1999) [74] was also a point of focus.",
              "Next, we present a walkthrough of the developments from the early 2000.",
              "The main objectives of NLP include interpretation, analysis, and manipulation of natural language data for the intended purpose with the use of various algorithms, tools, and methods.",
              "However, there are many challenges involved which may depend upon the natural language data under consideration, and so makes it difficult to achieve all the objectives with a single approach.",
              "Therefore, the development of different tools and methods in the field of NLP and relevant areas of studies have received much attention from several researchers in the recent past.",
              "The developments can be seen in the Fig.",
              "3: A walkthrough of recent developments in NLP In early 2000, neural language modeling in which the probability of occurring of next word (token) is determined given n previous words.",
              "Bendigo et al.",
              "[12] proposed the concept of feed forward neural network and lookup table which represents the n previous words in sequence.",
              "Collobert et al.",
              "[29] proposed the application of multitask learning in the field of NLP, where two convolutional models with max pooling were used to perform parts-of-speech and named entity recognition tagging.",
              "Mikolov et.",
              "al.",
              "[87] proposed a word embedding process where the dense vector representation of text was addressed.",
              "They also report the challenges faced by traditional sparse bag-of-words representation.",
              "After the advancement of word embedding, neural networks were introduced in the field of NLP where variable length input is taken for further processing.",
              "Sutskever et al.",
              "[132] proposed a general framework for sequence-to-sequence mapping where encoder and decoder networks are used to map from sequence to vector and vector to sequence respectively.",
              "In fact, the use of neural networks have played a very important role in NLP.",
              "One can observe from the existing literature that enough use of neural networks was not there in the early 2000s but till the year 2013enough discussion had happened about the use of neural networks in the field of NLP which transformed many things and further paved the way to implement various neural networks in NLP.",
              "Earlier the use of Convolutional neural networks (CNN) contributed to the field of image classification and analyzing visual imagery for further analysis.",
              "Later the use of CNNs can be observed in tackling problems associated with NLP tasks like Sentence Classification [127], Sentiment Analysis [135], Text Classification [118], Text Summarization [158], Machine Translation [70] and Answer Relations [150].",
              "An article by Newatia (2019) [93] illustrates the general architecture behind any CNN model, and how it can be used in the context of NLP.",
              "One can also refer to the work of Wang and Gang [145] for the applications of CNN in NLP.",
              "Further Neural Networks those are recurrent in nature due to performing the same function for every data, also known as Recurrent Neural Networks (RNNs), have also been used in NLP, and found ideal for sequential data such as text, time series, financial data, speech, audio, video among others, see article by Thomas (2019) [137].",
              "One of the modified versions of RNNs is Long Short-Term Memory (LSTM) which is also very useful in the cases where only the desired important information needs to be retained for a much longer time discarding the irrelevant information, see [52, 58].",
              "Further development in the LSTM has also led to a slightly simpler variant, called the gated recurrent unit (GRU), which has shown better results than standard LSTMs in many tasks [22, 26].",
              "Attention mechanisms [7] which suggest a network to learn what to pay attention to in accordance with the current hidden state and annotation together with the use of transformers have also made a significant development in NLP, see [141].",
              "It is to be noticed that Transformers have a potential of learning longer-term dependency but are limited by a fixed-length context in the setting of language modeling.",
              "In this direction recently Dai et al.",
              "[30] proposed a novel neural architecture Transformer-XL (XL as extra-long) which enables learning dependencies beyond a fixed length of words.",
              "Further the work of Rae et al.",
              "[104] on the Compressive Transformer, an attentive sequence model which compresses memories for long-range sequence learning, may be helpful for the readers.",
              "One may also refer to the recent work by Otter et al.",
              "[98] on uses of Deep Learning for NLP, and relevant references cited therein.",
              "The use of BERT (Bidirectional Encoder Representations from Transformers) [33] model and successive models have also played an important role for NLP.",
              "Many researchers worked on NLP, building tools and systems which makes NLP what it is today.",
              "Tools like Sentiment Analyser, Parts of Speech (POS) Taggers, Chunking, Named Entity Recognitions (NER), Emotion detection, Semantic Role Labeling have a huge contribution made to NLP, and are good topics for research.",
              "Sentiment analysis (Nasukawaetal.",
              ",2003) [156] works by extracting sentiments about a given topic, and it consists of a topic specific feature term extraction, sentiment extraction, and association by relationship analysis.",
              "It utilizes two linguistic resources for the analysis: the sentiment lexicon and the sentiment pattern database.",
              "It analyzes the documents for positive and negative words and tries to give ratings on scale \u22125 to +5.",
              "The mainstream of currently used tagsets is obtained from English.",
              "The most widely used tagsets as standard guidelines are designed for Indo-European languages but it is less researched on Asian languages or middle- eastern languages.",
              "Various authors have done research on making parts of speech taggers for various languages such as Arabic (Zeroual et al.",
              ", 2017) [160], Sanskrit (Tapswi & Jain, 2012) [136], Hindi (Ranjan & Basu, 2003) [105] to efficiently tag and classify words as nouns, adjectives, verbs etc.",
              "Authors in [136] have used treebank technique for creating rule-based POS Tagger for Sanskrit Language.",
              "Sanskrit sentences are parsed to assign the appropriate tag to each word using suffix stripping algorithm, wherein the longest suffix is searched from the suffix table and tags are assigned.",
              "Diab et al.",
              "(2004) [34] used supervised machine learning approach and adopted Support Vector Machines (SVMs) which were trained on the Arabic Treebank to automatically tokenize parts of speech tag and annotate base phrases in Arabic text.",
              "Chunking is a process of separating phrases from unstructured text.",
              "Since simple tokens may not represent the actual meaning of the text, it is advisable to use phrases such as \u201cNorth Africa\u201d as a single word instead of \u2018North\u2019 and \u2018Africa\u2019 separate words.",
              "Chunking known as \u201cShadow Parsing\u201d labels parts of sentences with syntactic correlated keywords like Noun Phrase (NP) and Verb Phrase (VP).",
              "Chunking is often evaluated using the CoNLL 2000 shared task.",
              "Various researchers (Sha and Pereira, 2003;",
              "McDonald et al.",
              ", 2005;",
              "Sun et al.",
              ", 2008) [83, 122, 130] used CoNLL test data for chunking and used features composed of words, POS tags, and tags.",
              "There are particular words in the document that refer to specific entities or real-world objects like location, people, organizations etc.",
              "To find the words which have a unique context and are more informative, noun phrases are considered in the text documents.",
              "Named entity recognition (NER) is a technique to recognize and separate the named entities and group them under predefined classes.",
              "But in the era of the Internet, where people use slang not the traditional or standard English which cannot be processed by standard natural language processing tools.",
              "Ritter (2011) [111] proposed the classification of named entities in tweets because standard NLP tools did not perform well on tweets.",
              "They re-built NLP pipeline starting from PoS tagging, then chunking for NER.",
              "It improved the performance in comparison to standard NLP tools.",
              "Emotion detection investigates and identifies the types of emotion from speech, facial expressions, gestures, and text.",
              "Sharma (2016) [124] analyzed the conversations in Hinglish means mix of English and Hindi languages and identified the usage patterns of PoS.",
              "Their work was based on identification of language and POS tagging of mixed script.",
              "They tried to detect emotions in mixed script by relating machine learning and human knowledge.",
              "They have categorized sentences into 6 groups based on emotions and used TLBO technique to help the users in prioritizing their messages based on the emotions attached with the message.",
              "Seal et al.",
              "(2020) [120] proposed an efficient emotion detection method by searching emotional words from a pre-defined emotional keyword database and analyzing the emotion words, phrasal verbs, and negation words.",
              "Their proposed approach exhibited better performance than recent approaches.",
              "Semantic Role Labeling (SRL) works by giving a semantic role to a sentence.",
              "For example, in the PropBank (Palmer et al.",
              ", 2005) [100] formalism, one assigns roles to words that are arguments of a verb in the sentence.",
              "The precise arguments depend on the verb frame and if multiple verbs exist in a sentence, it might have multiple tags.",
              "State-of-the-art SRL systems comprise several stages: creating a parse tree, identifying which parse tree nodes represent the arguments of a given verb, and finally classifying these nodes to compute the corresponding SRL tags.",
              "Event discovery in social media feeds (Benson et al.",
              ",2011) [13], using a graphical model to analyze any social media feeds to determine whether it contains the name of a person or name of a venue, place, time etc.",
              "The model operates on noisy feeds of data to extract records of events by aggregating multiple information across multiple messages, despite the noise of irrelevant noisy messages and very irregular message language, this model was able to extract records with a broader array of features on factors.",
              "We first give insights on some of the mentioned tools and relevant work done before moving to the broad applications of NLP.",
              "Natural Language Processing can be applied into various areas like Machine Translation, Email Spam detection, Information Extraction, Summarization, Question Answering etc.",
              "Next, we discuss some of the areas with the relevant work done in those directions.",
              "Machine Translation As most of the world is online, the task of making data accessible and available to all is a challenge.",
              "Major challenge in making data accessible is the language barrier.",
              "There are a multitude of languages with different sentence structure and grammar.",
              "Machine Translation is generally translating phrases from one language to another with the help of a statistical engine like Google Translate.",
              "The challenge with machine translation technologies is not directly translating words but keeping the meaning of sentences intact along with grammar and tenses.",
              "The statistical machine learning gathers as many data as they can find that seems to be parallel between two languages and they crunch their data to find the likelihood that something in Language A corresponds to something in Language B.",
              "As for Google, in September 2016, announced a new machine translation system based on artificial neural networks and Deep learning.",
              "In recent years, various methods have been proposed to automatically evaluate machine translation quality by comparing hypothesis translations with reference translations.",
              "Examples of such methods are word error rate, position-independent word error rate (Tillmann et al.",
              ", 1997) [138], generation string accuracy (Bangalore et al.",
              ", 2000) [8], multi-reference word error rate (Nie\u00dfen et al.",
              ", 2000) [95], BLEU score (Papineni et al.",
              ", 2002) [101], NIST score (Doddington, 2002) [35] All these criteria try to approximate human assessment and often achieve an astonishing degree of correlation to human subjective evaluation of fluency and adequacy (Papineni et al.",
              ", 2001;",
              "Doddington, 2002) [35, 101].",
              "Text Categorization Categorization systems input a large flow of data like official documents, military casualty reports, market data, newswires etc.",
              "and assign them to predefined categories or indices.",
              "For example, The Carnegie Group\u2019s Construe system (Hayes, 1991) [54], inputs Reuters articles and saves much time by doing the work that is to be done by staff or human indexers.",
              "Some companies have been using categorization systems to categorize trouble tickets or complaint requests and routing to the appropriate desks.",
              "Another application of text categorization is email spam filters.",
              "Spam filters are becoming important as the first line of defence against the unwanted emails.",
              "A false negative and false positive issue of spam filters is at the heart of NLP technology, it has brought down the challenge of extracting meaning from strings of text.",
              "A filtering solution that is applied to an email system uses a set of protocols to determine which of the incoming messages are spam;",
              "and which are not.",
              "There are several types of spam filters available.",
              "Content filters: Review the content within the message to determine whether it is spam or not.",
              "Header filters: Review the email header looking for fake information.",
              "General Blacklist filters: Stop all emails from blacklisted recipients.",
              "Rules Based Filters: It uses user-defined criteria.",
              "Such as stopping mails from a specific person or stopping mail including a specific word.",
              "Permission Filters: Require anyone sending a message to be pre-approved by the recipient.",
              "Challenge Response Filters: Requires anyone sending a message to enter a code to gain permission to send email.",
              "Spam Filtering It works using text categorization and in recent times, various machine learning techniques have been applied to text categorization or Anti-Spam Filtering like Rule Learning (Cohen 1996) [27], Nai\u0308ve Bayes (Sahami et al.",
              ", 1998;",
              "Androutsopoulos et al.",
              ", 2000;",
              "Rennie.",
              ",2000) [5, 109, 115],Memory based Learning (Sakkiset al.",
              ",2000b) [117], Support vector machines (Druker et al.",
              ", 1999) [36], Decision Trees (Carreras and Marquez, 2001) [19], Maximum Entropy Model (Berger et al.",
              "1996) [14], Hash Forest and a rule encoding method (T.",
              "Xia, 2020) [153], sometimes combining different learners (Sakkis et al.",
              ", 2001) [116].",
              "Using these approaches is better as classifier is learned from training data rather than making by hand.",
              "The nai\u0308ve bayes is preferred because of its performance despite its simplicity (Lewis, 1998) [67] In Text Categorization two types of models have been used (McCallum and Nigam, 1998) [77].",
              "Both modules assume that a fixed vocabulary is present.",
              "But in first model a document is generated by first choosing a subset of vocabulary and then using the selected words any number of times, at least once irrespective of order.",
              "This is called Multi-variate Bernoulli model.",
              "It takes the information of which words are used in a document irrespective of number of words and order.",
              "In second model, a document is generated by choosing a set of word occurrences and arranging them in any order.",
              "This model is called multi-nomial model, in addition to the Multi-variate Bernoulli model, it also captures information on how many times a word is used in a document.",
              "Most text categorization approaches to anti-spam Email filtering have used multi variate Bernoulli model (Androutsopoulos et al.",
              ", 2000) [5] [15].",
              "Information Extraction Information extraction is concerned with identifying phrases of interest of textual data.",
              "For many applications, extracting entities such as names, places, events, dates, times, and prices is a powerful way of summarizing the information relevant to a user\u2019s needs.",
              "In the case of a domain specific search engine, the automatic identification of important information can increase accuracy and efficiency of a directed search.",
              "There is use of hidden Markov models (HMMs) to extract the relevant fields of research papers.",
              "These extracted text segments are used to allow searched over specific fields and to provide effective presentation of search results and to match references to papers.",
              "For example, noticing the pop-up ads on any websites showing the recent items you might have looked on an online store with discounts.",
              "In Information Retrieval two types of models have been used (McCallum and Nigam, 1998) [77].",
              "Both modules assume that a fixed vocabulary is present.",
              "But in first model a document is generated by first choosing a subset of vocabulary and then using the selected words any number of times, at least once without any order.",
              "This is called Multi-variate Bernoulli model.",
              "It takes the information of which words are used in a document irrespective of number of words and order.",
              "In second model, a document is generated by choosing a set of word occurrences and arranging them in any order.",
              "This model is called multi-nominal model, in addition to the Multi-variate Bernoulli model, it also captures information on how many times a word is used in a document.",
              "Discovery of knowledge is becoming important areas of research over the recent years.",
              "Knowledge discovery research use a variety of techniques to extract useful information from source documents like Parts of Speech (POS) tagging, Chunking or Shadow Parsing, Stop-words (Keywords that are used and must be removed before processing documents), Stemming (Mapping words to some base for, it has two methods, dictionary-based stemming and Porter style stemming (Porter, 1980) [103].",
              "Former one has higher accuracy but higher cost of implementation while latter has lower implementation cost and is usually insufficient for IR).",
              "Compound or Statistical Phrases (Compounds and statistical phrases index multi token units instead of single tokens.)",
              "Word Sense Disambiguation (Word sense disambiguation is the task of understanding the correct sense of a word in context.",
              "When used for information retrieval, terms are replaced by their senses in the document vector.)",
              "The extracted information can be applied for a variety of purposes, for example to prepare a summary, to build databases, identify keywords, classifying text items according to some pre-defined categories etc.",
              "For example, CONSTRUE, it was developed for Reuters, that is used in classifying news stories (Hayes, 1992) [54].",
              "It has been suggested that many IE systems can successfully extract terms from documents, acquiring relations between the terms is still a difficulty.",
              "PROMETHEE is a system that extracts lexico-syntactic patterns relative to a specific conceptual relation (Morin,1999) [89].",
              "IE systems should work at many levels, from word recognition to discourse analysis at the level of the complete document.",
              "An application of the Blank Slate Language Processor (BSLP) (Bondale et al.",
              ", 1999) [16] approach for the analysis of a real-life natural language corpus that consists of responses to open-ended questionnaires in the field of advertising.",
              "There is a system called MITA (Metlife\u2019s Intelligent Text Analyzer) (Glasgow et al.",
              "(1998) [48]) that extracts information from life insurance applications.",
              "Ahonen et al.",
              "(1998) [1] suggested a mainstream framework for text mining that uses pragmatic and discourse level analyses of text.",
              "Summarization Overload of information is the real thing in this digital age, and already our reach and access to knowledge and information exceeds our capacity to understand it.",
              "This trend is not slowing down, so an ability to summarize the data while keeping the meaning intact is highly required.",
              "This is important not just allowing us the ability to recognize the understand the important information for a large set of data, it is used to understand the deeper emotional meanings;",
              "For example, a company determines the general sentiment on social media and uses it on their latest product offering.",
              "This application is useful as a valuable marketing asset.",
              "The types of text summarization depends on the basis of the number of documents and the two important categories are single document summarization and multi document summarization (Zajic et al.",
              "2008 [159];",
              "Fattah and Ren 2009 [43]).",
              "Summaries can also be of two types: generic or query-focused (Gong and Liu 2001 [50];",
              "Dunlavy et al.",
              "2007 [37];",
              "Wan 2008 [144];",
              "Ouyang et al.",
              "2011 [99]).",
              "Summarization task can be either supervised or unsupervised (Mani and Maybury 1999 [74];",
              "Fattah and Ren 2009 [43];",
              "Riedhammer et al.",
              "2010 [110]).",
              "Training data is required in a supervised system for selecting relevant material from the documents.",
              "Large amount of annotated data is needed for learning techniques.",
              "Few techniques are as follows\u2013 Bayesian Sentence based Topic Model (BSTM) uses both term-sentences and term document associations for summarizing multiple documents.",
              "(Wang et al.",
              "2009 [146]) Factorization with Given Bases (FGB) is a language model where sentence bases are the given bases and it utilizes document-term and sentence term matrices.",
              "This approach groups and summarizes the documents simultaneously.",
              "(Wang et al.",
              "2011) [147]) Topic Aspect-Oriented Summarization (TAOS) is based on topic factors.",
              "These topic factors are various features that describe topics such as capital words are used to represent entity.",
              "Various topics can have various aspects and various preferences of features are used to represent various aspects.",
              "(Fang et al.",
              "2015 [42]) Dialogue System Dialogue systems are very prominent in real world applications ranging from providing support to performing a particular action.",
              "In case of support dialogue systems, context awareness is required whereas in case to perform an action, it doesn\u2019t require much context awareness.",
              "Earlier dialogue systems were focused on small applications such as home theater systems. These dialogue systems utilize phonemic and lexical levels of language.",
              "Habitable dialogue systems offer potential for fully automated dialog systems by utilizing all levels of a language.",
              "(Liddy, 2001) [68].",
              "This leads to producing systems that can enable robots to interact with humans in natural languages such as Google\u2019s assistant, Windows Cortana, Apple\u2019s Siri and Amazon\u2019s Alexa etc.",
              "Medicine NLP is applied in the field as well.",
              "The Linguistic String Project-Medical Language Processor is one the large scale projects of NLP in the field of medicine [21, 53, 57, 71, 114].",
              "The LSP-MLP helps enabling physicians to extract and summarize information of any signs or symptoms, drug dosage and response data with the aim of identifying possible side effects of any medicine while highlighting or flagging data items [114].",
              "The National Library of Medicine is developing The Specialist System [78,79,80, 82, 84].",
              "It is expected to function as an Information Extraction tool for Biomedical Knowledge Bases, particularly Medline abstracts.",
              "The lexicon was created using MeSH (Medical Subject Headings), Dorland\u2019s Illustrated Medical Dictionary and general English Dictionaries.",
              "The Centre d\u2019Informatique Hospitaliere of the Hopital Cantonal de Geneve is working on an electronic archiving environment with NLP features [81, 119].",
              "In the first phase, patient records were archived.",
              "At later stage the LSP-MLP has been adapted for French [10, 72, 94, 113], and finally, a proper NLP system called RECIT [9, 11, 17, 106] has been developed using a method called Proximity Processing [88].",
              "It\u2019s task was to implement a robust and multilingual system able to analyze/comprehend medical sentences, and to preserve a knowledge of free text into a language independent knowledge representation [107, 108].",
              "The Columbia university of New York has developed an NLP system called MEDLEE (MEDical Language Extraction and Encoding System) that identifies clinical information in narrative reports and transforms the textual information into structured representation [45].",
              "We next discuss some of the recent NLP projects implemented by various companies: ACE Powered GDPR Robot Launched by RAVN Systems [134] RAVN Systems, a leading expert in Artificial Intelligence (AI), Search and Knowledge Management Solutions, announced the launch of a RAVN (\u201cApplied Cognitive Engine\u201d) i.",
              "e. powered software Robot to help and facilitate the GDPR (\u201cGeneral Data Protection Regulation\u201d) compliance.",
              "The Robot uses AI techniques to automatically analyze documents and other types of data in any business system which is subject to GDPR rules.",
              "It allows users to search, retrieve, flag, classify, and report on data, mediated to be super sensitive under GDPR quickly and easily.",
              "Users also can identify personal data from documents, view feeds on the latest personal data that requires attention and provide reports on the data suggested to be deleted or secured.",
              "RAVN\u2019s GDPR Robot is also able to hasten requests for information (Data Subject Access Requests - \u201cDSAR\u201d) in a simple and efficient way, removing the need for a physical approach to these requests which tends to be very labor thorough.",
              "Peter Wallqvist, CSO at RAVN Systems commented, \u201cGDPR compliance is of universal paramountcy as it will be exploited by any organization that controls and processes data concerning EU citizens.",
              "Link: http://markets.",
              "financialcontent.",
              "com/stocks/news/read/33888795/RAVN_Systems_Launch_the_ACE_Powered_GDPR_Robot Eno A Natural Language Chatbot Launched by Capital One [56] Capital One announces a chatbot for customers called Eno.",
              "Eno is a natural language chatbot that people socialize through texting.",
              "CapitalOne claims that Eno is First natural language SMS chatbot from a U.",
              "S.",
              "bank that allows customers to ask questions using natural language.",
              "Customers can interact with Eno asking questions about their savings and others using a text interface.",
              "Eno makes such an environment that it feels that a human is interacting.",
              "This provides a different platform than other brands that launch chatbots like Facebook Messenger and Skype.",
              "They believed that Facebook has too much access to private information of a person, which could get them into trouble with privacy laws U.",
              "S.",
              "financial institutions work under.",
              "Like Facebook Page admin can access full transcripts of the bot\u2019s conversations.",
              "If that would be the case then the admins could easily view the personal banking information of customers with is not correct.",
              "Link: https://www.",
              "macobserver.",
              "com/analysis/capital-one-natural-language-chatbot-eno/ Future of BI in Natural Language Processing [140] Several companies in BI spaces are trying to get with the trend and trying hard to ensure that data becomes more friendly and easily accessible.",
              "But still there is a long way for this.",
              "BI will also make it easier to access as GUI is not needed.",
              "Because nowadays the queries are made by text or voice command on smartphones.",
              "one of the most common examples is Google might tell you today what tomorrow\u2019s weather will be.",
              "But soon enough, we will be able to ask our personal data chatbot about customer sentiment today, and how we feel about their brand next week;",
              "all while walking down the street.",
              "Today, NLP tends to be based on turning natural language into machine language.",
              "But with time the technology matures \u2013 especially the AI component \u2013the computer will get better at \u201cunderstanding\u201d the query and start to deliver answers rather than search results.",
              "Initially, the data chatbot will probably ask the question \u2018how have revenues changed over the last three-quarters?",
              "\u2019 and then return pages of data for you to analyze.",
              "But once it learns the semantic relations and inferences of the question, it will be able to automatically perform the filtering and formulation necessary to provide an intelligible answer, rather than simply showing you data.",
              "Link: http://www.",
              "smartdatacollective.",
              "com/eran-levy/489410/here-s-why-natural-language-processing-future-bi Using Natural Language Processing and Network Analysis to Develop a Conceptual Framework for Medication Therapy Management Research [97] Natural Language Processing and Network Analysis to Develop a Conceptual Framework for Medication Therapy Management Research describes a theory derivation process that is used to develop a conceptual framework for medication therapy management (MTM) research.",
              "The MTM service model and chronic care model are selected as parent theories.",
              "Review article abstracts target medication therapy management in chronic disease care that were retrieved from Ovid Medline (2000\u20132016).",
              "Unique concepts in each abstract are extracted using Meta Map and their pair-wise co-occurrence are determined.",
              "Then the information is used to construct a network graph of concept co-occurrence that is further analyzed to identify content for the new conceptual model.",
              "142 abstracts are analyzed.",
              "Medication adherence is the most studied drug therapy problem and co-occurred with concepts related to patient-centered interventions targeting self-management.",
              "The enhanced model consists of 65 concepts clustered into 14 constructs.",
              "The framework requires additional refinement and evaluation to determine its relevance and applicability across a broad audience including underserved settings.",
              "Link: https://www.",
              "ncbi.",
              "nlm.",
              "nih.",
              "gov/pubmed/28269895?",
              "dopt=Abstract Meet the Pilot, world\u2019s first language translating earbuds [96] The world\u2019s first smart earpiece Pilot will soon be transcribed over 15 languages.",
              "According to Spring wise, Waverly Labs\u2019 Pilot can already transliterate five spoken languages, English, French, Italian, Portuguese, and Spanish, and seven written affixed languages, German, Hindi, Russian, Japanese, Arabic, Korean and Mandarin Chinese.",
              "The Pilot earpiece is connected via Bluetooth to the Pilot speech translation app, which uses speech recognition, machine translation and machine learning and speech synthesis technology.",
              "Simultaneously, the user will hear the translated version of the speech on the second earpiece.",
              "Moreover, it is not necessary that conversation would be taking place between two people;",
              "only the users can join in and discuss as a group.",
              "As if now the user may experience a few second lag interpolated the speech and translation, which Waverly Labs pursue to reduce.",
              "The Pilot earpiece will be available from September but can be pre-ordered now for $249.",
              "The earpieces can also be used for streaming music, answering voice calls, and getting audio notifications.",
              "Link: https://www.",
              "indiegogo.",
              "com/projects/meet-the-pilot-smart-earpiece-language-translator-headphones-travel#/ The objective of this section is to present the various datasets used in NLP and some state-of-the-art models in NLP.",
              "Corpus is a collection of linguistic data, either compiled from written texts or transcribed from recorded speech.",
              "Corpora are intended primarily for testing linguistic hypotheses - e.",
              "g., to determine how a certain sound, word, or syntactic construction is used across a culture or language.",
              "There are various types of corpus: In an annotated corpus, the implicit information in the plain text has been made explicit by specific annotations.",
              "Un-annotated corpus contains raw state of plain text.",
              "Different languages can be compared using a reference corpus.",
              "Monitor corpora are non-finite collections of texts which are mostly used in lexicography.",
              "Multilingual corpus refers to a type of corpus that contains small collections of monolingual corpora based on the same sampling procedure and categories for different languages.",
              "Parallel corpus contains texts in one language and their translations into other languages which are aligned sentence phrase by phrase.",
              "Reference corpus contains text of spoken (formal and informal) and written (formal and informal) language which represents various social and situational contexts.",
              "Speech corpus contains recorded speech and transcriptions of recording and the time each word occurred in the recorded speech.",
              "There are various datasets available for natural language processing;",
              "some of these are listed below for different use cases: Sentiment Analysis: Sentiment analysis is a rapidly expanding field of natural language processing (NLP) used in a variety of fields such as politics, business etc.",
              "Majorly used datasets for sentiment analysis are: Stanford Sentiment Treebank (SST): Socher et al.",
              "introduced SST containing sentiment labels for 215,154 phrases in parse trees for 11,855 sentences from movie reviews posing novel sentiment compositional difficulties [127].",
              "Sentiment140: It contains 1.",
              "6 million tweets annotated with negative, neutral and positive labels.",
              "Paper Reviews: It provides reviews of computing and informatics conferences written in English and Spanish languages.",
              "It has 405 reviews which are evaluated on a 5-point scale ranging from very negative to very positive.",
              "IMDB: For natural language processing, text analytics, and sentiment analysis, this dataset offers thousands of movie reviews split into training and test datasets.",
              "This dataset was introduced in by Mass et al.",
              "in 2011 [73].",
              "G.",
              "Rama Rohit Reddy of the Language Technologies Research Centre, KCIS, IIIT Hyderabad, generated the corpus \u201cSentiraama.",
              "\u201d The corpus is divided into four datasets, each of which is annotated with a two-value scale that distinguishes between positive and negative sentiment at the document level.",
              "The corpus contains data from a variety of fields, including book reviews, product reviews, movie reviews, and song lyrics.",
              "The annotators meticulously followed the annotation technique for each of them.",
              "The folder \u201cSong Lyrics\u201d in the corpus contains 339 Telugu song lyrics written in Telugu script [121].",
              "Language Modelling: Language models analyse text data to calculate word probability.",
              "They use an algorithm to interpret the data, which establishes rules for context in natural language.",
              "The model then uses these rules to accurately predict or construct new sentences.",
              "The model basically learns the basic characteristics and features of language and then applies them to new phrases.",
              "Majorly used datasets for Language modeling are as follows: Salesforce\u2019s WikiText-103 dataset has 103 million tokens collected from 28,475 featured articles from Wikipedia.",
              "WikiText-2 is a scaled-down version of WikiText-103.",
              "It contains 2 million tokens with a 33,278 jargon size.",
              "Penn Treebank piece of the Wall Street Diary corpus includes 929,000 tokens for training, 73,000 tokens for validation, and 82,000 tokens for testing purposes.",
              "Its context is limited since it comprises sentences rather than paragraphs [76].",
              "The Ministry of Electronics and Information Technology\u2019s Technology Development Programme for Indian Languages (TDIL) launched its own data distribution portal (www.",
              "tdil-dc.",
              "in) which has cataloged datasets [24].",
              "Machine Translation: The task of converting the text of one natural language into another language while keeping the sense of the input text is known as machine translation.",
              "Majorly used datasets are as follows: Tatoeba is a collection of multilingual sentence pairings.",
              "A tab-delimited pair of an English text sequence and the translated French text sequence appears on each line of the dataset.",
              "Each text sequence might be as simple as a single sentence or as complex as a paragraph of many sentences.",
              "The Europarl parallel corpus is derived from the European Parliament\u2019s proceedings.",
              "It is available in 21 European languages [40].",
              "WMT14 provides machine translation pairs for English-German and English-French.",
              "Separately, these datasets comprise 4.",
              "5 million and 35 million sentence sets.",
              "Byte-Pair Encoding with 32 K tasks is used to encode the phrases.",
              "There are around 160,000 sentence pairings in the IWSLT 14.",
              "The dataset includes descriptions in English-German (En-De) and German-English (De-En) languages.",
              "There are around 200 K training sentence sets in the IWSLT 13 dataset.",
              "The IIT Bombay English-Hindi corpus comprises parallel corpora for English-Hindi as well as monolingual Hindi corpora gathered from several existing sources and corpora generated over time at IIT Bombay\u2019s Centre for Indian Language Technology.",
              "Question Answering System: Question answering systems provide real-time responses which are widely used in customer care services.",
              "The datasets used for dialogue system/question answering system are as follows: Stanford Question Answering Dataset (SQuAD): it is a reading comprehension dataset made up of questions posed by crowd workers on a collection of Wikipedia articles.",
              "Natural Questions: It is a large-scale corpus presented by Google used for training and assessing open-domain question answering systems. It includes 300,000 naturally occurring queries as well as human-annotated responses from Wikipedia pages for use in QA system training.",
              "Question Answering in Context (QuAC): This dataset is used to describe, comprehend, and participate in information seeking conversation.",
              "In this dataset, instances are made up of an interactive discussion between two crowd workers: a student who asks a series of open-ended questions about an unknown Wikipedia text, and a teacher who responds by offering brief extracts from the text.",
              "The neural learning models are overtaking traditional models for NLP [64, 127].",
              "In [64], authors used CNN (Convolutional Neural Network) model for sentiment analysis of movie reviews and achieved 81.",
              "5% accuracy.",
              "The results illustrate that using CNN was an appropriate replacement for state-of-the-art methods.",
              "Authors [127] have combined SST and Recursive Neural Tensor Network for sentiment analysis of the single sentence.",
              "This model amplifies the accuracy by 5.",
              "4% for sentence classification compared to traditional NLP models.",
              "Authors [135] proposed a combined Recurrent Neural Network and Transformer model for sentiment analysis.",
              "This hybrid model was tested on three different datasets: Twitter US Airline Sentiment, IMDB, and Sentiment 140: and achieved F1 scores of 91%, 93%, and 90%, respectively.",
              "This model\u2019s performance outshined the state-of-art methods.",
              "Santoro et al.",
              "[118] introduced a rational recurrent neural network with the capacity to learn on classifying the information and perform complex reasoning based on the interactions between compartmentalized information.",
              "They used the relational memory core to handle such interactions.",
              "Finally, the model was tested for language modeling on three different datasets (GigaWord, Project Gutenberg, and WikiText-103).",
              "Further, they mapped the performance of their model to traditional approaches for dealing with relational reasoning on compartmentalized information.",
              "The results achieved with RMC show improved performance.",
              "Merity et al.",
              "[86] extended conventional word-level language models based on Quasi-Recurrent Neural Network and LSTM to handle the granularity at character and word level.",
              "They tuned the parameters for character-level modeling using Penn Treebank dataset and word-level modeling using WikiText-103.",
              "In both cases, their model outshined the state-of-art methods.",
              "Luong et al.",
              "[70] used neural machine translation on the WMT14 dataset and performed translation of English text to French text.",
              "The model demonstrated a significant improvement of up to 2.",
              "8 bi-lingual evaluation understudy (BLEU) scores compared to various neural machine translation systems. It outperformed the commonly used MT system on a WMT 14 dataset.",
              "Fan et al.",
              "[41] introduced a gradient-based neural architecture search algorithm that automatically finds architecture with better performance than a transformer, conventional NMT models.",
              "They tested their model on WMT14 (English-German Translation), IWSLT14 (German-English translation), and WMT18 (Finnish-to-English translation) and achieved 30.",
              "1, 36.",
              "1, and 26.",
              "4 BLEU points, which shows better performance than Transformer baselines.",
              "Wiese et al.",
              "[150] introduced a deep learning approach based on domain adaptation techniques for handling biomedical question answering tasks.",
              "Their model revealed the state-of-the-art performance on biomedical question answers, and the model outperformed the state-of-the-art methods in domains.",
              "Seunghak et al.",
              "[158] designed a Memory-Augmented-Machine-Comprehension-Network (MAMCN) to handle dependencies faced in reading comprehension.",
              "The model achieved state-of-the-art performance on document-level using TriviaQA and QUASAR-T datasets, and paragraph-level using SQuAD datasets.",
              "Xie et al.",
              "[154] proposed a neural architecture where candidate answers and their representation learning are constituent centric, guided by a parse tree.",
              "Under this architecture, the search space of candidate answers is reduced while preserving the hierarchical, syntactic, and compositional structure among constituents.",
              "Using SQuAD, the model delivers state-of-the-art performance.",
              "Rationalist approach or symbolic approach assumes that a crucial part of the knowledge in the human mind is not derived by the senses but is firm in advance, probably by genetic inheritance.",
              "Noam Chomsky was the strongest advocate of this approach.",
              "It was believed that machines can be made to function like the human brain by giving some fundamental knowledge and reasoning mechanism linguistics knowledge is directly encoded in rule or other forms of representation.",
              "This helps the automatic process of natural languages [92].",
              "Statistical and machine learning entail evolution of algorithms that allow a program to infer patterns.",
              "An iterative process is used to characterize a given algorithm\u2019s underlying algorithm that is optimized by a numerical measure that characterizes numerical parameters and learning phase.",
              "Machine-learning models can be predominantly categorized as either generative or discriminative.",
              "Generative methods can generate synthetic data because of which they create rich models of probability distributions.",
              "Discriminative methods are more functional and have right estimating posterior probabilities and are based on observations.",
              "Srihari [129] explains the different generative models as one with a resemblance that is used to spot an unknown speaker\u2019s language and would bid the deep knowledge of numerous languages to perform the match.",
              "Discriminative methods rely on a less knowledge-intensive approach and using distinction between languages.",
              "Whereas generative models can become troublesome when many features are used and discriminative models allow use of more features [38].",
              "Few of the examples of discriminative methods are Logistic regression and conditional random fields (CRFs), generative methods are Naive Bayes classifiers and hidden Markov models (HMMs).",
              "Naive Bayes Classifiers Naive Bayes is a probabilistic algorithm which is based on probability theory and Bayes\u2019 Theorem to predict the tag of a text such as news or customer review.",
              "It helps to calculate the probability of each tag for the given text and return the tag with the highest probability.",
              "Bayes\u2019 Theorem is used to predict the probability of a feature based on prior knowledge of conditions that might be related to that feature.",
              "The choice of area in NLP using Nai\u0308ve Bayes Classifiers could be in usual tasks such as segmentation and translation but it is also explored in unusual areas like segmentation for infant learning and identifying documents for opinions and facts.",
              "Anggraeni et al.",
              "(2019) [61] used ML and AI to create a question-and-answer system for retrieving information about hearing loss.",
              "They developed I-Chat Bot which understands the user input and provides an appropriate response and produces a model which can be used in the search for information about required hearing impairments.",
              "The problem with nai\u0308ve bayes is that we may end up with zero probabilities when we meet words in the test data for a certain class that are not present in the training data.",
              "Hidden Markov Model (HMM) An HMM is a system where a shifting takes place between several states, generating feasible output symbols with each switch.",
              "The sets of viable states and unique symbols may be large, but finite and known.",
              "We can describe the outputs, but the system\u2019s internals are hidden.",
              "Few of the problems could be solved by Inference A certain sequence of output symbols, compute the probabilities of one or more candidate states with sequences.",
              "Patterns matching the state-switch sequence are most likely to have generated a particular output-symbol sequence.",
              "Training the output-symbol chain data, reckon the state-switch/output probabilities that fit this data best.",
              "Hidden Markov Models are extensively used for speech recognition, where the output sequence is matched to the sequence of individual phonemes.",
              "HMM is not restricted to this application;",
              "it has several others such as bioinformatics problems, for example, multiple sequence alignment [128].",
              "Sonnhammer mentioned that Pfam holds multiple alignments and hidden Markov model-based profiles (HMM-profiles) of entire protein domains.",
              "The cue of domain boundaries, family members and alignment are done semi-automatically found on expert knowledge, sequence similarity, other protein family databases and the capability of HMM-profiles to correctly identify and align the members.",
              "HMM may be used for a variety of NLP applications, including word prediction, sentence production, quality assurance, and intrusion detection systems [133].",
              "Neural Network Earlier machine learning techniques such as Nai\u0308ve Bayes, HMM etc.",
              "were majorly used for NLP but by the end of 2010, neural networks transformed and enhanced NLP tasks by learning multilevel features.",
              "Major use of neural networks in NLP is observed for word embedding where words are represented in the form of vectors.",
              "These vectors can be used to recognize similar words by observing their closeness in this vector space, other uses of neural networks are observed in information retrieval, text summarization, text classification, machine translation, sentiment analysis and speech recognition.",
              "Initially focus was on feedforward [49] and CNN (convolutional neural network) architecture [69] but later researchers adopted recurrent neural networks to capture the context of a word with respect to surrounding words of a sentence.",
              "LSTM (Long Short-Term Memory), a variant of RNN, is used in various tasks such as word prediction, and sentence topic prediction.",
              "[47] In order to observe the word arrangement in forward and backward direction, bi-directional LSTM is explored by researchers [59].",
              "In case of machine translation, encoder-decoder architecture is used where dimensionality of input and output vector is not known.",
              "Neural networks can be used to anticipate a state that has not yet been seen, such as future states for which predictors exist whereas HMM predicts hidden states.",
              "BERT Bi-directional Encoder Representations from Transformers (BERT) is a pre-trained model with unlabeled text available on BookCorpus and English Wikipedia.",
              "This can be fine-tuned to capture context for various NLP tasks such as question answering, sentiment analysis, text classification, sentence embedding, interpreting ambiguity in the text etc.",
              "[25, 33, 90, 148].",
              "Earlier language-based models examine the text in either of one direction which is used for sentence generation by predicting the next word whereas the BERT model examines the text in both directions simultaneously for better language understanding.",
              "BERT provides contextual embedding for each word present in the text unlike context-free models (word2vec and GloVe).",
              "For example, in the sentences \u201che is going to the riverbank for a walk\u201d and \u201che is going to the bank to withdraw some money\u201d, word2vec will have one vector representation for \u201cbank\u201d in both the sentences whereas BERT will have different vector representation for \u201cbank\u201d.",
              "Muller et al.",
              "[90] used the BERT model to analyze the tweets on covid-19 content.",
              "The use of the BERT model in the legal domain was explored by Chalkidis et al.",
              "[20].",
              "Since BERT considers up to 512 tokens, this is the reason if there is a long text sequence that must be divided into multiple short text sequences of 512 tokens.",
              "This is the limitation of BERT as it lacks in handling large text sequences.",
              "The objective of this section is to discuss evaluation metrics used to evaluate the model\u2019s performance and involved challenges.",
              "Since the number of labels in most classification problems is fixed, it is easy to determine the score for each class and, as a result, the loss from the ground truth.",
              "In image generation problems, the output resolution and ground truth are both fixed.",
              "As a result, we can calculate the loss at the pixel level using ground truth.",
              "But in NLP, though output format is predetermined in the case of NLP, dimensions cannot be specified.",
              "It is because a single statement can be expressed in multiple ways without changing the intent and meaning of that statement.",
              "Evaluation metrics are important to evaluate the model\u2019s performance if we were trying to solve two problems with one model.",
              "BLEU (BiLingual Evaluation Understudy) Score: Each word in the output sentence is scored 1 if it appears in either of the reference sentences and a 0 if it does not.",
              "Further the number of words that appeared in one of the reference translations is divided by the total number of words in the output sentence to normalize the count so that it is always between 0 and 1.",
              "For example, if ground truth is \u201cHe is playing chess in the backyard\u201d and output sentences are S1: \u201cHe is playing tennis in the backyard\u201d, S2: \u201cHe is playing badminton in the backyard\u201d, S3: \u201cHe is playing movie in the backyard\u201d and S4: \u201cbackyard backyard backyard backyard backyard backyard backyard\u201d.",
              "The score of S1, S2 and S3 would be 6/7,6/7 and 6/7.",
              "All sentences are getting the same score though information in S1 and S3 is not same.",
              "This is because BELU considers words in a sentence contribute equally to the meaning of a sentence which is not the case in real-world scenario.",
              "Using combination of uni-gram, bi-gram and n-grams, we can to capture the order of a sentence.",
              "We may also set a limit on how many times each word is counted based on how many times it appears in each reference phrase, which helps us prevent excessive repetition.",
              "GLUE (General Language Understanding Evaluation) score: Previously, NLP models were almost usually built to perform effectively on a unique job.",
              "Various models such as LSTM, Bi-LSTM were trained solely for this task, and very rarely generalized to other tasks.",
              "The model which is used for named entity recognition can perform for textual entailment.",
              "GLUE is a set of datasets for training, assessing, and comparing NLP models.",
              "It includes nine diverse task datasets designed to test a model\u2019s language understanding.",
              "To acquire a comprehensive assessment of a model\u2019s performance, GLUE tests the model on a variety of tasks rather than a single one.",
              "Single-sentence tasks, similarity and paraphrase tasks, and inference tasks are among them.",
              "For example, in sentiment analysis of customer reviews, we might be interested in analyzing ambiguous reviews and determining which product the client is referring to in his reviews.",
              "Thus, the model obtains a good \u201cknowledge\u201d of language in general after some generalized pre-training.",
              "When the time comes to test out a model to meet a given task, this universal \u201cknowledge\u201d gives us an advantage.",
              "With GLUE, researchers can evaluate their model and score it on all nine tasks.",
              "The final performance score model is the average of those nine scores.",
              "It makes little difference how the model looks or works if it can analyze inputs and predict outcomes for all the activities.",
              "Considering these metrics in mind, it helps to evaluate the performance of an NLP model for a particular task or a variety of tasks.",
              "The applications of NLP have been growing day by day, and with these new challenges are also occurring despite a lot of work done in the recent past.",
              "Some of the common challenges are: Contextual words and phrases in the language where same words and phrases can have different meanings in a sentence which are easy for the humans to understand but makes a challenging task.",
              "Such type of challenges can also be faced with dealing Synonyms in the language because humans use many different words to express the same idea, also in the language different levels of complexity such as large, huge, and big may be used by the different persons which become a challenging task to process the language and design algorithms to adopt all these issues.",
              "Further in language, Homonyms, the words used to be pronounced the same but have different definitions are also problematic for question answering and speech-to-text applications because they aren\u2019t written in text form.",
              "Sentences using sarcasm and irony sometimes may be understood in the opposite way by the humans, and so designing models to deal with such sentences is a really challenging task in NLP.",
              "Furthermore, the sentences in the language having any type of ambiguity in the sense of interpreting in more than one way is also an area to work upon where more accuracy can be achieved.",
              "Language containing informal phrases, expressions, idioms, and culture-specific lingo make difficult to design models intended for the broad use, however having a lot of data on which training and updating on regular basis may improve the models, but it is a really challenging task to deal with the words having different meaning in different geographic areas.",
              "In fact, such types of issues also occur in dealing with different domains such as the meaning of words or sentences may be different in the education industry but have different meaning in health, law, defense etc.",
              "So, the models for NLP may be working good for an individual domain, geographic area but for a broad use such challenges need to be tackled.",
              "Further together with the above-mentioned challenges misspelled or misused words can also create a problem, although autocorrect and grammar corrections applications have improved a lot due to the continuous developments in the direction but predicting the intention of the writer that to from a specific domain, geographic area by considering sarcasm, expressions, informal phrases etc.",
              "is really a big challenge.",
              "There is no doubt that for most common widely used languages models for NLP have been doing very well, and further improving day by day but still there is a need for models for all the persons rather than specific knowledge of a particular language and technology.",
              "One may further refer to the work of Sharifirad and Matwin (2019) [123] for classification of different online harassment categories and challenges, Baclic et.",
              "al.",
              "(2020) [6] and Wong et al.",
              "(2018) [151] for challenges and opportunities in public health, Kang et.",
              "al.",
              "(2020) [63] for detailed literature survey and technological challenges relevant to management research and NLP, and a recent review work by Alshemali and Kalita (2020) [3], and references cited there in.",
              "In the recent past, models dealing with Visual Commonsense Reasoning [31] and NLP have also been getting attention of the several researchers and seems a promising and challenging area to work upon.",
              "These models try to extract the information from an image, video using a visual reasoning paradigm such as the humans can infer from a given image, video beyond what is visually obvious, such as objects\u2019 functions, people\u2019s intents, and mental states.",
              "In this direction, recently Wen and Peng (2020) [149] suggested a model to capture knowledge from different perspectives, and perceive common sense in advance, and the results based on the conducted experiments on visual commonsense reasoning dataset VCR seems very satisfactory and effective.",
              "The work of Peng and Chi (2019) [102], that proposes Domain Adaptation with Scene Graph approach to transfer knowledge from the source domain with the objective to improve cross-media retrieval in the target domain, and Yen et al.",
              "(2019) [155] is also very useful to further explore the use of NLP and in its relevant domains.",
              "This paper is written with three objectives.",
              "The first objective gives insights of the various important terminologies of NLP and NLG, and can be useful for the readers interested to start their early career in NLP and work relevant to its applications.",
              "The second objective of this paper focuses on the history, applications, and recent developments in the field of NLP.",
              "The third objective is to discuss datasets, approaches and evaluation metrics used in NLP.",
              "The relevant work done in the existing literature with their findings and some of the important applications and projects in NLP are also discussed in the paper.",
              "The last two objectives may serve as a literature survey for the readers already working in the NLP and relevant fields, and further can provide motivation to explore the fields mentioned in this paper.",
              "It is to be noticed that even though a great amount of work on natural language processing is available in literature surveys (one may refer to [15, 32, 63, 98, 133, 151] focusing on one domain such as usage of deep-learning techniques in NLP, techniques used for email spam filtering, medication safety, management research, intrusion detection, and Gujarati language etc.)",
              ", still there is not much work on regional languages, which can be the focus of future research.",
              "Affiliation 3 has been added into the online PDF.",
              "Ahonen H, Heinonen O, Klemettinen M, Verkamo AI (1998) Applying data mining techniques for descriptive phrase extraction in digital document collections.",
              "In research and technology advances in digital libraries, 1998.",
              "ADL 98.",
              "Proceedings.",
              "IEEE international forum on (pp.",
              "2-11).",
              "IEEE Alshawi H (1992) The core language engine.",
              "MIT press Alshemali B, Kalita J (2020) Improving the reliability of deep neural networks in NLP: A review.",
              "Knowl-Based Syst 191:105210 Article Google Scholar Andreev ND (1967) The intermediary language as the focal point of machine translation.",
              "In: Booth AD (ed) Machine translation.",
              "North Holland Publishing Company, Amsterdam, pp 3\u201327 Google Scholar Androutsopoulos I, Paliouras G, Karkaletsis V, Sakkis G, Spyropoulos CD, Stamatopoulos P (2000) Learning to filter spam e-mail: A comparison of a naive bayesian and a memory-based approach.",
              "arXiv preprint cs/0009009 Baclic O, Tunis M, Young K, Doan C, Swerdfeger H, Schonfeld J (2020) Artificial intelligence in public health: challenges and opportunities for public health made possible by advances in natural language processing.",
              "Can Commun Dis Rep 46(6):161 Article Google Scholar Bahdanau D, Cho K, Bengio Y (2015) Neural machine translation by jointly learning to align and translate.",
              "In ICLR 2015 Bangalore S, Rambow O, Whittaker S (2000) Evaluation metrics for generation.",
              "In proceedings of the first international conference on natural language generation-volume 14 (pp.",
              "1-8).",
              "Assoc Comput Linguist Baud RH, Rassinoux AM, Scherrer JR (1991) Knowledge representation of discharge summaries.",
              "In AIME 91 (pp.",
              "173\u2013182).",
              "Springer, Berlin Heidelberg Google Scholar Baud RH, Rassinoux AM, Scherrer JR (1992) Natural language processing and semantical representation of medical texts.",
              "Methods Inf Med 31(2):117\u2013125 Article Google Scholar Baud RH, Alpay L, Lovis C (1994) Let\u2019s meet the users with natural language understanding.",
              "Knowledge and Decisions in Health Telematics: The Next Decade 12:103 Google Scholar Bengio Y, Ducharme R, Vincent P (2001) A neural probabilistic language model.",
              "Proceedings of NIPS Benson E, Haghighi A, Barzilay R (2011) Event discovery in social media feeds.",
              "In proceedings of the 49th annual meeting of the Association for Computational Linguistics: human language technologies-volume 1 (pp.",
              "389-398).",
              "Assoc Comput Linguist Berger AL, Della Pietra SA, Della Pietra VJ (1996) A maximum entropy approach to natural language processing.",
              "Computational Linguistics 22(1):39\u201371 Google Scholar Blanzieri E, Bryl A (2008) A survey of learning-based techniques of email spam filtering.",
              "Artif Intell Rev 29(1):63\u201392 Article Google Scholar Bondale N, Maloor P, Vaidyanathan A, Sengupta S, Rao PV (1999) Extraction of information from open-ended questionnaires using natural language processing techniques.",
              "Computer Science and Informatics 29(2):15\u201322 Google Scholar Borst F, Sager N, Nha\u0300n NT, Su Y, Lyman M, Tick LJ, .",
              ".",
              ".",
              ", Scherrer JR (1989) Analyse automatique de comptes rendus d'hospitalisation.",
              "In Degoulet P, Stephan JC, Venot A, Yvon PJ, re\u0301dacteurs.",
              "Informatique et Sante\u0301, Informatique et Gestion des Unite\u0301s de Soins, Comptes Rendus du Colloque AIM-IF, Paris (pp.",
              "246\u201356).",
              "[5] Briscoe EJ, Grover C, Boguraev B, Carroll J (1987) A formalism and environment for the development of a large grammar of English.",
              "IJCAI 87:703\u2013708 Google Scholar Carreras X, Marquez L (2001) Boosting trees for anti-spam email filtering.",
              "arXiv preprint cs/0109015 Chalkidis I, Fergadiotis M, Malakasiotis P, Aletras N, Androutsopoulos I (2020) LEGAL-BERT: the muppets straight out of law school.",
              "arXiv preprint arXiv:2010.",
              "02559 Chi EC, Lyman MS, Sager N, Friedman C, Macleod C (1985) A database of computer-structured narrative: methods of computing complex relations.",
              "In proceedings of the annual symposium on computer application in medical care (p.",
              "221).",
              "Am Med Inform Assoc Cho K, Van Merrie\u0308nboer B, Bahdanau D, Bengio Y, (2014) On the properties of neural machine translation: encoder-decoder approaches.",
              "arXiv preprint arXiv:1409.",
              "1259 Chomsky N (1965) Aspects of the theory of syntax.",
              "MIT Press, Cambridge, Massachusetts Google Scholar Choudhary N (2021) LDC-IL: the Indian repository of resources for language technology.",
              "Lang Resources & Evaluation 55:855\u2013867.",
              "https://doi.",
              "org/10.",
              "1007/s10579-020-09523-3 Article Google Scholar Chouikhi H, Chniter H, Jarray F (2021) Arabic sentiment analysis using BERT model.",
              "In international conference on computational collective intelligence (pp.",
              "621-632).",
              "Springer, Cham Google Scholar Chung J, Gulcehre C, Cho K, Bengio Y, (2014) Empirical evaluation of gated recurrent neural networks on sequence modeling.",
              "arXiv preprint arXiv:1412.",
              "3555 Cohen WW (1996) Learning rules that classify e-mail.",
              "In AAAI spring symposium on machine learning in information access (Vol.",
              "18, p.",
              "25) Cohen PR, Morgan J, Ramsay AM (2002) Intention in communication, Am J Psychol 104(4) Collobert R, Weston J (2008) A unified architecture for natural language processing.",
              "In proceedings of the 25th international conference on machine learning (pp.",
              "160\u2013167) Dai Z, Yang Z, Yang Y, Carbonell J, Le QV, Salakhutdinov R, (2019) Transformer-xl: attentive language models beyond a fixed-length context.",
              "arXiv preprint arXiv:1901.",
              "02860 Davis E, Marcus G (2015) Commonsense reasoning and commonsense knowledge in artificial intelligence.",
              "Commun ACM 58(9):92\u2013103 Article Google Scholar Desai NP, Dabhi VK (2022) Resources and components for Gujarati NLP systems: a survey.",
              "Artif Intell Rev:1\u201319 Devlin J, Chang MW, Lee K, Toutanova K, (2018) Bert: pre-training of deep bidirectional transformers for language understanding.",
              "arXiv preprint arXiv:1810.",
              "04805 Diab M, Hacioglu K, Jurafsky D (2004) Automatic tagging of Arabic text: From raw text to base phrase chunks.",
              "In Proceedings of HLT-NAACL 2004: Short papers (pp.",
              "149\u2013152).",
              "Assoc Computat Linguist Doddington G (2002) Automatic evaluation of machine translation quality using n-gram co-occurrence statistics.",
              "In proceedings of the second international conference on human language technology research (pp.",
              "138-145).",
              "Morgan Kaufmann publishers Inc Drucker H, Wu D, Vapnik VN (1999) Support vector machines for spam categorization.",
              "IEEE Trans Neural Netw 10(5):1048\u20131054 Article Google Scholar Dunlavy DM, O\u2019Leary DP, Conroy JM, Schlesinger JD (2007) QCS: A system for querying, clustering and summarizing documents.",
              "Inf Process Manag 43(6):1588\u20131605 Article Google Scholar Elkan C (2008) Log-Linear Models and Conditional Random Fields.",
              "http://cseweb.",
              "ucsd.",
              "edu/welkan/250B/cikmtutorial.",
              "pdf accessed 28 Jun 2017.",
              "Emele MC, Dorna M (1998) Ambiguity preserving machine translation using packed representations.",
              "In proceedings of the 36th annual meeting of the Association for Computational Linguistics and 17th international conference on computational linguistics-volume 1 (pp.",
              "365-371).",
              "Association for Computational Linguistics Europarl: A Parallel Corpus for Statistical Machine Translation (2005) Philipp Koehn, MT Summit 2005 Fan Y, Tian F, Xia Y, Qin T, Li XY, Liu TY (2020) Searching better architectures for neural machine translation.",
              "IEEE/ACM Transactions on Audio, Speech, and Language Processing 28:1574\u20131585 Article Google Scholar Fang H, Lu W, Wu F, Zhang Y, Shang X, Shao J, Zhuang Y (2015) Topic aspect-oriented summarization via group selection.",
              "Neurocomputing 149:1613\u20131619 Article Google Scholar Fattah MA, Ren F (2009) GA, MR, FFNN, PNN and GMM based models for automatic text summarization.",
              "Comput Speech Lang 23(1):126\u2013144 Article Google Scholar Feldman S (1999) NLP meets the jabberwocky: natural language processing in information retrieval.",
              "Online-Weston Then Wilton 23:62\u201373 Google Scholar Friedman C, Cimino JJ, Johnson SB (1993) A conceptual model for clinical radiology reports.",
              "In proceedings of the annual symposium on computer application in medical care (p.",
              "829).",
              "Am Med Inform Assoc Gao T, Dontcheva M, Adar E, Liu Z, Karahalios K DataTone: managing ambiguity in natural language interfaces for data visualization, UIST \u201815: proceedings of the 28th annual ACM symposium on User Interface Software & Technology, November 2015, 489\u2013500, https://doi.",
              "org/10.",
              "1145/2807442.",
              "2807478 Ghosh S, Vinyals O, Strope B, Roy S, Dean T, Heck L (2016) Contextual lstm (clstm) models for large scale nlp tasks.",
              "arXiv preprint arXiv:1602.",
              "06291 Glasgow B, Mandell A, Binney D, Ghemri L, Fisher D (1998) MITA: an information-extraction approach to the analysis of free-form text in life insurance applications.",
              "AI Mag 19(1):59 Google Scholar Goldberg Y (2017) Neural network methods for natural language processing.",
              "Synthesis lectures on human language technologies 10(1):1\u2013309 Article Google Scholar Gong Y, Liu X (2001) Generic text summarization using relevance measure and latent semantic analysis.",
              "In proceedings of the 24th annual international ACM SIGIR conference on research and development in information retrieval (pp.",
              "19-25).",
              "ACM Green Jr, BF, Wolf AK, Chomsky C, Laughery K (1961) Baseball: an automatic question-answerer.",
              "In papers presented at the may 9-11, 1961, western joint IRE-AIEE-ACM computer conference (pp.",
              "219-224).",
              "ACM Greff K, Srivastava RK, Koutni\u0301k J, Steunebrink BR, Schmidhuber J (2016) LSTM: A search space odyssey.",
              "IEEE transactions on neural networks and learning systems 28(10):2222\u20132232 Article MathSciNet Google Scholar Grishman R, Sager N, Raze C, Bookchin B (1973) The linguistic string parser.",
              "In proceedings of the June 4-8, 1973, national computer conference and exposition (pp.",
              "427-434).",
              "ACM Hayes PJ (1992) Intelligent high-volume text processing using shallow, domain-specific techniques.",
              "Text-based intelligent systems: current research and practice in information extraction and retrieval, 227-242.",
              "Hendrix GG, Sacerdoti ED, Sagalowicz D, Slocum J (1978) Developing a natural language interface to complex data.",
              "ACM Transactions on Database Systems (TODS) 3(2):105\u2013147 Article Google Scholar \"Here\u2019s Why Natural Language Processing is the Future of BI (2017) \" SmartData Collective.",
              "N.",
              "p.",
              ", n.",
              "d.",
              "Web.",
              "19 Hirschman L, Grishman R, Sager N (1976) From text to structured information: automatic processing of medical reports.",
              "In proceedings of the June 7-10, 1976, national computer conference and exposition (pp.",
              "267-275).",
              "ACM Hochreiter S, Schmidhuber J (1997) Long short-term memory.",
              "Neural Comput 9(8):1735\u20131780 Article Google Scholar Huang Z, Xu W, Yu K (2015) Bidirectional LSTM-CRF models for sequence tagging.",
              "arXiv preprint arXiv:1508.",
              "01991 Hutchins WJ (1986) Machine translation: past, present, future (p.",
              "66).",
              "Ellis Horwood, Chichester Google Scholar Jurafsky D, Martin J (2008) H.",
              "Speech and language processing.",
              "2nd edn.",
              "Prentice-Hall, Englewood Cliffs, NJ Google Scholar Kamp H, Reyle U (1993) Tense and aspect.",
              "In from discourse to logic (pp.",
              "483-689).",
              "Springer Netherlands Kang Y, Cai Z, Tan CW, Huang Q, Liu H (2020) Natural language processing (NLP) in management research: A literature review.",
              "Journal of Management Analytics 7(2):139\u2013172 Article Google Scholar Kim Y.",
              "(2014) Convolutional neural networks for sentence classification.",
              "arXiv preprint arXiv:1408.",
              "5882 Knight K, Langkilde I (2000) Preserving ambiguities in generation via automata intersection.",
              "In AAAI/IAAI (pp.",
              "697-702) Lass R (1998) Phonology: An Introduction to Basic Concepts.",
              "Cambridge, UK;",
              "New York;",
              "Melbourne, Australia: Cambridge University Press.",
              "p.",
              "1.",
              "ISBN 978\u20130\u2013521-23728-4.",
              "Retrieved 8 January 2011Paperback ISBN 0\u2013521\u201328183-0 Lewis DD (1998) Naive (Bayes) at forty: The independence assumption in information retrieval.",
              "In European conference on machine learning (pp.",
              "4\u201315).",
              "Springer, Berlin Heidelberg Google Scholar Liddy ED (2001).",
              "Natural language processing Lopez MM, Kalita J (2017) Deep learning applied to NLP.",
              "arXiv preprint arXiv:1703.",
              "03091 Luong MT, Sutskever I, Le Q V, Vinyals O, Zaremba W (2014) Addressing the rare word problem in neural machine translation.",
              "arXiv preprint arXiv:1410.",
              "8206 Lyman M, Sager N, Friedman C, Chi E (1985) Computer-structured narrative in ambulatory care: its use in longitudinal review of clinical data.",
              "In proceedings of the annual symposium on computer application in medical care (p.",
              "82).",
              "Am Med Inform Assoc Lyman M, Sager N, Chi EC, Tick LJ, Nhan NT, Su Y, .",
              ".",
              ".",
              ", Scherrer, J.",
              "(1989) Medical Language Processing for Knowledge Representation and Retrievals.",
              "In Proceedings.",
              "Symposium on Computer Applications in Medical Care (pp.",
              "548\u2013553).",
              "Am Med Inform Assoc Maas A, Daly RE, Pham PT, Huang D, Ng AY, Potts C (2011) Learning word vectors for sentiment analysis.",
              "In proceedings of the 49th annual meeting of the association for computational linguistics: human language technologies (pp.",
              "142-150) Mani I, Maybury MT (eds) (1999) Advances in automatic text summarization, vol 293.",
              "MIT press, Cambridge, MA Google Scholar Manning CD, Schu\u0308tze H (1999) Foundations of statistical natural language processing, vol 999.",
              "MIT press, Cambridge MATH Google Scholar Marcus MP, Marcinkiewicz MA, Santorini B (1993) Building a large annotated corpus of english: the penn treebank.",
              "Comput Linguist 19(2):313\u2013330 Google Scholar McCallum A, Nigam K (1998) A comparison of event models for naive bayes text classification.",
              "In AAAI-98 workshop on learning for text categorization (Vol.",
              "752, pp.",
              "41-48) McCray AT (1991) Natural language processing for intelligent information retrieval.",
              "In Engineering in Medicine and Biology Society, 1991.",
              "Vol.",
              "13: 1991.",
              ", Proceedings of the Annual International Conference of the IEEE (pp.",
              "1160\u20131161).",
              "IEEE McCray AT (1991) Extending a natural language parser with UMLS knowledge.",
              "In proceedings of the annual symposium on computer application in medical care (p.",
              "194).",
              "Am Med Inform Assoc McCray AT, Nelson SJ (1995) The representation of meaning in the UMLS.",
              "Methods Inf Med 34(1\u20132):193\u2013201 Google Scholar McCray AT, Razi A (1994) The UMLS knowledge source server.",
              "Medinfo MedInfo 8:144\u2013147 Google Scholar McCray AT, Srinivasan S, Browne AC (1994) Lexical methods for managing variation in biomedical terminologies.",
              "In proceedings of the annual symposium on computer application in medical care (p.",
              "235).",
              "Am Med Inform Assoc McDonald R, Crammer K, Pereira F (2005) Flexible text segmentation with structured multilabel classification.",
              "In proceedings of the conference on human language technology and empirical methods in natural language processing (pp.",
              "987-994).",
              "Assoc Comput Linguist McGray AT, Sponsler JL, Brylawski B, Browne AC (1987) The role of lexical knowledge in biomedical text understanding.",
              "In proceedings of the annual symposium on computer application in medical care (p.",
              "103).",
              "Am Med Inform Assoc McKeown KR (1985) Text generation.",
              "Cambridge University Press, Cambridge Book Google Scholar Merity S, Keskar NS, Socher R (2018) An analysis of neural language modeling at multiple scales.",
              "arXiv preprint arXiv:1803.",
              "08240 Mikolov T, Chen K, Corrado G.",
              ", & Dean, J.",
              "(2013).",
              "Distributed representations of words and phrases and their compositionality.",
              "In Advances in Neural Information Processing Systems Morel-Guillemaz AM, Baud RH, Scherrer JR (1990) Proximity processing of medical text.",
              "In medical informatics Europe\u201990 (pp.",
              "625\u2013630).",
              "Springer, Berlin Heidelberg Google Scholar Morin E (1999) Automatic acquisition of semantic relations between terms from technical corpora.",
              "In proc.",
              "of the fifth international congress on terminology and knowledge engineering-TKE\u201999 Mu\u0308ller M, Salathe\u0301 M, Kummervold PE (2020) Covid-twitter-bert: A natural language processing model to analyse covid-19 content on twitter.",
              "arXiv preprint arXiv:2005.",
              "07503 \"Natural Language Processing (2017) \" Natural Language Processing RSS.",
              "N.",
              "p.",
              ", n.",
              "d.",
              "Web.",
              "25 \"Natural Language Processing\" (2017) Natural Language Processing RSS.",
              "N.",
              "p.",
              ", n.",
              "d.",
              "Web.",
              "23 Newatia R (2019) https://medium.",
              "com/saarthi-ai/sentence-classification-using-convolutional-neural-networks-ddad72c7048c.",
              "Accessed 15 Dec 2021 Nha\u0300n NT, Sager N, Lyman M, Tick LJ, Borst F, Su Y (1989) A medical language processor for two indo-European languages.",
              "In proceedings.",
              "Symposium on computer applications in medical care (pp.",
              "554-558).",
              "Am Med Inform Assoc Nie\u00dfen S, Och FJ, Leusch G, Ney H (2000) An evaluation tool for machine translation: fast evaluation for MT research.",
              "In LREC Ochoa, A.",
              "(2016).",
              "Meet the Pilot: Smart Earpiece Language Translator.",
              "https://www.",
              "indiegogo.",
              "com/projects/meet-the-pilot-smart-earpiece-language-translator-headphones-travel.",
              "Accessed April 10, 2017 Ogallo, W.",
              ", & Kanter, A.",
              "S.",
              "(2017).",
              "Using natural language processing and network analysis to develop a conceptual framework for medication therapy management research.",
              "https://www.",
              "ncbi.",
              "nlm.",
              "nih.",
              "gov/pubmed/28269895?",
              "dopt=Abstract.",
              "Accessed April 10, 2017 Otter DW, Medina JR, Kalita JK (2020) A survey of the usages of deep learning for natural language processing.",
              "IEEE Transactions on Neural Networks and Learning Systems 32(2):604\u2013624 Article MathSciNet Google Scholar Ouyang Y, Li W, Li S, Lu Q (2011) Applying regression models to query-focused multi-document summarization.",
              "Inf Process Manag 47(2):227\u2013237 Article Google Scholar Palmer M, Gildea D, Kingsbury P (2005) The proposition bank: an annotated corpus of semantic roles.",
              "Computational linguistics 31(1):71\u2013106 Article Google Scholar Papineni K, Roukos S, Ward T, Zhu WJ (2002) BLEU: a method for automatic evaluation of machine translation.",
              "In proceedings of the 40th annual meeting on association for computational linguistics (pp.",
              "311-318).",
              "Assoc Comput Linguist Peng Y, Chi J (2019) Unsupervised cross-media retrieval using domain adaptation with scene graph.",
              "IEEE Transactions on Circuits and Systems for Video Technology 30(11):4368\u20134379 Article Google Scholar Porter MF (1980) An algorithm for suffix stripping.",
              "Program 14(3):130\u2013137 Article Google Scholar Rae JW, Potapenko A, Jayakumar SM, Lillicrap TP, (2019) Compressive transformers for long-range sequence modelling.",
              "arXiv preprint arXiv:1911.",
              "05507 Ranjan P, Basu HVSSA (2003) Part of speech tagging and local word grouping techniques for natural language parsing in Hindi.",
              "In Proceedings of the 1st International Conference on Natural Language Processing (ICON 2003) Rassinoux AM, Baud RH, Scherrer JR (1992) Conceptual graphs model extension for knowledge representation of medical texts.",
              "MEDINFO 92:1368\u20131374 Google Scholar Rassinoux AM, Michel PA, Juge C, Baud R, Scherrer JR (1994) Natural language processing of medical texts within the HELIOS environment.",
              "Comput Methods Prog Biomed 45:S79\u2013S96 Google Scholar Rassinoux AM, Juge C, Michel PA, Baud RH, Lemaitre D, Jean FC, Scherrer JR (1995) Analysis of medical jargon: The RECIT system.",
              "In Conference on Artificial Intelligence in Medicine in Europe (pp.",
              "42\u201352).",
              "Springer, Berlin Heidelberg Google Scholar Rennie J (2000) ifile: An application of machine learning to e-mail filtering.",
              "In Proc.",
              "KDD 2000 Workshop on text mining, Boston, MA Riedhammer K, Favre B, Hakkani-Tu\u0308r D (2010) Long story short\u2013global unsupervised models for keyphrase based meeting summarization.",
              "Speech Comm 52(10):801\u2013815 Article Google Scholar Ritter A, Clark S, Etzioni O (2011) Named entity recognition in tweets: an experimental study.",
              "In proceedings of the conference on empirical methods in natural language processing (pp.",
              "1524-1534).",
              "Assoc Comput Linguist Rospocher M, van Erp M, Vossen P, Fokkens A, Aldabe I, Rigau G, Soroa A, Ploeger T, Bogaard T(2016) Building event-centric knowledge graphs from news.",
              "Web Semantics: Science, Services and Agents on the World Wide Web, In Press Sager N, Lyman M, Tick LJ, Borst F, Nhan NT, Revillard C, .",
              ".",
              ".",
              "Scherrer JR (1989) Adapting a medical language processor from English to French.",
              "Medinfo 89:795\u2013799 Google Scholar Sager N, Lyman M, Nhan NT, Tick LJ (1995) Medical language processing: applications to patient data representation and automatic encoding.",
              "Methods Inf Med 34(1\u20132):140\u2013146 Google Scholar Sahami M, Dumais S, Heckerman D, Horvitz E (1998) A Bayesian approach to filtering junk e-mail.",
              "In learning for text categorization: papers from the 1998 workshop (Vol.",
              "62, pp.",
              "98-105) Sakkis G, Androutsopoulos I, Paliouras G, Karkaletsis V, Spyropoulos CD, Stamatopoulos P (2001) Stacking classifiers for anti-spam filtering of e-mail.",
              "arXiv preprint cs/0106040 Sakkis G, Androutsopoulos I, Paliouras G et al (2003) A memory-based approach to anti-spam filtering for mailing lists.",
              "Inf Retr 6:49\u201373.",
              "https://doi.",
              "org/10.",
              "1023/A:1022948414856 Article Google Scholar Santoro A, Faulkner R, Raposo D, Rae J, Chrzanowski M, Weber T, .",
              ".",
              ".",
              ", Lillicrap T (2018) Relational recurrent neural networks.",
              "Adv Neural Inf Proces Syst, 31 Scherrer JR, Revillard C, Borst F, Berthoud M, Lovis C (1994) Medical office automation integrated into the distributed architecture of a hospital information system.",
              "Methods Inf Med 33(2):174\u2013179 Article Google Scholar Seal D, Roy UK, Basak R (2020) Sentence-level emotion detection from text based on semantic rules.",
              "In: Tuba M, Akashe S, Joshi A (eds) Information and communication Technology for Sustainable Development.",
              "Advances in intelligent Systems and computing, vol 933.",
              "Springer, Singapore.",
              "https://doi.",
              "org/10.",
              "1007/978-981-13-7166-0_42 Chapter Google Scholar Sentiraama Corpus by Gangula Rama Rohit Reddy, Radhika Mamidi.",
              "Language Technologies Research Centre, KCIS, IIIT Hyderabad (n.",
              "d.)",
              "ltrc.",
              "iiit.",
              "ac.",
              "in/showfile.",
              "php?",
              "filename=downloads/sentiraama/ Sha F, Pereira F (2003) Shallow parsing with conditional random fields.",
              "In proceedings of the 2003 conference of the north American chapter of the Association for Computational Linguistics on human language technology-volume 1 (pp.",
              "134-141).",
              "Assoc Comput Linguist Sharifirad S, Matwin S, (2019) When a tweet is actually sexist.",
              "A more comprehensive classification of different online harassment categories and the challenges in NLP.",
              "arXiv preprint arXiv:1902.",
              "10584 Sharma S, Srinivas PYKL, Balabantaray RC (2016) Emotion Detection using Online Machine Learning Method and TLBO on Mixed Script.",
              "In Proceedings of Language Resources and Evaluation Conference 2016 (pp.",
              "47\u201351) Shemtov H (1997) Ambiguity management in natural language generation.",
              "Stanford University Small SL, Cortell GW, Tanenhaus MK (1988) Lexical Ambiguity Resolutions.",
              "Morgan Kauffman, San Mateo, CA Google Scholar Socher R, Perelygin A, Wu J, Chuang J, Manning CD, Ng AY, Potts C (2013) Recursive deep models for semantic compositionality over a sentiment treebank.",
              "In proceedings of the 2013 conference on empirical methods in natural language processing (pp.",
              "1631-1642) Sonnhammer EL, Eddy SR, Birney E, Bateman A, Durbin R (1998) Pfam: multiple sequence alignments and HMM-profiles of protein domains.",
              "Nucleic Acids Res 26(1):320\u2013322 Article Google Scholar Srihari S (2010) Machine Learning: Generative and Discriminative Models.",
              "http://www.",
              "cedar.",
              "buffalo.",
              "edu/wsrihari/CSE574/Discriminative-Generative.",
              "pdf.",
              "accessed 31 May 2017.]",
              "Sun X, Morency LP, Okanohara D, Tsujii JI (2008) Modeling latent-dynamic in shallow parsing: a latent conditional model with improved inference.",
              "In proceedings of the 22nd international conference on computational linguistics-volume 1 (pp.",
              "841-848).",
              "Assoc Comput Linguist Sundheim BM, Chinchor NA (1993) Survey of the message understanding conferences.",
              "In proceedings of the workshop on human language technology (pp.",
              "56-60).",
              "Assoc Comput Linguist Sutskever I, Vinyals O, Le QV (2014) Sequence to sequence learning with neural networks.",
              "In Advances in Neural Information Processing Systems Sworna ZT, Mousavi Z, Babar MA (2022) NLP methods in host-based intrusion detection Systems: A systematic review and future directions.",
              "arXiv preprint arXiv:2201.",
              "08066 Systems RAVN (2017) \"RAVN Systems Launch the ACE Powered GDPR Robot - Artificial Intelligence to Expedite GDPR Compliance.\"",
              "Stock Market.",
              "PR Newswire, n.",
              "d.",
              "Web.",
              "19 Tan KL, Lee CP, Anbananthen KSM, Lim KM (2022) RoBERTa-LSTM: A hybrid model for sentiment analysis with transformers and recurrent neural network.",
              "IEEE Access, RoBERTa-LSTM: A Hybrid Model for Sentiment Analysis With Transformer and Recurrent Neural Network Tapaswi N, Jain S (2012) Treebank based deep grammar acquisition and part-of-speech tagging for Sanskrit sentences.",
              "In software engineering (CONSEG), 2012 CSI sixth international conference on (pp.",
              "1-4).",
              "IEEE Thomas C (2019) https://towardsdatascience.",
              "com/recurrent-neural-networks-and-natural-language-processing-73af640c2aa1.",
              "Accessed 15 Dec 2021 Tillmann C, Vogel S, Ney H, Zubiaga A, Sawaf H (1997) Accelerated DP based search for statistical translation.",
              "In Eurospeech Umber A, Bajwa I (2011) \u201cMinimizing ambiguity in natural language software requirements specification,\u201d in Sixth Int Conf Digit Inf Manag, pp.",
              "102\u2013107 \"Using Natural Language Processing and Network Analysis to Develop a Conceptual Framework for Medication Therapy Management Research (2017) \" AMIA .",
              ".",
              ".",
              "Annual Symposium proceedings.",
              "AMIA Symposium.",
              "U.",
              "S.",
              "National Library of Medicine, n.",
              "d.",
              "Web.",
              "19 Vaswani A, Shazeer N, Parmar N, Uszkoreit J, Jones L, Gomez AN, Kaiser \u0141, Polosukhin I, (2017) Attention is all you need.",
              "In advances in neural information processing systems (pp.",
              "5998-6008) Wahlster W, Kobsa A (1989) User models in dialog systems. In user models in dialog systems (pp.",
              "4\u201334).",
              "Springer Berlin Heidelberg, User Models in Dialog Systems Walton D (1996) A pragmatic synthesis.",
              "In: fallacies arising from ambiguity.",
              "Applied logic series, vol 1.",
              "Springer, Dordrecht) Wan X (2008) Using only cross-document relationships for both generic and topic-focused multi-document summarizations.",
              "Inf Retr 11(1):25\u201349 Article Google Scholar Wang W, Gang J, 2018 Application of convolutional neural network in natural language processing.",
              "In 2018 international conference on information Systems and computer aided education (ICISCAE) (pp.",
              "64-70).",
              "IEEE Wang D, Zhu S, Li T, Gong Y (2009) Multi-document summarization using sentence-based topic models.",
              "In proceedings of the ACL-IJCNLP 2009 conference short papers (pp.",
              "297-300).",
              "Assoc Comput Linguist Wang D, Zhu S, Li T, Chi Y, Gong Y (2011) Integrating document clustering and multidocument summarization.",
              "ACM Transactions on Knowledge Discovery from Data (TKDD) 5(3):14\u201326 Article Google Scholar Wang Z, Ng P, Ma X, Nallapati R, Xiang B (2019) Multi-passage bert: A globally normalized bert model for open-domain question answering.",
              "arXiv preprint arXiv:1908.",
              "08167 Wen Z, Peng Y (2020) Multi-level knowledge injecting for visual commonsense reasoning.",
              "IEEE Transactions on Circuits and Systems for Video Technology 31(3):1042\u20131054 Article MathSciNet Google Scholar Wiese G, Weissenborn D, Neves M (2017) Neural domain adaptation for biomedical question answering.",
              "arXiv preprint arXiv:1706.",
              "03610 Wong A, Plasek JM, Montecalvo SP, Zhou L (2018) Natural language processing and its implications for the future of medication safety: a narrative review of recent advances and challenges.",
              "Pharmacotherapy: The Journal of Human Pharmacology and Drug Therapy 38(8):822\u2013841 Article Google Scholar Woods WA (1978) Semantics and quantification in natural language question answering.",
              "Adv Comput 17:1\u201387 Article Google Scholar Xia T (2020) A constant time complexity spam detection algorithm for boosting throughput on rule-based filtering Systems. IEEE Access 8:82653\u201382661.",
              "https://doi.",
              "org/10.",
              "1109/ACCESS.",
              "2020.",
              "2991328 Article Google Scholar Xie P, Xing E (2017) A constituent-centric neural architecture for reading comprehension.",
              "In proceedings of the 55th annual meeting of the Association for Computational Linguistics (volume 1: long papers) (pp.",
              "1405-1414) Yan X, Ye Y, Mao Y, Yu H (2019) Shared-private information bottleneck method for cross-modal clustering.",
              "IEEE Access 7:36045\u201336056 Article Google Scholar Yi J, Nasukawa T, Bunescu R, Niblack W (2003) Sentiment analyzer: extracting sentiments about a given topic using natural language processing techniques.",
              "In data mining, 2003.",
              "ICDM 2003.",
              "Third IEEE international conference on (pp.",
              "427-434).",
              "IEEE Young SJ, Chase LL (1998) Speech recognition evaluation: a review of the US CSR and LVCSR programmes.",
              "Comput Speech Lang 12(4):263\u2013279 Article Google Scholar Yu S, et al.",
              "(2018) \"A multi-stage memory augmented neural network for machine reading comprehension.\"",
              "Proceedings of the workshop on machine reading for question answering Zajic DM, Dorr BJ, Lin J (2008) Single-document and multi-document summarization techniques for email threads using sentence compression.",
              "Inf Process Manag 44(4):1600\u20131610 Article Google Scholar Zeroual I, Lakhouaja A, Belahbib R (2017) Towards a standard part of speech tagset for the Arabic language.",
              "J King Saud Univ Comput Inf Sci 29(2):171\u2013178 Google Scholar Download references Authors would like to express the gratitude to Research Mentors from CL Educate: Accendere Knowledge Management Services Pvt.",
              "Ltd.",
              "for their comments on earlier versions of the manuscript.",
              "Although any errors are our own and should not tarnish the reputations of these esteemed persons.",
              "We would also like to appreciate the Editor, Associate Editor, and anonymous referees for their constructive suggestions that led to many improvements on an earlier version of this manuscript.",
              "Department of Computer Science, Manav Rachna International Institute of Research and Studies, Faridabad, India Diksha Khurana & Aditya Koli Department of Computer Science, BML Munjal University, Gurgaon, India Kiran Khatter Department of Statistics, Amity University Punjab, Mohali, India Sukhdev Singh You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar Correspondence to Kiran Khatter.",
              "The first draft of this paper was written under the supervision of Dr.",
              "Kiran Khatter and Dr.",
              "Sukhdev Singh, associated with CL- Educate: Accendere Knowledge Management Services Pvt.",
              "Ltd.",
              "and deputed at the Manav Rachna International University.",
              "The draft is also available on arxiv.",
              "org at https://arxiv.",
              "org/abs/1708.",
              "05148 Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.",
              "Springer Nature or its licensor holds exclusive rights to this article under a publishing agreement with the author(s) or other rightsholder(s);",
              "author self-archiving of the accepted manuscript version of this article is solely governed by the terms of such publishing agreement and applicable law.",
              "Reprints and permissions Khurana, D.",
              ", Koli, A.",
              ", Khatter, K.",
              "et al.",
              "Natural language processing: state of the art, current trends and challenges.",
              "Multimed Tools Appl 82, 3713\u20133744 (2023).",
              "https://doi.",
              "org/10.",
              "1007/s11042-022-13428-4 Download citation Received: 03 February 2021 Revised: 23 March 2022 Accepted: 02 July 2022 Published: 14 July 2022 Issue Date: January 2023 DOI: https://doi.",
              "org/10.",
              "1007/s11042-022-13428-4 Anyone you share the following link with will be able to read this content: Sorry, a shareable link is not currently available for this article.",
              "Provided by the Springer Nature SharedIt content-sharing initiative Avoid common mistakes on your manuscript.",
              "Advertisement 205.",
              "172.",
              "168.",
              "145 University of Massachusetts Amherst W.",
              "E.",
              "B.",
              "Du Bois Library (8200177774) - NorthEast Research Libraries (NERL) (8200828607) \u00a9 2024 Springer Nature"
            ]
          },
          {
            "title": "A Comprehensive Guide to Natural Language Processing Text Summarization ...",
            "url": "https://machinemindmatters.com/posts/nlp-text-summarization-guide/",
            "content": [
              "A Comprehensive Guide to Natural Language Processing Text Summarization ...",
              " Natural language processing (NLP) is a branch of artificial intelligence that deals with understanding and analyzing natural language.",
              "It is used to process large amounts of data and extract meaningful insights from it.",
              "NLP can be used to solve various problems, such as text summarization, sentiment analysis, machine translation, and many more.",
              "In this blog post, we will explore one such application of NLP: text summarization.",
              "Text summarization is the process of reducing a long piece of text into a shorter summary while preserving the most important information.",
              "It has various applications in fields like news aggregation, document analysis, question answering systems etc.",
              "We will discuss how NLP works for text summarization and its benefits over traditional methods.",
              "We will also look at different types of NLP techniques for text summarization and their applications in various domains.",
              "Finally, we will address some challenges that are encountered when implementing these techniques as well as best practices for using them effectively.",
              "Natural language processing (NLP) text summarization is a process of automatically extracting the most important information from a given text to create a short summary.",
              "This can be done using various techniques, such as keyword extraction and sentence compression.",
              "In both cases, an algorithm is used to identify the key topics and ideas in the text and then generate a concise summary that captures them.",
              "In keyword extraction, an algorithm looks for words that appear frequently throughout the document and extracts them as keywords.",
              "The key phrases are then used to determine which sentences contain these concepts and generate a summary based on those sentences.",
              "Sentence compression involves understanding each sentence in the original document and determining which ones are essential for conveying its main idea.",
              "These important sentences are identified using algorithms like Dependency Parsing or TextRank, which analyze how each sentence relates to others in the document.",
              "Once these key points have been extracted, they can be re-written into shorter summaries that capture the same meaning as the original source material.",
              "NLP text summarization is a powerful tool that provides many advantages over traditional summarization techniques.",
              "Here are some of the benefits of using an NLP-based approach to text summarization: Increased Efficiency \u2013 NLP-based text summarization allows for faster and more efficient extraction of key information from large volumes of data.",
              "This can greatly reduce time spent manually reading and analyzing documents or webpages, saving both time and resources.",
              "Improved Accuracy \u2013 By leveraging sophisticated algorithms, NLP-based text summarizers can deliver results with greater accuracy than manual methods.",
              "NLP models are able to learn from their mistakes and improve over time, leading to more reliable results than human judgement alone.",
              "Easier Customization \u2013 With traditional methods, creating custom summaries requires extensive programming knowledge as well as trial and error testing before getting satisfactory results.",
              "However, with NLP-based approaches this process is much simpler since the input data needs only to be fed into the model which automatically generates a summary tailored to user preferences such as length or content relevance.",
              "More Natural Outputs \u2013 Since these models use natural language processing techniques they are able to produce output in a more natural form rather than just extracting keywords or phrases from the original source material like manual approaches do Natural language processing (NLP) text summarization involves the use of advanced algorithms to identify and extract the most important information from a text document.",
              "There are several different techniques used for NLP text summarization, including extractive and abstractive summarization.",
              "Extractive Summarization: Extractive summarization uses existing words, phrases, and sentences from the original text to create a summary.",
              "This type of summarization relies on identifying key terms and topics in order to form an accurate representation of the original content.",
              "It is considered more reliable than abstractive summarization because it allows users to see exactly what was written in the source material.",
              "Abstractive Summarization: Abstractive summarization goes beyond simply extracting existing words, phrases, and sentences;",
              "it also includes generating new words or phrases that capture the main points of a text document without changing its meaning.",
              "This technique requires sophisticated algorithms that can understand context as well as recognize patterns in order to generate summary statements that accurately reflect the original content.",
              "It should be noted that both extractive and abstractive summaries come with their own set of advantages and disadvantages.",
              "Extractive summaries are often more reliable since they rely on exact words from the source material, but may not always provide accurate representations due to limitations in understanding context or recognizing subtle nuances in tone or meaning.",
              "Abstractive summaries can provide more comprehensive overviews due to their ability to generate new content but may not always capture all aspects of a document\u2019s contents accurately due to inherent algorithmic limitations.",
              "Natural language processing (NLP) text summarization has numerous potential applications in a wide range of fields.",
              "The most common applications include: -News Aggregation: NLP can be used to automatically summarize news articles, giving readers a concise overview of the latest news.",
              "This reduces the time needed to read multiple long articles, enabling people to stay up-to-date with current events quickly and efficiently.",
              "-Search Engine Results: Search engines such as Google use NLP algorithms to generate summaries for search results, allowing users to quickly understand what a website is about without having to click on every link.",
              "-Business Intelligence: Companies can utilize NLP text summarization to extract important insights from large volumes of customer feedback or internal documents.",
              "This enables them to quickly identify key trends in customer sentiment or uncover new opportunities for growth.",
              "-Document Management: Text summarization can be used to classify and organize documents more effectively, making it easier for businesses and organizations to find relevant information when they need it.",
              "While NLP text summarization is a powerful tool for automatically summarizing texts, there are some challenges that need to be taken into account when implementing this technology.",
              "The first challenge lies in the fact that natural language processing algorithms can often produce summaries that lack coherence and readability.",
              "This means that while these summaries may accurately convey the main ideas of the original text, they may not be as clear and informative as one would like.",
              "As such, it is important to test out different approaches and techniques before settling on one particular method of text summarization.",
              "Another challenge has to do with the accuracy of the summary produced by an NLP algorithm.",
              "Even if an algorithm produces a coherent and readable summary, it may still fail to capture all of the nuances and details contained in the original text.",
              "For example, certain words or phrases might have been omitted from the summary due to their complexity or length.",
              "It is important for users to keep this limitation in mind when using NLP text summarization tools so that they can make sure that all of the necessary information from a source document is included in its summary.",
              "Finally, there is also an issue related to data privacy when using NLP algorithms for text summarization.",
              "Since this technology involves analyzing large amounts of data, users must ensure that any confidential information contained within source documents remains secure at all times during processing.",
              "Additionally, appropriate measures should be taken to protect sensitive user data from unauthorized access or manipulation by malicious actors.",
              "When using NLP text summarization, it\u2019s important to take into account the different types of techniques and applications available.",
              "Additionally, there are a few best practices to follow in order to get the most out of your NLP text summarization efforts.",
              "First, consider the size of the text you\u2019re looking to summarize.",
              "Different techniques and applications can work better with shorter or longer texts;",
              "for example, if you have a lengthy document that needs summarizing, abstractive techniques might be more effective than extractive ones.",
              "Next, pay attention to which words are used when creating summaries.",
              "Automated summarization algorithms can sometimes use words that don\u2019t accurately capture the meaning of the original text;",
              "as such, it\u2019s important to read through each summary carefully before incorporating it into any other project or publication.",
              "Finally, keep track of how well certain techniques and applications perform on different types of texts and documents.",
              "This data can help inform your decisions when creating summaries in future tasks;",
              "by keeping records of what works best for certain projects and texts, you can save time in having to re-evaluate which type of technique is most appropriate for each new task.",
              "Natural Language Processing (NLP) text summarization is a powerful tool that can help organizations quickly and effectively summarize large amounts of text.",
              "This technology has a wide range of applications, including helping to improve customer service, streamline the analysis of customer feedback, and make it easier to draw insights from data.",
              "However, NLP text summarization also comes with some challenges.",
              "It requires an understanding of natural language processing techniques and algorithms as well as access to appropriate data sets for training.",
              "Additionally, there are best practices that need to be followed when using this technology in order to ensure accurate results.",
              "Overall, NLP text summarization is an important part of any organization\u2019s digital transformation journey.",
              "By leveraging this technology appropriately, organizations can gain valuable insights from their data more efficiently than ever before.",
              "Related"
            ]
          }
        ],
        "AlphaGoZero is a program that learned to play the game of Go from scratch and defeated the world champion.": [
          {
            "title": "AlphaGo Zero - Wikipedia",
            "url": "https://en.wikipedia.org/wiki/AlphaGo_Zero",
            "content": [
              "AlphaGo Zero - Wikipedia",
              "AlphaGo Zero is a version of DeepMind's Go software AlphaGo.",
              "AlphaGo's team published an article in the journal Nature on 19 October 2017, introducing AlphaGo Zero, a version created without using data from human games, and stronger than any previous version.",
              "[1] By playing games against itself, AlphaGo Zero surpassed the strength of AlphaGo Lee in three days by winning 100 games to 0, reached the level of AlphaGo Master in 21 days, and exceeded all the old versions in 40 days.",
              "[2] Training artificial intelligence (AI) without datasets derived from human experts has significant implications for the development of AI with superhuman skills because expert data is \"often expensive, unreliable or simply unavailable.\"",
              "[3] Demis Hassabis, the co-founder and CEO of DeepMind, said that AlphaGo Zero was so powerful because it was \"no longer constrained by the limits of human knowledge\".",
              "[4] Furthermore, AlphaGo Zero performed better than standard reinforcement deep learning models (such as DQN implementations[5]) due to its integration of Monte Carlo tree search.",
              "David Silver, one of the first authors of DeepMind's papers published in Nature on AlphaGo, said that it is possible to have generalised AI algorithms by removing the need to learn from humans.",
              "[6] Google later developed AlphaZero, a generalized version of AlphaGo Zero that could play chess and Sho\u0304gi in addition to Go.",
              "In December 2017, AlphaZero beat the 3-day version of AlphaGo Zero by winning 60 games to 40, and with 8 hours of training it outperformed AlphaGo Lee on an Elo scale.",
              "AlphaZero also defeated a top chess program (Stockfish) and a top Sho\u0304gi program (Elmo).",
              "[7][8] AlphaGo Zero's neural network was trained using TensorFlow, with 64 GPU workers and 19 CPU parameter servers.",
              "Only four TPUs were used for inference.",
              "The neural network initially knew nothing about Go beyond the rules.",
              "Unlike earlier versions of AlphaGo, Zero only perceived the board's stones, rather than having some rare human-programmed edge cases to help recognize unusual Go board positions.",
              "The AI engaged in reinforcement learning, playing against itself until it could anticipate its own moves and how those moves would affect the game's outcome.",
              "[9] In the first three days AlphaGo Zero played 4.",
              "9 million games against itself in quick succession.",
              "[10] It appeared to develop the skills required to beat top humans within just a few days, whereas the earlier AlphaGo took months of training to achieve the same level.",
              "[11] For comparison, the researchers also trained a version of AlphaGo Zero using human games, AlphaGo Master, and found that it learned more quickly, but actually performed more poorly in the long run.",
              "[12] DeepMind submitted its initial findings in a paper to Nature in April 2017, which was then published in October 2017.",
              "[1] The hardware cost for a single AlphaGo Zero system in 2017, including the four TPUs, has been quoted as around $25 million.",
              "[13] According to Hassabis, AlphaGo's algorithms are likely to be of the most benefit to domains that require an intelligent search through an enormous space of possibilities, such as protein folding (see AlphaFold) or accurately simulating chemical reactions.",
              "[14] AlphaGo's techniques are probably less useful in domains that are difficult to simulate, such as learning how to drive a car.",
              "[15] DeepMind stated in October 2017 that it had already started active work on attempting to use AlphaGo Zero technology for protein folding, and stated it would soon publish new findings.",
              "[16][17] AlphaGo Zero was widely regarded as a significant advance, even when compared with its groundbreaking predecessor, AlphaGo.",
              "Oren Etzioni of the Allen Institute for Artificial Intelligence called AlphaGo Zero \"a very impressive technical result\" in \"both their ability to do it\u2014and their ability to train the system in 40 days, on four TPUs\".",
              "[9] The Guardian called it a \"major breakthrough for artificial intelligence\", citing Eleni Vasilaki of Sheffield University and Tom Mitchell of Carnegie Mellon University, who called it an impressive feat and an \u201coutstanding engineering accomplishment\" respectively.",
              "[15] Mark Pesce of the University of Sydney called AlphaGo Zero \"a big technological advance\" taking us into \"undiscovered territory\".",
              "[18] Gary Marcus, a psychologist at New York University, has cautioned that for all we know, AlphaGo may contain \"implicit knowledge that the programmers have about how to construct machines to play problems like Go\" and will need to be tested in other domains before being sure that its base architecture is effective at much more than playing Go.",
              "In contrast, DeepMind is \"confident that this approach is generalisable to a large number of domains\".",
              "[10] In response to the reports, South Korean Go professional Lee Sedol said, \"The previous version of AlphaGo wasn\u2019t perfect, and I believe that\u2019s why AlphaGo Zero was made.\"",
              "On the potential for AlphaGo's development, Lee said he will have to wait and see but also said it will affect young Go players.",
              "Mok Jin-seok, who directs the South Korean national Go team, said the Go world has already been imitating the playing styles of previous versions of AlphaGo and creating new ideas from them, and he is hopeful that new ideas will come out from AlphaGo Zero.",
              "Mok also added that general trends in the Go world are now being influenced by AlphaGo's playing style.",
              "\"At first, it was hard to understand and I almost felt like I was playing against an alien.",
              "However, having had a great amount of experience, I\u2019ve become used to it,\" Mok said.",
              "\"We are now past the point where we debate the gap between the capability of AlphaGo and humans.",
              "It\u2019s now between computers.\"",
              "Mok has reportedly already begun analyzing the playing style of AlphaGo Zero along with players from the national team.",
              "\"Though having watched only a few matches, we received the impression that AlphaGo Zero plays more like a human than its predecessors,\" Mok said.",
              "[19] Chinese Go professional Ke Jie commented on the remarkable accomplishments of the new program: \"A pure self-learning AlphaGo is the strongest.",
              "Humans seem redundant in front of its self-improvement.\"",
              "[20] Future of Go Summit 89:11 against AlphaGo Master On 5 December 2017, DeepMind team released a preprint on arXiv, introducing AlphaZero, a program using generalized AlphaGo Zero's approach, which achieved within 24 hours a superhuman level of play in chess, shogi, and Go, defeating world-champion programs, Stockfish, Elmo, and 3-day version of AlphaGo Zero in each case.",
              "[7] AlphaZero (AZ) is a more generalized variant of the AlphaGo Zero (AGZ) algorithm, and is able to play shogi and chess as well as Go.",
              "Differences between AZ and AGZ include:[7] An open source program, Leela Zero, based on the ideas from the AlphaGo papers is available.",
              "It uses a GPU instead of the TPUs recent versions of AlphaGo rely on."
            ]
          },
          {
            "title": "AlphaGo - Google DeepMind",
            "url": "https://deepmind.google/technologies/alphago/",
            "content": [
              "AlphaGo - Google DeepMind",
              "Technology AlphaGo mastered the ancient game of Go, defeated a Go world champion, and inspired a new era of AI systems. Our artificial intelligence (AI) system, AlphaGo, learned to master the ancient Chinese game of Go \u2014 a profoundly complex board game of strategy, creativity, and ingenuity.",
              "AlphaGo defeated a human Go world champion a decade before experts thought possible, inspired players around the world to discover new approaches, and arguably, became the strongest Go player in history.",
              "It proved that AI systems can learn how to solve the most challenging problems in highly complex domains.",
              "AlphaGo in training.",
              "Go was long considered a grand challenge for AI.",
              "The game is a googol times more complex than chess \u2014 with an astonishing 10 to the power of 170 possible board configurations.",
              "That\u2019s more than the number of atoms in the known universe.",
              "The strongest Go computer programs only achieved the level of human amateurs, despite decades of work.",
              "Standard AI methods struggled to assess the sheer number of possible moves and lacked the creativity and intuition of human players.",
              "We created AlphaGo, an AI system that combines deep neural networks with advanced search algorithms. One neural network \u2014 known as the \u201cpolicy network\u201d \u2014 selects the next move to play.",
              "The other neural network \u2014 the \u201cvalue network\u201d \u2014 predicts the winner of the game.",
              "Initially, we introduced AlphaGo to numerous amateur games of Go so the system could learn how humans play the game.",
              "Then we instructed AlphaGo to play against different versions of itself thousands of times, each time learning from its mistakes \u2014 a method known as reinforcement learning.",
              "Over time, AlphaGo improved and became a better player.",
              "I thought AlphaGo was based on probability calculation and that it was merely a machine.",
              "But when I saw this move, I changed my mind.",
              "Surely, AlphaGo is creative.",
              "Lee SedolWinner of 18 world Go titles In October 2015, AlphaGo played its first game against the reigning three-time European Champion, Fan Hui.",
              "AlphaGo won the first ever match between an AI system and Go professional, scoring 5-0.",
              "AlphaGo then competed against legendary Go player Lee Sedol \u2014 winner of 18 world titles, and widely considered the greatest player of that decade.",
              "AlphaGo's 4-1 victory in Seoul, South Korea, in March 2016 was watched by over 200 million people worldwide.",
              "This landmark achievement was a decade ahead of its time.",
              "Watch This game earned AlphaGo a 9 dan professional ranking \u2014 the first time a computer Go player had received the highest possible certification.",
              "During the games, AlphaGo played several inventive winning moves.",
              "In game two, it played Move 37 \u2014 a move that had a 1 in 10,000 chance of being used.",
              "This pivotal and creative move helped AlphaGo win the game and upended centuries of traditional wisdom.",
              "Then in game four, Lee Sedol played a Move 78, which had a 1 in 10,000 chance of being played.",
              "Known as \u201cGod\u2019s Touch\u201d, this move was just as unlikely and inventive as the one AlphaGo played two games earlier \u2014 and helped Sedol win the game.",
              "Players of all levels have examined these moves ever since.",
              "AlphaGo\u2019s victory inspired a new era of AI systems. It was conclusive proof that the underlying neural networks could be applied to complex domains, while the use of reinforcement learning showed how machines can learn to solve incredibly hard problems for themselves, simply through trial-and-error.",
              "Its ability to look ahead and plan are also still used in today\u2019s AI systems. These ideas allowed us to develop stronger versions of AlphaGo and the system continued to play competitively, including defeating the world champion.",
              "Now, its successors \u2014 AlphaZero, MuZero, and AlphaDev \u2014 are building upon AlphaGo\u2019s legacy to help solve increasingly complex challenges that impact our everyday lives.",
              "AlphaZero and MuZero Powerful, general AI systems that mastered a range of board games and video games \u2014 and are now helping us solve real-world problems. Research MuZero: Mastering Go, chess, shogi and Atari without rules In 2016, we introduced AlphaGo, the first artificial intelligence (AI) program to defeat humans at the ancient game of Go.",
              "Two years later, its successor - AlphaZero - learned from scratch to.",
              ".",
              ".",
              "Research AlphaZero: Shedding new light on chess, shogi, and Go In late 2017 we introduced AlphaZero, a single system that taught itself from scratch how to master the games of chess, shogi (Japanese chess), and Go, beating a world-champion program in each.",
              ".",
              ".",
              "AlphaStar First AI to master the real-time strategy game StarCraft II, long considered a grand challenge for AI research.",
              "I accept Google's Terms and Conditions and acknowledge that my information will be used in accordance with Google's Privacy Policy."
            ]
          },
          {
            "title": "Mastering the game of Go without human knowledge | Nature",
            "url": "https://www.nature.com/articles/nature24270",
            "content": [
              "Mastering the game of Go without human knowledge | Nature",
              "Thank you for visiting nature.",
              "com.",
              "You are using a browser version with limited support for CSS.",
              "To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer).",
              "In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.",
              "Advertisement Nature volume 550, pages 354\u2013359 (2017)Cite this article 352k Accesses 4517 Citations 2508 Altmetric Metrics details A long-standing goal of artificial intelligence is an algorithm that learns, tabula rasa, superhuman proficiency in challenging domains.",
              "Recently, AlphaGo became the first program to defeat a world champion in the game of Go.",
              "The tree search in AlphaGo evaluated positions and selected moves using deep neural networks.",
              "These neural networks were trained by supervised learning from human expert moves, and by reinforcement learning from self-play.",
              "Here we introduce an algorithm based solely on reinforcement learning, without human data, guidance or domain knowledge beyond game rules.",
              "AlphaGo becomes its own teacher: a neural network is trained to predict AlphaGo\u2019s own move selections and also the winner of AlphaGo\u2019s games.",
              "This neural network improves the strength of the tree search, resulting in higher quality move selection and stronger self-play in the next iteration.",
              "Starting tabula rasa, our new program AlphaGo Zero achieved superhuman performance, winning 100\u20130 against the previously published, champion-defeating AlphaGo.",
              "You have full access to this article via your institution.",
              "Much progress towards artificial intelligence has been made using supervised learning systems that are trained to replicate the decisions of human experts1,2,3,4.",
              "However, expert data sets are often expensive, unreliable or simply unavailable.",
              "Even when reliable data sets are available, they may impose a ceiling on the performance of systems trained in this manner5.",
              "By contrast, reinforcement learning systems are trained from their own experience, in principle allowing them to exceed human capabilities, and to operate in domains where human expertise is lacking.",
              "Recently, there has been rapid progress towards this goal, using deep neural networks trained by reinforcement learning.",
              "These systems have outperformed humans in computer games, such as Atari6,7 and 3D virtual environments8,9,10.",
              "However, the most challenging domains in terms of human intellect\u2014such as the game of Go, widely viewed as a grand challenge for artificial intelligence11\u2014require a precise and sophisticated lookahead in vast search spaces.",
              "Fully general methods have not previously achieved human-level performance in these domains.",
              "AlphaGo was the first program to achieve superhuman performance in Go.",
              "The published version12, which we refer to as AlphaGo Fan, defeated the European champion Fan Hui in October 2015.",
              "AlphaGo Fan used two deep neural networks: a policy network that outputs move probabilities and a value network that outputs a position evaluation.",
              "The policy network was trained initially by supervised learning to accurately predict human expert moves, and was subsequently refined by policy-gradient reinforcement learning.",
              "The value network was trained to predict the winner of games played by the policy network against itself.",
              "Once trained, these networks were combined with a Monte Carlo tree search (MCTS)13,14,15 to provide a lookahead search, using the policy network to narrow down the search to high-probability moves, and using the value network (in conjunction with Monte Carlo rollouts using a fast rollout policy) to evaluate positions in the tree.",
              "A subsequent version, which we refer to as AlphaGo Lee, used a similar approach (see Methods), and defeated Lee Sedol, the winner of 18 international titles, in March 2016.",
              "Our program, AlphaGo Zero, differs from AlphaGo Fan and AlphaGo Lee12 in several important aspects.",
              "First and foremost, it is trained solely by self-play reinforcement learning, starting from random play, without any supervision or use of human data.",
              "Second, it uses only the black and white stones from the board as input features.",
              "Third, it uses a single neural network, rather than separate policy and value networks.",
              "Finally, it uses a simpler tree search that relies upon this single neural network to evaluate positions and sample moves, without performing any Monte Carlo rollouts.",
              "To achieve these results, we introduce a new reinforcement learning algorithm that incorporates lookahead search inside the training loop, resulting in rapid improvement and precise and stable learning.",
              "Further technical differences in the search algorithm, training procedure and network architecture are described in Methods.",
              "Our new method uses a deep neural network f\u03b8 with parameters \u03b8.",
              "This neural network takes as an input the raw board representation s of the position and its history, and outputs both move probabilities and a value, (p, v) = f\u03b8(s).",
              "The vector of move probabilities p represents the probability of selecting each move a (including pass), pa = Pr(a|s).",
              "The value v is a scalar evaluation, estimating the probability of the current player winning from position s.",
              "This neural network combines the roles of both policy network and value network12 into a single architecture.",
              "The neural network consists of many residual blocks4 of convolutional layers16,17 with batch normalization18 and rectifier nonlinearities19 (see Methods).",
              "The neural network in AlphaGo Zero is trained from games of self-play by a novel reinforcement learning algorithm.",
              "In each position s, an MCTS search is executed, guided by the neural network f\u03b8.",
              "The MCTS search outputs probabilities \u03c0 of playing each move.",
              "These search probabilities usually select much stronger moves than the raw move probabilities p of the neural network f\u03b8(s);",
              "MCTS may therefore be viewed as a powerful policy improvement operator20,21.",
              "Self-play with search\u2014using the improved MCTS-based policy to select each move, then using the game winner z as a sample of the value\u2014may be viewed as a powerful policy evaluation operator.",
              "The main idea of our reinforcement learning algorithm is to use these search operators repeatedly in a policy iteration procedure22,23: the neural network\u2019s parameters are updated to make the move probabilities and value (p, v) = f\u03b8(s) more closely match the improved search probabilities and self-play winner (\u03c0, z);",
              "these new parameters are used in the next iteration of self-play to make the search even stronger.",
              "Figure 1 illustrates the self-play training pipeline.",
              "a, The program plays a game s1, .",
              ".",
              ".",
              ", sT against itself.",
              "In each position st, an MCTS \u03b1\u03b8 is executed (see Fig.",
              "2) using the latest neural network f\u03b8.",
              "Moves are selected according to the search probabilities computed by the MCTS, at \u223c \u03c0t.",
              "The terminal position sT is scored according to the rules of the game to compute the game winner z.",
              "b, Neural network training in AlphaGo Zero.",
              "The neural network takes the raw board position st as its input, passes it through many convolutional layers with parameters \u03b8, and outputs both a vector pt, representing a probability distribution over moves, and a scalar value vt, representing the probability of the current player winning in position st.",
              "The neural network parameters \u03b8 are updated to maximize the similarity of the policy vector pt to the search probabilities \u03c0t, and to minimize the error between the predicted winner vt and the game winner z (see equation (1)).",
              "The new parameters are used in the next iteration of self-play as in a.",
              "PowerPoint slide The MCTS uses the neural network f\u03b8 to guide its simulations (see Fig.",
              "2).",
              "Each edge (s, a) in the search tree stores a prior probability P(s, a), a visit count N(s, a), and an action value Q(s, a).",
              "Each simulation starts from the root state and iteratively selects moves that maximize an upper confidence bound Q(s, a) + U(s, a), where U(s, a) \u221d P(s, a) / (1 + N(s, a)) (refs 12, 24), until a leaf node s\u2032 is encountered.",
              "This leaf position is expanded and evaluated only once by the network to generate both prior probabilities and evaluation, (P(s\u2032, \u00b7),V(s\u2032)) = f\u03b8(s\u2032).",
              "Each edge (s, a) traversed in the simulation is updated to increment its visit count N(s, a), and to update its action value to the mean evaluation over these simulations, where s, a\u2192s\u2032 indicates that a simulation eventually reached s\u2032 after taking move a from position s.",
              "a, Each simulation traverses the tree by selecting the edge with maximum action value Q, plus an upper confidence bound U that depends on a stored prior probability P and visit count N for that edge (which is incremented once traversed).",
              "b, The leaf node is expanded and the associated position s is evaluated by the neural network (P(s, \u00b7),V(s)) = f\u03b8(s);",
              "the vector of P values are stored in the outgoing edges from s.",
              "c, Action value Q is updated to track the mean of all evaluations V in the subtree below that action.",
              "d, Once the search is complete, search probabilities \u03c0 are returned, proportional to N1/\u03c4, where N is the visit count of each move from the root state and \u03c4 is a parameter controlling temperature.",
              "PowerPoint slide MCTS may be viewed as a self-play algorithm that, given neural network parameters \u03b8 and a root position s, computes a vector of search probabilities recommending moves to play, \u03c0 = \u03b1\u03b8(s), proportional to the exponentiated visit count for each move, \u03c0a \u221d N(s, a)1/\u03c4, where \u03c4 is a temperature parameter.",
              "The neural network is trained by a self-play reinforcement learning algorithm that uses MCTS to play each move.",
              "First, the neural network is initialized to random weights \u03b80.",
              "At each subsequent iteration i \u2265 1, games of self-play are generated (Fig.",
              "1a).",
              "At each time-step t, an MCTS search is executed using the previous iteration of neural network and a move is played by sampling the search probabilities \u03c0t.",
              "A game terminates at step T when both players pass, when the search value drops below a resignation threshold or when the game exceeds a maximum length;",
              "the game is then scored to give a final reward of rT \u2208 {\u22121,+1} (see Methods for details).",
              "The data for each time-step t is stored as (st, \u03c0t, zt), where zt = \u00b1rT is the game winner from the perspective of the current player at step t.",
              "In parallel (Fig.",
              "1b), new network parameters \u03b8i are trained from data (s, \u03c0, z) sampled uniformly among all time-steps of the last iteration(s) of self-play.",
              "The neural network is adjusted to minimize the error between the predicted value v and the self-play winner z, and to maximize the similarity of the neural network move probabilities p to the search probabilities \u03c0.",
              "Specifically, the parameters \u03b8 are adjusted by gradient descent on a loss function l that sums over the mean-squared error and cross-entropy losses, respectively: where c is a parameter controlling the level of L2 weight regularization (to prevent overfitting).",
              "We applied our reinforcement learning pipeline to train our program AlphaGo Zero.",
              "Training started from completely random behaviour and continued without human intervention for approximately three days.",
              "Over the course of training, 4.",
              "9 million games of self-play were generated, using 1,600 simulations for each MCTS, which corresponds to approximately 0.",
              "4 s thinking time per move.",
              "Parameters were updated from 700,000 mini-batches of 2,048 positions.",
              "The neural network contained 20 residual blocks (see Methods for further details).",
              "Figure 3a shows the performance of AlphaGo Zero during self-play reinforcement learning, as a function of training time, on an Elo scale25.",
              "Learning progressed smoothly throughout training, and did not suffer from the oscillations or catastrophic forgetting that have been suggested in previous literature26,27,28.",
              "Surprisingly, AlphaGo Zero outperformed AlphaGo Lee after just 36 h.",
              "In comparison, AlphaGo Lee was trained over several months.",
              "After 72 h, we evaluated AlphaGo Zero against the exact version of AlphaGo Lee that defeated Lee Sedol, under the same 2 h time controls and match conditions that were used in the man\u2013machine match in Seoul (see Methods).",
              "AlphaGo Zero used a single machine with 4 tensor processing units (TPUs)29, whereas AlphaGo Lee was distributed over many machines and used 48 TPUs.",
              "AlphaGo Zero defeated AlphaGo Lee by 100 games to 0 (see Extended Data Fig.",
              "1and Supplementary Information).",
              "a, Performance of self-play reinforcement learning.",
              "The plot shows the performance of each MCTS player from each iteration i of reinforcement learning in AlphaGo Zero.",
              "Elo ratings were computed from evaluation games between different players, using 0.",
              "4 s of thinking time per move (see Methods).",
              "For comparison, a similar player trained by supervised learning from human data, using the KGS dataset, is also shown.",
              "b, Prediction accuracy on human professional moves.",
              "The plot shows the accuracy of the neural network, at each iteration of self-play i, in predicting human professional moves from the GoKifu dataset.",
              "The accuracy measures the percentage of positions in which the neural network assigns the highest probability to the human move.",
              "The accuracy of a neural network trained by supervised learning is also shown.",
              "c, Mean-squared error (MSE) of human professional game outcomes.",
              "The plot shows the MSE of the neural network, at each iteration of self-play i, in predicting the outcome of human professional games from the GoKifu dataset.",
              "The MSE is between the actual outcome z \u2208 {\u22121, +1} and the neural network value v, scaled by a factor of to the range of 0\u20131.",
              "The MSE of a neural network trained by supervised learning is also shown.",
              "PowerPoint slide To assess the merits of self-play reinforcement learning, compared to learning from human data, we trained a second neural network (using the same architecture) to predict expert moves in the KGS Server dataset;",
              "this achieved state-of-the-art prediction accuracy compared to previous work12,30,31,32,33 (see Extended Data Tables 1 and 2 for current and previous results, respectively).",
              "Supervised learning achieved a better initial performance, and was better at predicting human professional moves (Fig.",
              "3).",
              "Notably, although supervised learning achieved higher move prediction accuracy, the self-learned player performed much better overall, defeating the human-trained player within the first 24 h of training.",
              "This suggests that AlphaGo Zero may be learning a strategy that is qualitatively different to human play.",
              "To separate the contributions of architecture and algorithm, we compared the performance of the neural network architecture in AlphaGo Zero with the previous neural network architecture used in AlphaGo Lee (see Fig.",
              "4).",
              "Four neural networks were created, using either separate policy and value networks, as were used in AlphaGo Lee, or combined policy and value networks, as used in AlphaGo Zero;",
              "and using either the convolutional network architecture from AlphaGo Lee or the residual network architecture from AlphaGo Zero.",
              "Each network was trained to minimize the same loss function (equation (1)), using a fixed dataset of self-play games generated by AlphaGo Zero after 72 h of self-play training.",
              "Using a residual network was more accurate, achieved lower error and improved performance in AlphaGo by over 600 Elo.",
              "Combining policy and value together into a single network slightly reduced the move prediction accuracy, but reduced the value error and boosted playing performance in AlphaGo by around another 600 Elo.",
              "This is partly due to improved computational efficiency, but more importantly the dual objective regularizes the network to a common representation that supports multiple use cases.",
              "Comparison of neural network architectures using either separate (sep) or combined policy and value (dual) networks, and using either convolutional (conv) or residual (res) networks.",
              "The combinations \u2018dual\u2013res\u2019 and \u2018sep\u2013conv\u2019 correspond to the neural network architectures used in AlphaGo Zero and AlphaGo Lee, respectively.",
              "Each network was trained on a fixed dataset generated by a previous run of AlphaGo Zero.",
              "a, Each trained network was combined with AlphaGo Zero\u2019s search to obtain a different player.",
              "Elo ratings were computed from evaluation games between these different players, using 5 s of thinking time per move.",
              "b, Prediction accuracy on human professional moves (from the GoKifu dataset) for each network architecture.",
              "c MSE of human professional game outcomes (from the GoKifu dataset) for each network architecture.",
              "PowerPoint slide AlphaGo Zero discovered a remarkable level of Go knowledge during its self-play training process.",
              "This included not only fundamental elements of human Go knowledge, but also non-standard strategies beyond the scope of traditional Go knowledge.",
              "Figure 5 shows a timeline indicating when professional joseki (corner sequences) were discovered (Fig.",
              "5a and Extended Data Fig.",
              "2);",
              "ultimately AlphaGo Zero preferred new joseki variants that were previously unknown (Fig.",
              "5b and Extended Data Fig.",
              "3).",
              "Figure 5c shows several fast self-play games played at different stages of training (see Supplementary Information).",
              "Tournament length games played at regular intervals throughout training are shown in Extended Data Fig.",
              "4 and in the Supplementary Information.",
              "AlphaGo Zero rapidly progressed from entirely random moves towards a sophisticated understanding of Go concepts, including fuseki (opening), tesuji (tactics), life-and-death, ko (repeated board situations), yose (endgame), capturing races, sente (initiative), shape, influence and territory, all discovered from first principles.",
              "Surprisingly, shicho (\u2018ladder\u2019 capture sequences that may span the whole board)\u2014one of the first elements of Go knowledge learned by humans\u2014were only understood by AlphaGo Zero much later in training.",
              "a, Five human joseki (common corner sequences) discovered during AlphaGo Zero training.",
              "The associated timestamps indicate the first time each sequence occurred (taking account of rotation and reflection) during self-play training.",
              "Extended Data Figure 2 provides the frequency of occurence over training for each sequence.",
              "b, Five joseki favoured at different stages of self-play training.",
              "Each displayed corner sequence was played with the greatest frequency, among all corner sequences, during an iteration of self-play training.",
              "The timestamp of that iteration is indicated on the timeline.",
              "At 10 h a weak corner move was preferred.",
              "At 47 h the 3\u20133 invasion was most frequently played.",
              "This joseki is also common in human professional play;",
              "however AlphaGo Zero later discovered and preferred a new variation.",
              "Extended Data Figure 3 provides the frequency of occurence over time for all five sequences and the new variation.",
              "c, The first 80 moves of three self-play games that were played at different stages of training, using 1,600 simulations (around 0.",
              "4 s) per search.",
              "At 3 h, the game focuses greedily on capturing stones, much like a human beginner.",
              "At 19 h, the game exhibits the fundamentals of life-and-death, influence and territory.",
              "At 70 h, the game is remarkably balanced, involving multiple battles and a complicated ko fight, eventually resolving into a half-point win for white.",
              "See Supplementary Information for the full games.",
              "PowerPoint slide We subsequently applied our reinforcement learning pipeline to a second instance of AlphaGo Zero using a larger neural network and over a longer duration.",
              "Training again started from completely random behaviour and continued for approximately 40 days.",
              "Over the course of training, 29 million games of self-play were generated.",
              "Parameters were updated from 3.",
              "1 million mini-batches of 2,048 positions each.",
              "The neural network contained 40 residual blocks.",
              "The learning curve is shown in Fig.",
              "6a.",
              "Games played at regular intervals throughout training are shown in Extended Data Fig.",
              "5 and in the Supplementary Information.",
              "a, Learning curve for AlphaGo Zero using a larger 40-block residual network over 40 days.",
              "The plot shows the performance of each player from each iteration i of our reinforcement learning algorithm.",
              "Elo ratings were computed from evaluation games between different players, using 0.",
              "4 s per search (see Methods).",
              "b, Final performance of AlphaGo Zero.",
              "AlphaGo Zero was trained for 40 days using a 40-block residual neural network.",
              "The plot shows the results of a tournament between: AlphaGo Zero, AlphaGo Master (defeated top human professionals 60\u20130 in online games), AlphaGo Lee (defeated Lee Sedol), AlphaGo Fan (defeated Fan Hui), as well as previous Go programs Crazy Stone, Pachi and GnuGo.",
              "Each program was given 5 s of thinking time per move.",
              "AlphaGo Zero and AlphaGo Master played on a single machine on the Google Cloud;",
              "AlphaGo Fan and AlphaGo Lee were distributed over many machines.",
              "The raw neural network from AlphaGo Zero is also included, which directly selects the move a with maximum probability pa, without using MCTS.",
              "Programs were evaluated on an Elo scale25: a 200-point gap corresponds to a 75% probability of winning.",
              "PowerPoint slide We evaluated the fully trained AlphaGo Zero using an internal tournament against AlphaGo Fan, AlphaGo Lee and several previous Go programs. We also played games against the strongest existing program, AlphaGo Master\u2014a program based on the algorithm and architecture presented in this paper but using human data and features (see Methods)\u2014which defeated the strongest human professional players 60\u20130 in online games in January 201734.",
              "In our evaluation, all programs were allowed 5 s of thinking time per move;",
              "AlphaGo Zero and AlphaGo Master each played on a single machine with 4 TPUs;",
              "AlphaGo Fan and AlphaGo Lee were distributed over 176 GPUs and 48 TPUs, respectively.",
              "We also included a player based solely on the raw neural network of AlphaGo Zero;",
              "this player simply selected the move with maximum probability.",
              "Figure 6b shows the performance of each program on an Elo scale.",
              "The raw neural network, without using any lookahead, achieved an Elo rating of 3,055.",
              "AlphaGo Zero achieved a rating of 5,185, compared to 4,858 for AlphaGo Master, 3,739 for AlphaGo Lee and 3,144 for AlphaGo Fan.",
              "Finally, we evaluated AlphaGo Zero head to head against AlphaGo Master in a 100-game match with 2-h time controls.",
              "AlphaGo Zero won by 89 games to 11 (see Extended Data Fig.",
              "6 and Supplementary Information).",
              "Our results comprehensively demonstrate that a pure reinforcement learning approach is fully feasible, even in the most challenging of domains: it is possible to train to superhuman level, without human examples or guidance, given no knowledge of the domain beyond basic rules.",
              "Furthermore, a pure reinforcement learning approach requires just a few more hours to train, and achieves much better asymptotic performance, compared to training on human expert data.",
              "Using this approach, AlphaGo Zero defeated the strongest previous versions of AlphaGo, which were trained from human data using handcrafted features, by a large margin.",
              "Humankind has accumulated Go knowledge from millions of games played over thousands of years, collectively distilled into patterns, proverbs and books.",
              "In the space of a few days, starting tabula rasa, AlphaGo Zero was able to rediscover much of this Go knowledge, as well as novel strategies that provide new insights into the oldest of games.",
              "Policy iteration20,21 is a classic algorithm that generates a sequence of improving policies, by alternating between policy evaluation\u2014estimating the value function of the current policy\u2014and policy improvement\u2014using the current value function to generate a better policy.",
              "A simple approach to policy evaluation is to estimate the value function from the outcomes of sampled trajectories35,36.",
              "A simple approach to policy improvement is to select actions greedily with respect to the value function20.",
              "In large state spaces, approximations are necessary to evaluate each policy and to represent its improvement22,23.",
              "Classification-based reinforcement learning37 improves the policy using a simple Monte Carlo search.",
              "Many rollouts are executed for each action;",
              "the action with the maximum mean value provides a positive training example, while all other actions provide negative training examples;",
              "a policy is then trained to classify actions as positive or negative, and used in subsequent rollouts.",
              "This may be viewed as a precursor to the policy component of AlphaGo Zero\u2019s training algorithm when \u03c4\u21920.",
              "A more recent instantiation, classification-based modified policy iteration (CBMPI), also performs policy evaluation by regressing a value function towards truncated rollout values, similar to the value component of AlphaGo Zero;",
              "this achieved state-of-the-art results in the game of Tetris38.",
              "However, this previous work was limited to simple rollouts and linear function approximation using handcrafted features.",
              "The AlphaGo Zero self-play algorithm can similarly be understood as an approximate policy iteration scheme in which MCTS is used for both policy improvement and policy evaluation.",
              "Policy improvement starts with a neural network policy, executes an MCTS based on that policy\u2019s recommendations, and then projects the (much stronger) search policy back into the function space of the neural network.",
              "Policy evaluation is applied to the (much stronger) search policy: the outcomes of self-play games are also projected back into the function space of the neural network.",
              "These projection steps are achieved by training the neural network parameters to match the search probabilities and self-play game outcome respectively.",
              "Guo et al.",
              "7 also project the output of MCTS into a neural network, either by regressing a value network towards the search value, or by classifying the action selected by MCTS.",
              "This approach was used to train a neural network for playing Atari games;",
              "however, the MCTS was fixed\u2014there was no policy iteration\u2014and did not make any use of the trained networks.",
              "Our approach is most directly applicable to Zero-sum games of perfect information.",
              "We follow the formalism of alternating Markov games described in previous work12, noting that algorithms based on value or policy iteration extend naturally to this setting39.",
              "Self-play reinforcement learning has previously been applied to the game of Go.",
              "NeuroGo40,41 used a neural network to represent a value function, using a sophisticated architecture based on Go knowledge regarding connectivity, territory and eyes.",
              "This neural network was trained by temporal-difference learning42 to predict territory in games of self-play, building on previous work43.",
              "A related approach, RLGO44, represented the value function instead by a linear combination of features, exhaustively enumerating all 3 \u00d7 3 patterns of stones;",
              "it was trained by temporal-difference learning to predict the winner in games of self-play.",
              "Both NeuroGo and RLGO achieved a weak amateur level of play.",
              "MCTS may also be viewed as a form of self-play reinforcement learning45.",
              "The nodes of the search tree contain the value function for the positions encountered during search;",
              "these values are updated to predict the winner of simulated games of self-play.",
              "MCTS programs have previously achieved strong amateur level in Go46,47, but used substantial domain expertise: a fast rollout policy, based on handcrafted features13,48, that evaluates positions by running simulations until the end of the game;",
              "and a tree policy, also based on handcrafted features, that selects moves within the search tree47.",
              "Self-play reinforcement learning approaches have achieved high levels of performance in other games: chess49,50,51, checkers52, backgammon53, othello54, Scrabble55 and most recently poker56.",
              "In all of these examples, a value function was trained by regression54,55,56 or temporal-difference learning49,50,51,52,53 from training data generated by self-play.",
              "The trained value function was used as an evaluation function in an alpha\u2013beta search49,50,51,52,53,54, a simple Monte Carlo search55,57 or counterfactual regret minimization56.",
              "However, these methods used handcrafted input features49,50,51,52,53,56 or handcrafted feature templates54,55.",
              "In addition, the learning process used supervised learning to initialize weights58, hand-selected weights for piece values49,51,52, handcrafted restrictions on the action space56 or used pre-existing computer programs as training opponents49,50, or to generate game records51.",
              "Many of the most successful and widely used reinforcement learning methods were first introduced in the context of Zero-sum games: temporal-difference learning was first introduced for a checkers-playing program59, while MCTS was introduced for the game of Go13.",
              "However, very similar algorithms have subsequently proven highly effective in video games6,7,8,10, robotics60, industrial control61,62,63 and online recommendation systems64,65.",
              "We compare three distinct versions of AlphaGo: (1) AlphaGo Fan is the previously published program12 that played against Fan Hui in October 2015.",
              "This program was distributed over many machines using 176 GPUs.",
              "(2) AlphaGo Lee is the program that defeated Lee Sedol 4\u20131 in March 2016.",
              "It was previously unpublished, but is similar in most regards to AlphaGo Fan12.",
              "However, we highlight several key differences to facilitate a fair comparison.",
              "First, the value network was trained from the outcomes of fast games of self-play by AlphaGo, rather than games of self-play by the policy network;",
              "this procedure was iterated several times\u2014an initial step towards the tabula rasa algorithm presented in this paper.",
              "Second, the policy and value networks were larger than those described in the original paper\u2014using 12 convolutional layers of 256 planes\u2014and were trained for more iterations.",
              "This player was also distributed over many machines using 48 TPUs, rather than GPUs, enabling it to evaluate neural networks faster during search.",
              "(3) AlphaGo Master is the program that defeated top human players by 60\u20130 in January 201734.",
              "It was previously unpublished, but uses the same neural network architecture, reinforcement learning algorithm, and MCTS algorithm as described in this paper.",
              "However, it uses the same handcrafted features and rollouts as AlphaGo Lee12 and training was initialized by supervised learning from human data.",
              "(4) AlphaGo Zero is the program described in this paper.",
              "It learns from self-play reinforcement learning, starting from random initial weights, without using rollouts, with no human supervision and using only the raw board history as input features.",
              "It uses just a single machine in the Google Cloud with 4 TPUs (AlphaGo Zero could also be distributed, but we chose to use the simplest possible search algorithm).",
              "Our primary contribution is to demonstrate that superhuman performance can be achieved without human domain knowledge.",
              "To clarify this contribution, we enumerate the domain knowledge that AlphaGo Zero uses, explicitly or implicitly, either in its training procedure or its MCTS;",
              "these are the items of knowledge that would need to be replaced for AlphaGo Zero to learn a different (alternating Markov) game.",
              "(1) AlphaGo Zero is provided with perfect knowledge of the game rules.",
              "These are used during MCTS, to simulate the positions resulting from a sequence of moves, and to score any simulations that reach a terminal state.",
              "Games terminate when both players pass or after 19 \u00d7 19 \u00d7 2 = 722 moves.",
              "In addition, the player is provided with the set of legal moves in each position.",
              "(2) AlphaGo Zero uses Tromp\u2013Taylor scoring66 during MCTS simulations and self-play training.",
              "This is because human scores (Chinese, Japanese or Korean rules) are not well-defined if the game terminates before territorial boundaries are resolved.",
              "However, all tournament and evaluation games were scored using Chinese rules.",
              "(3) The input features describing the position are structured as a 19 \u00d7 19 image;",
              "that is, the neural network architecture is matched to the grid-structure of the board.",
              "(4) The rules of Go are invariant under rotation and reflection;",
              "this knowledge has been used in AlphaGo Zero both by augmenting the dataset during training to include rotations and reflections of each position, and to sample random rotations or reflections of the position during MCTS (see Search algorithm).",
              "Aside from komi, the rules of Go are also invariant to colour transposition;",
              "this knowledge is exploited by representing the board from the perspective of the current player (see Neural network architecture).",
              "AlphaGo Zero does not use any form of domain knowledge beyond the points listed above.",
              "It only uses its deep neural network to evaluate leaf nodes and to select moves (see \u2018Search algorithm\u2019).",
              "It does not use any rollout policy or tree policy, and the MCTS is not augmented by any other heuristics or domain-specific rules.",
              "No legal moves are excluded\u2014even those filling in the player\u2019s own eyes (a standard heuristic used in all previous programs67).",
              "The algorithm was started with random initial parameters for the neural network.",
              "The neural network architecture (see \u2018Neural network architecture\u2019) is based on the current state of the art in image recognition4,18, and hyperparameters for training were chosen accordingly (see \u2018Self-play training pipeline\u2019).",
              "MCTS search parameters were selected by Gaussian process optimization68, so as to optimize self-play performance of AlphaGo Zero using a neural network trained in a preliminary run.",
              "For the larger run (40 blocks, 40 days), MCTS search parameters were re-optimized using the neural network trained in the smaller run (20 blocks, 3 days).",
              "The training algorithm was executed autonomously without human intervention.",
              "AlphaGo Zero\u2019s self-play training pipeline consists of three main components, all executed asynchronously in parallel.",
              "Neural network parameters \u03b8i are continually optimized from recent self-play data;",
              "AlphaGo Zero players are continually evaluated;",
              "and the best performing player so far, , is used to generate new self-play data.",
              "Each neural network is optimized on the Google Cloud using TensorFlow, with 64 GPU workers and 19 CPU parameter servers.",
              "The batch-size is 32 per worker, for a total mini-batch size of 2,048.",
              "Each mini-batch of data is sampled uniformly at random from all positions of the most recent 500,000 games of self-play.",
              "Neural network parameters are optimized by stochastic gradient descent with momentum and learning rate annealing, using the loss in equation (1).",
              "The learning rate is annealed according to the standard schedule in Extended Data Table 3.",
              "The momentum parameter is set to 0.",
              "9.",
              "The cross-entropy and MSE losses are weighted equally (this is reasonable because rewards are unit scaled, r \u2208 {\u22121, +1}) and the L2 regularization parameter is set to c = 10\u22124.",
              "The optimization process produces a new checkpoint every 1,000 training steps.",
              "This checkpoint is evaluated by the evaluator and it may be used for generating the next batch of self-play games, as we explain next.",
              "To ensure we always generate the best quality data, we evaluate each new neural network checkpoint against the current best network before using it for data generation.",
              "The neural network is evaluated by the performance of an MCTS search that uses to evaluate leaf positions and prior probabilities (see Search algorithm).",
              "Each evaluation consists of 400 games, using an MCTS with 1,600 simulations to select each move, using an infinitesimal temperature \u03c4\u21920 (that is, we deterministically select the move with maximum visit count, to give the strongest possible play).",
              "If the new player wins by a margin of >55% (to avoid selecting on noise alone) then it becomes the best player , and is subsequently used for self-play generation, and also becomes the baseline for subsequent comparisons.",
              "The best current player , as selected by the evaluator, is used to generate data.",
              "In each iteration, plays 25,000 games of self-play, using 1,600 simulations of MCTS to select each move (this requires approximately 0.",
              "4 s per search).",
              "For the first 30 moves of each game, the temperature is set to \u03c4 = 1;",
              "this selects moves proportionally to their visit count in MCTS, and ensures a diverse set of positions are encountered.",
              "For the remainder of the game, an infinitesimal temperature is used, \u03c4\u21920.",
              "Additional exploration is achieved by adding Dirichlet noise to the prior probabilities in the root node s0, specifically P(s, a) = (1 \u2212 \u03b5)pa + \u03b5 \u03b7a, where \u03b7 \u223c Dir(0.",
              "03) and \u03b5 = 0.",
              "25;",
              "this noise ensures that all moves may be tried, but the search may still overrule bad moves.",
              "In order to save computation, clearly lost games are resigned.",
              "The resignation threshold vresign is selected automatically to keep the fraction of false positives (games that could have been won if AlphaGo had not resigned) below 5%.",
              "To measure false positives, we disable resignation in 10% of self-play games and play until termination.",
              "For comparison, we also trained neural network parameters \u03b8SL by supervised learning.",
              "The neural network architecture was identical to AlphaGo Zero.",
              "Mini-batches of data (s, \u03c0, z) were sampled at random from the KGS dataset, setting \u03c0a = 1 for the human expert move a.",
              "Parameters were optimized by stochastic gradient descent with momentum and learning rate annealing, using the same loss as in equation (1), but weighting the MSE component by a factor of 0.",
              "01.",
              "The learning rate was annealed according to the standard schedule in Extended Data Table 3.",
              "The momentum parameter was set to 0.",
              "9, and the L2 regularization parameter was set to c = 10\u22124.",
              "By using a combined policy and value network architecture, and by using a low weight on the value component, it was possible to avoid overfitting to the values (a problem described in previous work12).",
              "After 72 h the move prediction accuracy exceeded the state of the art reported in previous work12,30,31,32,33, reaching 60.",
              "4% on the KGS test set;",
              "the value prediction error was also substantially better than previously reported12.",
              "The validation set was composed of professional games from GoKifu.",
              "Accuracies and MSEs are reported in Extended Data Table 1 and Extended Data Table 2, respectively.",
              "AlphaGo Zero uses a much simpler variant of the asynchronous policy and value MCTS algorithm (APV-MCTS) used in AlphaGo Fan and AlphaGo Lee.",
              "Each node s in the search tree contains edges (s, a) for all legal actions .",
              "Each edge stores a set of statistics, where N(s, a) is the visit count, W(s, a) is the total action value, Q(s, a) is the mean action value and P(s, a) is the prior probability of selecting that edge.",
              "Multiple simulations are executed in parallel on separate search threads.",
              "The algorithm proceeds by iterating over three phases (Fig.",
              "2a\u2013c), and then selects a move to play (Fig.",
              "2d).",
              "The selection phase is almost identical to AlphaGo Fan12;",
              "we recapitulate here for completeness.",
              "The first in-tree phase of each simulation begins at the root node of the search tree, s0, and finishes when the simulation reaches a leaf node sL at time-step L.",
              "At each of these time-steps, t < L, an action is selected according to the statistics in the search tree, , using a variant of the PUCT algorithm24, where cpuct is a constant determining the level of exploration;",
              "this search control strategy initially prefers actions with high prior probability and low visit count, but asympotically prefers actions with high action value.",
              "The leaf node sL is added to a queue for neural network evaluation, (di(p), v) = f\u03b8(di(sL)), where di is a dihedral reflection or rotation selected uniformly at random from i in [1.",
              ".",
              "8].",
              "Positions in the queue are evaluated by the neural network using a mini-batch size of 8;",
              "the search thread is locked until evaluation completes.",
              "The leaf node is expanded and each edge (sL, a) is initialized to{N(sL, a) = 0, W(sL, a) = 0, Q(sL, a) = 0, P(sL, a) = pa};",
              "the value v is then backed up.",
              "The edge statistics are updated in a backward pass through each step t \u2264 L.",
              "The visit counts are incremented, N(st, at) = N(st, at) + 1, and the action value is updated to the mean value, At the end of the search AlphaGo Zero selects a move a to play in the root position s0, proportional to its exponentiated visit count, , where \u03c4 is a temperature parameter that controls the level of exploration.",
              "The search tree is reused at subsequent time-steps: the child node corresponding to the played action becomes the new root node;",
              "the subtree below this child is retained along with all its statistics, while the remainder of the tree is discarded.",
              "AlphaGo Zero resigns if its root value and best child value are lower than a threshold value vresign.",
              "Compared to the MCTS in AlphaGo Fan and AlphaGo Lee, the principal differences are that AlphaGo Zero does not use any rollouts;",
              "it uses a single neural network instead of separate policy and value networks;",
              "leaf nodes are always expanded, rather than using dynamic expansion;",
              "each search thread simply waits for the neural network evaluation, rather than performing evaluation and backup asynchronously;",
              "and there is no tree policy.",
              "A transposition table was also used in the large (40 blocks, 40 days) instance of AlphaGo Zero.",
              "The input to the neural network is a 19 \u00d7 19 \u00d7 17 image stack comprising 17 binary feature planes.",
              "Eight feature planes, Xt, consist of binary values indicating the presence of the current player\u2019s stones ( if intersection i contains a stone of the player\u2019s colour at time-step t;",
              "0 if the intersection is empty, contains an opponent stone, or if t < 0).",
              "A further 8 feature planes, Yt, represent the corresponding features for the opponent\u2019s stones.",
              "The final feature plane, C, represents the colour to play, and has a constant value of either 1 if black is to play or 0 if white is to play.",
              "These planes are concatenated together to give input features st = [Xt, Yt, Xt\u22121, Yt\u22121,.",
              ".",
              ".",
              ", Xt\u22127, Yt\u22127, C].",
              "History features Xt, Yt are necessary, because Go is not fully observable solely from the current stones, as repetitions are forbidden;",
              "similarly, the colour feature C is necessary, because the komi is not observable.",
              "The input features st are processed by a residual tower that consists of a single convolutional block followed by either 19 or 39 residual blocks4.",
              "The convolutional block applies the following modules: (1) A convolution of 256 filters of kernel size 3 \u00d7 3 with stride 1 (2) Batch normalization18 (3) A rectifier nonlinearity Each residual block applies the following modules sequentially to its input: (1) A convolution of 256 filters of kernel size 3 \u00d7 3 with stride 1 (2) Batch normalization (3) A rectifier nonlinearity (4) A convolution of 256 filters of kernel size 3 \u00d7 3 with stride 1 (5) Batch normalization (6) A skip connection that adds the input to the block (7) A rectifier nonlinearity The output of the residual tower is passed into two separate \u2018heads\u2019 for computing the policy and value.",
              "The policy head applies the following modules: (1) A convolution of 2 filters of kernel size 1 \u00d7 1 with stride 1 (2) Batch normalization (3) A rectifier nonlinearity (4) A fully connected linear layer that outputs a vector of size 192 + 1 = 362, corresponding to logit probabilities for all intersections and the pass move The value head applies the following modules: (1) A convolution of 1 filter of kernel size 1 \u00d7 1 with stride 1 (2) Batch normalization (3) A rectifier nonlinearity (4) A fully connected linear layer to a hidden layer of size 256 (5) A rectifier nonlinearity (6) A fully connected linear layer to a scalar (7) A tanh nonlinearity outputting a scalar in the range [\u22121, 1] The overall network depth, in the 20- or 40-block network, is 39 or 79 parameterized layers, respectively, for the residual tower, plus an additional 2 layers for the policy head and 3 layers for the value head.",
              "We note that a different variant of residual networks was simultaneously applied to computer Go33 and achieved an amateur dan-level performance;",
              "however, this was restricted to a single-headed policy network trained solely by supervised learning.",
              "Figure 4 shows the results of a comparison between network architectures.",
              "Specifically, we compared four different neural networks: (1) dual\u2013res: the network contains a 20-block residual tower, as described above, followed by both a policy head and a value head.",
              "This is the architecture used in AlphaGo Zero.",
              "(2) sep\u2013res: the network contains two 20-block residual towers.",
              "The first tower is followed by a policy head and the second tower is followed by a value head.",
              "(3) dual\u2013conv: the network contains a non-residual tower of 12 convolutional blocks, followed by both a policy head and a value head.",
              "(4) sep\u2013conv: the network contains two non-residual towers of 12 convolutional blocks.",
              "The first tower is followed by a policy head and the second tower is followed by a value head.",
              "This is the architecture used in AlphaGo Lee.",
              "Each network was trained on a fixed dataset containing the final 2 million games of self-play data generated by a previous run of AlphaGo Zero, using stochastic gradient descent with the annealing rate, momentum and regularization hyperparameters described for the supervised learning experiment;",
              "however, cross-entropy and MSE components were weighted equally, since more data was available.",
              "We evaluated the relative strength of AlphaGo Zero (Figs 3a, 6) by measuring the Elo rating of each player.",
              "We estimate the probability that player a will defeat player b by a logistic function , and estimate the ratings e(\u00b7) by Bayesian logistic regression, computed by the BayesElo program25 using the standard constant celo = 1/400.",
              "Elo ratings were computed from the results of a 5 s per move tournament between AlphaGo Zero, AlphaGo Master, AlphaGo Lee and AlphaGo Fan.",
              "The raw neural network from AlphaGo Zero was also included in the tournament.",
              "The Elo ratings of AlphaGo Fan, Crazy Stone, Pachi and GnuGo were anchored to the tournament values from previous work12, and correspond to the players reported in that work.",
              "The results of the matches of AlphaGo Fan against Fan Hui and AlphaGo Lee against Lee Sedol were also included to ground the scale to human references, as otherwise the Elo ratings of AlphaGo are unrealistically high due to self-play bias.",
              "The Elo ratings in Figs 3a, 4a, 6a were computed from the results of evaluation games between each iteration of player during self-play training.",
              "Further evaluations were also performed against baseline players with Elo ratings anchored to the previously published values12.",
              "We measured the head-to-head performance of AlphaGo Zero against AlphaGo Lee, and the 40-block instance of AlphaGo Zero against AlphaGo Master, using the same player and match conditions that were used against Lee Sedol in Seoul, 2016.",
              "Each player received 2 h of thinking time plus 3 byoyomi periods of 60 s per move.",
              "All games were scored using Chinese rules with a komi of 7.",
              "5 points.",
              "The datasets used for validation and testing are the GoKifu dataset (available from http://gokifu.",
              "com/) and the KGS dataset (available from https://u-go.",
              "net/gamerecords/).",
              "Friedman, J.",
              ", Hastie, T.",
              "& Tibshirani, R.",
              "The Elements of Statistical Learning: Data Mining, Inference, and Prediction (Springer, 2009) LeCun, Y.",
              ", Bengio, Y.",
              "& Hinton, G.",
              "Deep learning.",
              "Nature 521, 436\u2013444 (2015) Article CAS ADS Google Scholar Krizhevsky, A.",
              ", Sutskever, I.",
              "& Hinton, G.",
              "ImageNet classification with deep convolutional neural networks.",
              "In Adv.",
              "Neural Inf.",
              "Process.",
              "Syst.",
              "Vol.",
              "25 (eds Pereira, F.",
              ", Burges, C.",
              "J.",
              "C.",
              ", Bottou, L.",
              "& Weinberger, K.",
              "Q.",
              ") 1097\u20131105 (2012) He, K.",
              ", Zhang, X.",
              ", Ren, S .",
              "& Sun, J.",
              "Deep residual learning for image recognition.",
              "In Proc.",
              "29th IEEE Conf.",
              "Comput.",
              "Vis.",
              "Pattern Recognit.",
              "770\u2013778 (2016) Hayes-Roth, F.",
              ", Waterman, D.",
              "& Lenat, D.",
              "Building Expert Systems (Addison-Wesley, 1984) Mnih, V.",
              "et al.",
              "Human-level control through deep reinforcement learning.",
              "Nature 518, 529\u2013533 (2015) Article CAS ADS Google Scholar Guo, X.",
              ", Singh, S.",
              "P.",
              ", Lee, H.",
              ", Lewis, R.",
              "L.",
              "& Wang, X.",
              "Deep learning for real-time Atari game play using offline Monte-Carlo tree search planning.",
              "In Adv.",
              "Neural Inf.",
              "Process.",
              "Syst.",
              "Vol.",
              "27 (eds Ghahramani, Z.",
              ", Welling, M.",
              ", Cortes, C.",
              ", Lawrence, N.",
              "D.",
              "& Weinberger, K.",
              "Q.",
              ") 3338\u20133346 (2014) Mnih, V .",
              "et al.",
              "Asynchronous methods for deep reinforcement learning.",
              "In Proc.",
              "33rd Int.",
              "Conf.",
              "Mach.",
              "Learn.",
              "Vol.",
              "48 (eds Balcan, M.",
              "F.",
              "& Weinberger, K.",
              "Q.",
              ") 1928\u20131937 (2016) Jaderberg, M .",
              "et al.",
              "Reinforcement learning with unsupervised auxiliary tasks.",
              "In 5th Int.",
              "Conf.",
              "Learn.",
              "Representations (2017) Dosovitskiy, A.",
              "& Koltun, V.",
              "Learning to act by predicting the future.",
              "In 5th Int.",
              "Conf.",
              "Learn.",
              "Representations (2017) Man \u0301dziuk, J.",
              "in Challenges for Computational Intelligence ( Duch, W.",
              "& Man \u0301dziuk, J.",
              ") 407\u2013442 (Springer, 2007) Silver, D.",
              "et al.",
              "Mastering the game of Go with deep neural networks and tree search.",
              "Nature 529, 484\u2013489 (2016) Article CAS ADS Google Scholar Coulom, R.",
              "Efficient selectivity and backup operators in Monte-Carlo tree search.",
              "In 5th Int.",
              "Conf.",
              "Computers and Games (eds Ciancarini, P.",
              "& van den Herik, H.",
              "J.",
              ") 72\u201383 (2006) Kocsis, L.",
              "& Szepesva\u0301ri, C.",
              "Bandit based Monte-Carlo planning.",
              "In 15th Eu.",
              "Conf.",
              "Mach.",
              "Learn.",
              "282\u2013293 (2006) Browne, C.",
              "et al.",
              "A survey of Monte Carlo tree search methods.",
              "IEEE Trans.",
              "Comput.",
              "Intell.",
              "AI Games 4, 1\u201349 (2012) Article Google Scholar Fukushima, K.",
              "Neocognitron: a self organizing neural network model for a mechanism of pattern recognition unaffected by shift in position.",
              "Biol.",
              "Cybern.",
              "36, 193\u2013202 (1980) Article CAS Google Scholar LeCun, Y.",
              "& Bengio, Y.",
              "in The Handbook of Brain Theory and Neural Networks Ch.",
              "3 (ed.",
              "Arbib, M.",
              ") 276\u2013278 (MIT Press, 1995) Ioffe, S.",
              "& Szegedy, C.",
              "Batch normalization: accelerating deep network training by reducing internal covariate shift.",
              "In Proc.",
              "32nd Int.",
              "Conf.",
              "Mach.",
              "Learn.",
              "Vol.",
              "37 448\u2013456 (2015) Hahnloser, R.",
              "H.",
              "R.",
              ", Sarpeshkar, R.",
              ", Mahowald, M.",
              "A.",
              ", Douglas, R.",
              "J.",
              "& Seung, H.",
              "S.",
              "Digital selection and analogue amplification coexist in a cortex-inspired silicon circuit.",
              "Nature 405, 947\u2013951 (2000) Article CAS ADS Google Scholar Howard, R.",
              "Dynamic Programming and Markov Processes (MIT Press, 1960) Sutton, R .",
              "& Barto, A.",
              "Reinforcement Learning: an Introduction (MIT Press, 1998) Bertsekas, D.",
              "P.",
              "Approximate policy iteration: a survey and some new methods.",
              "J.",
              "Control Theory Appl.",
              "9, 310\u2013335 (2011) Article MathSciNet Google Scholar Scherrer, B.",
              "Approximate policy iteration schemes: a comparison.",
              "In Proc.",
              "31st Int.",
              "Conf.",
              "Mach.",
              "Learn.",
              "Vol.",
              "32 1314\u20131322 (2014) Rosin, C.",
              "D.",
              "Multi-armed bandits with episode context.",
              "Ann.",
              "Math.",
              "Artif.",
              "Intell.",
              "61, 203\u2013230 (2011) Article MathSciNet Google Scholar Coulom, R.",
              "Whole-history rating: a Bayesian rating system for players of time-varying strength.",
              "In Int.",
              "Conf.",
              "Comput.",
              "Games (eds van den Herik, H.",
              "J.",
              ", Xu, X .",
              "Ma, Z .",
              "& Winands, M.",
              "H.",
              "M.",
              ") Vol.",
              "5131 113\u2013124 (Springer, 2008) Laurent, G.",
              "J.",
              ", Matignon, L.",
              "& Le Fort-Piat, N.",
              "The world of independent learners is not Markovian.",
              "Int.",
              "J.",
              "Knowledge-Based Intelligent Engineering Systems 15, 55\u201364 (2011) Article Google Scholar Foerster, J.",
              "N .",
              "et al.",
              "Stabilising experience replay for deep multi-agent reinforcement learning.",
              "In Proc.",
              "34th Int.",
              "Conf.",
              "Mach.",
              "Learn.",
              "Vol.",
              "70 1146\u20131155 (2017) Heinrich, J .",
              "& Silver, D.",
              "Deep reinforcement learning from self-play in imperfect-information games.",
              "In NIPS Deep Reinforcement Learning Workshop (2016) Jouppi, N.",
              "P .",
              "et al.",
              "In-datacenter performance analysis of a Tensor Processing Unit.",
              "Proc.",
              "44th Annu.",
              "Int.",
              "Symp.",
              "Comp.",
              "Architecture Vol.",
              "17 1\u201312 (2017) Maddison, C.",
              "J.",
              ", Huang, A.",
              ", Sutskever, I .",
              "& Silver, D.",
              "Move evaluation in Go using deep convolutional neural networks.",
              "In 3rd Int.",
              "Conf.",
              "Learn.",
              "Representations.",
              "(2015) Clark, C .",
              "& Storkey, A.",
              "J.",
              "Training deep convolutional neural networks to play Go.",
              "In Proc.",
              "32nd Int.",
              "Conf.",
              "Mach.",
              "Learn.",
              "Vol.",
              "37 1766\u20131774 (2015) Tian, Y.",
              "& Zhu, Y.",
              "Better computer Go player with neural network and long-term prediction.",
              "In 4th Int.",
              "Conf.",
              "Learn.",
              "Representations (2016) Cazenave, T.",
              "Residual networks for computer Go.",
              "IEEE Trans.",
              "Comput.",
              "Intell.",
              "AI Games https://doi.",
              "org/10.",
              "1109/TCIAIG.",
              "2017.",
              "2681042 (2017) Huang, A.",
              "AlphaGo master online series of games.",
              "https://deepmind.",
              "com/research/AlphaGo/match-archive/master (2017) Barto, A.",
              "G.",
              "& Duff, M.",
              "Monte Carlo matrix inversion and reinforcement learning.",
              "Adv.",
              "Neural Inf.",
              "Process.",
              "Syst.",
              "6, 687\u2013694 (1994) Google Scholar Singh, S.",
              "P.",
              "& Sutton, R.",
              "S.",
              "Reinforcement learning with replacing eligibility traces.",
              "Mach.",
              "Learn.",
              "22, 123\u2013158 (1996) MATH Google Scholar Lagoudakis, M.",
              "G.",
              "& Parr, R.",
              "Reinforcement learning as classification: leveraging modern classifiers.",
              "In Proc.",
              "20th Int.",
              "Conf.",
              "Mach.",
              "Learn.",
              "424\u2013431 (2003) Scherrer, B.",
              ", Ghavamzadeh, M.",
              ", Gabillon, V.",
              ", Lesner, B.",
              "& Geist, M.",
              "Approximate modified policy iteration and its application to the game of Tetris.",
              "J.",
              "Mach.",
              "Learn.",
              "Res.",
              "16, 1629\u20131676 (2015) MathSciNet MATH Google Scholar Littman, M.",
              "L.",
              "Markov games as a framework for multi-agent reinforcement learning.",
              "In Proc.",
              "11th Int.",
              "Conf.",
              "Mach.",
              "Learn.",
              "157\u2013163 (1994) Enzenberger, M.",
              "The integration of a priori knowledge into a Go playing neural network.",
              "http://www.",
              "cgl.",
              "ucsf.",
              "edu/go/Programs/neurogo-html/neurogo.",
              "html (1996) Enzenberger, M.",
              "in Advances in Computer Games (eds Van Den Herik, H.",
              "J.",
              ", Iida, H.",
              "& Heinz, E.",
              "A.",
              ") 97\u2013108 (2003) Sutton, R.",
              "Learning to predict by the method of temporal differences.",
              "Mach.",
              "Learn.",
              "3, 9\u201344 (1988) Google Scholar Schraudolph, N.",
              "N.",
              ", Dayan, P.",
              "& Sejnowski, T.",
              "J.",
              "Temporal difference learning of position evaluation in the game of Go.",
              "Adv.",
              "Neural Inf.",
              "Process.",
              "Syst.",
              "6, 817\u2013824 (1994) Google Scholar Silver, D.",
              ", Sutton, R.",
              "& Mu\u0308ller, M.",
              "Temporal-difference search in computer Go.",
              "Mach.",
              "Learn.",
              "87, 183\u2013219 (2012) Article MathSciNet Google Scholar Silver, D.",
              "Reinforcement Learning and Simulation-Based Search in Computer Go.",
              "PhD thesis, Univ.",
              "Alberta, Edmonton, Canada (2009) Gelly, S.",
              "& Silver, D.",
              "Monte-Carlo tree search and rapid action value estimation in computer Go.",
              "Artif.",
              "Intell.",
              "175, 1856\u20131875 (2011) Article MathSciNet Google Scholar Coulom, R.",
              "Computing Elo ratings of move patterns in the game of Go.",
              "Int.",
              "Comput.",
              "Games Assoc.",
              "J.",
              "30, 198\u2013208 (2007) Google Scholar Gelly, S.",
              ", Wang, Y.",
              ", Munos, R.",
              "& Teytaud, O.",
              "Modification of UCT with patterns in Monte-Carlo Go.",
              "Report No.",
              "6062 (INRIA, 2006) Baxter, J.",
              ", Tridgell, A.",
              "& Weaver, L.",
              "Learning to play chess using temporal differences.",
              "Mach.",
              "Learn.",
              "40, 243\u2013263 (2000) Article Google Scholar Veness, J.",
              ", Silver, D.",
              ", Blair, A.",
              "& Uther, W.",
              "Bootstrapping from game tree search.",
              "In Adv.",
              "Neural Inf.",
              "Process.",
              "Syst.",
              "1937\u20131945 (2009) Lai, M.",
              "Giraffe: Using Deep Reinforcement Learning to Play Chess.",
              "MSc thesis, Imperial College London (2015) Schaeffer, J.",
              ", Hlynka, M .",
              "& Jussila, V.",
              "Temporal difference learning applied to a high-performance game-playing program.",
              "In Proc.",
              "17th Int.",
              "Jt Conf.",
              "Artif.",
              "Intell.",
              "Vol.",
              "1 529\u2013534 (2001) Tesauro, G.",
              "TD-gammon, a self-teaching backgammon program, achieves master-level play.",
              "Neural Comput.",
              "6, 215\u2013219 (1994) Article Google Scholar Buro, M.",
              "From simple features to sophisticated evaluation functions.",
              "In Proc.",
              "1st Int.",
              "Conf.",
              "Comput.",
              "Games 126\u2013145 (1999) Sheppard, B.",
              "World-championship-caliber Scrabble.",
              "Artif.",
              "Intell.",
              "134, 241\u2013275 (2002) Article Google Scholar Moravc\u02c7i\u0301k, M.",
              "et al.",
              "DeepStack: expert-level artificial intelligence in heads-up no-limit poker.",
              "Science 356, 508\u2013513 (2017) Article ADS MathSciNet Google Scholar Tesauro, G & Galperin, G.",
              "On-line policy improvement using Monte-Carlo search.",
              "In Adv.",
              "Neural Inf.",
              "Process.",
              "Syst.",
              "1068\u20131074 (1996) Tesauro, G.",
              "Neurogammon: a neural-network backgammon program.",
              "In Proc.",
              "Int.",
              "Jt Conf.",
              "Neural Netw.",
              "Vol.",
              "3, 33\u201339 (1990) Samuel, A.",
              "L.",
              "Some studies in machine learning using the game of checkers II - recent progress.",
              "IBM J.",
              "Res.",
              "Develop.",
              "11, 601\u2013617 (1967) Article Google Scholar Kober, J.",
              ", Bagnell, J.",
              "A.",
              "& Peters, J.",
              "Reinforcement learning in robotics: a survey.",
              "Int.",
              "J.",
              "Robot.",
              "Res.",
              "32, 1238\u20131274 (2013) Article Google Scholar Zhang, W.",
              "& Dietterich, T.",
              "G.",
              "A reinforcement learning approach to job-shop scheduling.",
              "In Proc.",
              "14th Int.",
              "Jt Conf.",
              "Artif.",
              "Intell.",
              "1114\u20131120 (1995) Cazenave, T.",
              ", Balbo, F.",
              "& Pinson, S.",
              "Using a Monte-Carlo approach for bus regulation.",
              "In Int.",
              "IEEE Conf.",
              "Intell.",
              "Transport.",
              "Syst.",
              "1\u20136 (2009) Evans, R.",
              "& Gao, J.",
              "Deepmind AI reduces Google data centre cooling bill by 40%.",
              "https://deepmind.",
              "com/blog/deepmind-ai-reduces-google-data-centre-cooling-bill-40/ (2016) Abe, N .",
              "et al.",
              "Empirical comparison of various reinforcement learning strategies for sequential targeted marketing.",
              "In IEEE Int.",
              "Conf.",
              "Data Mining 3\u201310 (2002) Silver, D.",
              ", Newnham, L.",
              ", Barker, D.",
              ", Weller, S.",
              "& McFall, J.",
              "Concurrent reinforcement learning from customer interactions.",
              "In Proc.",
              "30th Int.",
              "Conf.",
              "Mach.",
              "Learn.",
              "Vol.",
              "28 924\u2013932 (2013) Tromp, J.",
              "Tromp\u2013Taylor rules.",
              "http://tromp.",
              "github.",
              "io/go.",
              "html (1995) Mu\u0308ller, M.",
              "Computer Go.",
              "Artif.",
              "Intell.",
              "134, 145\u2013179 (2002) Article Google Scholar Shahriari, B.",
              ", Swersky, K.",
              ", Wang, Z.",
              ", Adams, R.",
              "P.",
              "& de Freitas, N.",
              "Taking the human out of the loop: a review of Bayesian optimization.",
              "Proc.",
              "IEEE 104, 148\u2013175 (2016) Article Google Scholar Segal, R.",
              "B.",
              "On the scalability of parallel UCT.",
              "Comput.",
              "Games 6515, 36\u201347 (2011) Article MathSciNet Google Scholar Download references We thank A.",
              "Cain for work on the visuals;",
              "A.",
              "Barreto, G.",
              "Ostrovski, T.",
              "Ewalds, T.",
              "Schaul, J.",
              "Oh and N.",
              "Heess for reviewing the paper;",
              "and the rest of the DeepMind team for their support.",
              "David Silver, Julian Schrittwieser and Karen Simonyan: These authors contributed equally to this work.",
              "DeepMind, 5 New Street Square, London, EC4A 3TW, UK David Silver, Julian Schrittwieser, Karen Simonyan, Ioannis Antonoglou, Aja Huang, Arthur Guez, Thomas Hubert, Lucas Baker, Matthew Lai, Adrian Bolton, Yutian Chen, Timothy Lillicrap, Fan Hui, Laurent Sifre, George van den Driessche, Thore Graepel & Demis Hassabis You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar D.",
              "S.",
              ", J.",
              "S.",
              ", K.",
              "S.",
              ", I.",
              "A.",
              ", A.",
              "G.",
              ", L.",
              "S.",
              "and T.",
              "H.",
              "designed and implemented the reinforcement learning algorithm in AlphaGo Zero.",
              "A.",
              "H.",
              ", J.",
              "S.",
              ", M.",
              "L.",
              "and D.",
              "S.",
              "designed and implemented the search in AlphaGo Zero.",
              "L.",
              "B.",
              ", J.",
              "S.",
              ", A.",
              "H.",
              ", F.",
              "H.",
              ", T.",
              "H.",
              ", Y.",
              "C.",
              "and D.",
              "S.",
              "designed and implemented the evaluation framework for AlphaGo Zero.",
              "D.",
              "S.",
              ", A.",
              "B.",
              ", F.",
              "H.",
              ", A.",
              "G.",
              ", T.",
              "L.",
              ", T.",
              "G.",
              ", L.",
              "S.",
              ", G.",
              "v.",
              "d.",
              "D.",
              "and D.",
              "H.",
              "managed and advised on the project.",
              "D.",
              "S.",
              ", T.",
              "G.",
              "and A.",
              "G.",
              "wrote the paper.",
              "Correspondence to David Silver.",
              "The authors declare no competing financial interests.",
              "Reviewer Information Nature thanks S.",
              "Singh and the other anonymous reviewer(s) for their contribution to the peer review of this work.",
              "Publisher's note: Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.",
              "One hundred moves of the first 20 games are shown;",
              "full games are provided in the Supplementary Information.",
              "The corresponding joseki are shown on the right.",
              "The corresponding joseki are shown on the right.",
              "The 3-day training run was subdivided into 20 periods.",
              "The best player from each period (as selected by the evaluator) played a single game against itself, with 2 h time controls.",
              "One hundred moves are shown for each game;",
              "full games are provided in the Supplementary Information.",
              "The 40-day training run was subdivided into 20 periods.",
              "The best player from each period (as selected by the evaluator) played a single game against itself, with 2 h time controls.",
              "One hundred moves are shown for each game;",
              "full games are provided in the Supplementary Information.",
              "One hundred moves of the first 20 games are shown;",
              "full games are provided in the Supplementary Information.",
              "This zipped file contains the game records of self-play and tournament games played by AlphaGo Zero in .",
              "sgf format.",
              "(ZIP 82 kb) Reprints and Permissions Silver, D.",
              ", Schrittwieser, J.",
              ", Simonyan, K.",
              "et al.",
              "Mastering the game of Go without human knowledge.",
              "Nature 550, 354\u2013359 (2017).",
              "https://doi.",
              "org/10.",
              "1038/nature24270 Download citation Received: 07 April 2017 Accepted: 13 September 2017 Published: 19 October 2017 Issue Date: 19 October 2017 DOI: https://doi.",
              "org/10.",
              "1038/nature24270 Anyone you share the following link with will be able to read this content: Sorry, a shareable link is not currently available for this article.",
              "Provided by the Springer Nature SharedIt content-sharing initiative Empirical Software Engineering (2024) Frontiers of Physics (2024) By submitting a comment you agree to abide by our Terms and Community Guidelines.",
              "If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate.",
              "You have full access to this article via your institution.",
              "To beat world champions at the game of Go, the computer program AlphaGo has relied largely on supervised learning from millions of human expert moves.",
              "David Silver and colleagues have now produced a system called AlphaGo Zero, which is based purely on reinforcement learning and learns solely from self-play.",
              "Starting from random moves, it can reach superhuman level in just a couple of days of training and five million games of self-play, and can now beat all previous versions of AlphaGo.",
              "Because the machine independently discovers the same fundamental principles of the game that took humans millennia to conceptualize, the work suggests that such principles have some universal character, beyond human bias.",
              "Advertisement Nature (Nature) ISSN 1476-4687 (online) ISSN 0028-0836 (print) \u00a9 2023 Springer Nature Limited Sign up for the Nature Briefing newsletter \u2014 what matters in science, free to your inbox daily."
            ]
          }
        ],
        "IBM Watson is a system that can analyze medical records and literature to provide evidence-based recommendations for cancer care.": [
          {
            "title": "How IBM\u2019s Watson went from the future of health care to sold off for parts.",
            "url": "https://slate.com/technology/2022/01/ibm-watson-health-failure-artificial-intelligence.html",
            "content": [
              "How IBM\u2019s Watson went from the future of health care to sold off for parts.",
              "Most likely, you\u2019re familiar with Watson from the IBM computer system\u2019s appearance on Jeopardy!",
              "in 2011, when it beat former champions Ken Jennings and Brad Rudder.",
              "Watson\u2019s time on Jeopardy!",
              "was fun viewing, but it was also a very savvy public debut of a product that IBM wanted to sell: Watson Health.",
              "Watson Health was supposed to change health care in a lot of important ways, by providing insight to oncologists about care for cancer patients, delivering insight to pharmaceutical companies about drug development, helping to match patients with clinical trials, and more.",
              "It sounded revolutionary, but it never really worked.",
              "Recently, Watson Health was, essentially, sold for parts: Francisco Partners, a private equity firm, bought some of Watson\u2019s data and analytics products for what Bloomberg News said was more than $1 billion.",
              "On Friday\u2019s episode of What Next: TBD, I spoke with Casey Ross, technology correspondent for Stat News, who has been covering Watson Health for years, about how Watson went from being the future of health care to being sold for scraps.",
              "Our conversation has been edited and condensed for clarity.",
              "Lizzie O\u2019Leary: I look at the amount of money that went into pulling this together.",
              "Acquisition after acquisition.",
              "It was billions of dollars, and it sold for a billion in the end.",
              "Is there any way to read that as anything but a failure?",
              "Casey Ross: Financially, certainly not.",
              "They spent way more money building this than they got back.",
              "Just the acquisitions alone cost them $5 billion.",
              "That it was sold so many years later, after so much in effort\u20147,000 employees at one point\u2014means that this will as a total failure that they needed to just cut their losses and move on.",
              "Why did IBM want to get into the health data business?",
              "What problem did they think Watson would help solve?",
              "There\u2019s a tremendous amount of information that is collected every day on the care of hundreds of millions of people.",
              "However, there is currently no way to connect that information, to link it to an individual across all the domains in which they get care, and then to develop a holistic picture of who they are, of what their diseases are, of what the best treatments are, and how to ensure that they get the best care at the lowest possible cost.",
              "There is no connectivity right now that can do that at scale.",
              "The people in the technology sector look at it and say, \u201cThis has to be fixed, and we\u2019re going to fix it.",
              "\u201d Google, Microsoft, a lot of very big companies are extremely interested in health care.",
              "What is so attractive for these big tech companies about health care?",
              "It\u2019s one of the biggest parts of our economy.",
              "It\u2019s a three trillion business that has legacy technology infrastructure that should be embarrassing.",
              "Tech companies are drawn to audacious challenges like this, and ones where they can make\u2014if they\u2019re successful\u2014a ton of money.",
              "That\u2019s how things are today, but the same problems have been around since the advent of digitized data.",
              "In 2012, IBM closed a deal with Memorial Sloan Kettering, one of the preeminent cancer centers in the country, to train an AI to make treatment recommendations.",
              "What was the goal?",
              "What were they trying to do?",
              "They were really trying to democratize the expertise of Memorial Sloan Kettering\u2019s oncologists, to make that expertise available to patients all over the world and to develop this standardized engine for providing optimal treatment recommendations, customized to a patient, in front of a doctor, thousands of miles away.",
              "It was a beautiful notion.",
              "They were trying to say, \u201cWell, let\u2019s make it more objective.",
              "Let\u2019s look at all of the data, and let\u2019s tell every physician, for this patient in front of you, this is how they should be treated.",
              "\u201d So you get your biopsy results, and things don\u2019t look good, but you\u2019re not just getting the expertise or the biases of your particular oncologist.",
              "You\u2019re getting the wealth of thousands of oncologists distilled into an algorithm?",
              "Yes, you are getting all of that data, across so many different physicians, crunched down into a very digestible format and recommendation that could then lead to the best treatment for that patient.",
              "Reading your reporting, it sounds like this was incredibly important to IBM.",
              "In 2015, Ginni Rometty, who was the CEO at the time, went on Charlie Rose.",
              "She said health care was \u201cour moonshot.",
              "\u201d How much of IBM\u2019s hopes were hung on this thing?",
              "The company made a huge bet that this could be the bridge to a different kind of future for IBM, which at the time was several years of quarterly revenue declines.",
              "They were trying to use Watson as a bridge to a different future where IBM wasn\u2019t this old guard hardware company that everybody knew so well, but was operating on the cutting edge of artificial intelligence.",
              "Health care was the biggest, the buzziest use case.",
              "This was where they were going to really show the surpassing value of their technology.",
              "To do that, IBM needed massive amounts of data on which to train Watson.",
              "It got that data through acquisitions, eventually spending some $5 billion buying a series of health data companies.",
              "What were those companies?",
              "Truven, Phytel, Explorys and merge.",
              "Truven had the biggest insurance database in the nation with 300 million covered lives, Explorys provided a clinical data set of actual electronic health records kept by health systems representing about 50 million or so patients, Phytel added on top of that, and Merge had a huge imaging database.",
              "They had all this data and the idea was: Expose Watson to that, and it finds patterns that physicians and anyone else can\u2019t possibly find when looking at that data, given all the variables in it.",
              "Except that was not the reality.",
              "One of IBM\u2019s high-profile partnerships with MD Anderson Cancer Center in Texas fell apart.",
              "A doctor involved said that there wasn\u2019t enough data for the program to make good recommendations, and that Watson had trouble with the complexity of patient files.",
              "The partnership was later audited and shelved.",
              "What went wrong?",
              "If you think about it, knowing what we know now or what we\u2019ve learned through this, the notion that you\u2019re going to take an artificial intelligence tool, expose it to data on patients who were cared for on the upper east side of Manhattan, and then use that information and the insights derived from it to treat patients in China, is ridiculous.",
              "You need to have representative data.",
              "The data from New York is just not going to generalize to different kinds of patients all the way across the world.",
              "What was happening in a clinical setting?",
              "What was happening to patients?",
              "Our window through the reporting was talking to physicians.",
              "We got concerns from them that the recommendations that it was giving were just not relevant.",
              "Maybe it would suggest a particular kind of treatment that wasn\u2019t available in the locality in which it was making the recommendation, or the recommendation did not at all square with the treatment protocols that were in use at the local institution or, and more commonly so, especially in the U.",
              "S.",
              "and Europe, \u201cyou\u2019re not telling me anything I don\u2019t already know.",
              "\u201d That was the big credibility gap for physicians.",
              "It was like, \u201cWell duh.",
              "Yeah, I know that that\u2019s the chemotherapy I should pursue.",
              "I know that this treatment follows that one.",
              "\u201d You got a hold of an internal IBM presentation from 2017 where a doctor at a hospital in Florida told the company this product was a piece of shit.",
              "Seeing that written down in an internal document, which was circulated among IBM executives, was a shocking thing to see.",
              "It really underscored the extent of the gap between what IBM was saying in public and what was happening behind the scenes.",
              "There were a lot of internal discussions, even a presentation, that indicated that the technology was not as far along as they\u2019d hoped, that it wasn\u2019t able to accomplish what they set out to accomplish in cancer care.",
              "There were probably a lot of people that believed, that truly did believe, that they would get there or that it was closer than maybe some people realized.",
              "I think the marketing got way ahead of the capabilities.",
              "It\u2019s very hard to listen to you and not think about Theranos, even though this is not a one-to-one parallel in any way.",
              "When you are trying to move by leaps and bounds with technology in the health care sector, it feels like a reminder that all things are not created equal, that making big leaps with people\u2019s health is a much riskier proposition.",
              "That underscores the central theme of this story: When you try to combine the bravado of the tech culture and the notion that you can achieve these huge audacious goals in a domain where you\u2019re dealing with people\u2019s lives and health and the most sacrosanct aspects of their existence and their bodies, you need to have evidence to back up that you can do what you say you can do.",
              "Why did they continue on trying to rescue this product that they seemed to know internally was failing?",
              "I think they had so much invested in it that it really was, for them, too big to fail.",
              "It had 7,000 employees.",
              "They\u2019d invested so much time and energy on marketing in the success of the product that they really needed it to succeed.",
              "Instead, they got a fail.",
              "But Watson\u2019s fate certainly doesn\u2019t mean that AI in health care is going away.",
              "Just recently, Microsoft and a large group of hospitals announced a coalition to develop AI solutions in health care.",
              "If you had to pin down a moral to the story, is it that AI in health care isn\u2019t ready for prime time, or that IBM did it wrong?",
              "I think it\u2019s both of those.",
              "This will be a case study for business schools for decades.",
              "When you look at what IBM did and the strategy mistakes, the tactical errors that they made in pursuing this product, they made a lot of unforced errors here.",
              "It\u2019s also true that the generation of technology that they had was nowhere near ready to accomplish the things that they set out to accomplish and promised that they could accomplish.",
              "I don\u2019t think that the failure of Watson means that artificial intelligence isn\u2019t ready to make significant improvements and changes in health care.",
              "I think it means the way that they approached it is a cautionary tale that lays out how not to do it.",
              "Does the failure of Watson Health make you worry that it\u2019s going to shut down other avenues for innovation?",
              "Will such a spectacular belly flop impede progress?",
              "I don\u2019t think so.",
              "There were so many mistakes that were made, that were learned from, that, if anything, it will facilitate faster learning and better decision making by other parties that are now poised to disrupt health care and make the progress that IBM failed to achieve.",
              "There\u2019s a saying that pioneers often end up with arrows in their backs, and that\u2019s what happened here.",
              "They\u2019re an example, a spectacular example, of wrongheaded decision making and missteps that didn\u2019t have to happen.",
              "By learning from that, I think advancement and progress and true benefits will be faster coming.",
              "Future Tense is a partnership of Slate, New America, and Arizona State University that examines emerging technologies, public policy, and society.",
              "Slate is published by The Slate Group, a Graham Holdings Company.",
              "All contents \u00a9 2023 The Slate Group LLC.",
              "All rights reserved."
            ]
          },
          {
            "title": "A meta-analysis of Watson for Oncology in clinical application - Nature",
            "url": "https://www.nature.com/articles/s41598-021-84973-5",
            "content": [
              "A meta-analysis of Watson for Oncology in clinical application - Nature",
              "Thank you for visiting nature.",
              "com.",
              "You are using a browser version with limited support for CSS.",
              "To obtain the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in Internet Explorer).",
              "In the meantime, to ensure continued support, we are displaying the site without styles and JavaScript.",
              "Advertisement Scientific Reports volume 11, Article number: 5792 (2021) Cite this article 9327 Accesses 44 Citations 19 Altmetric Metrics details Using the method of meta-analysis to systematically evaluate the consistency of treatment schemes between Watson for Oncology (WFO) and Multidisciplinary Team (MDT), and to provide references for the practical application of artificial intelligence clinical decision-support system in cancer treatment.",
              "We systematically searched articles about the clinical applications of Watson for Oncology in the databases and conducted meta-analysis using RevMan 5.",
              "3 software.",
              "A total of 9 studies were identified, including 2463 patients.",
              "When the MDT is consistent with WFO at the \u2018Recommended\u2019 or the \u2018For consideration\u2019 level, the overall concordance rate is 81.",
              "52%.",
              "Among them, breast cancer was the highest and gastric cancer was the lowest.",
              "The concordance rate in stage I\u2013III cancer is higher than that in stage IV, but the result of lung cancer is opposite (P < 0.",
              "05).",
              "Similar results were obtained when MDT was only consistent with WFO at the \"recommended\" level.",
              "Moreover, the consistency of estrogen and progesterone receptor negative breast cancer patients, colorectal cancer patients under 70 years old or ECOG 0, and small cell lung cancer patients is higher than that of estrogen and progesterone positive breast cancer patients, colorectal cancer patients over 70 years old or ECOG 1\u20132, and non-small cell lung cancer patients, with statistical significance (P < 0.",
              "05).",
              "Treatment recommendations made by WFO and MDT were highly concordant for cancer cases examined, but this system still needs further improvement.",
              "Owing to relatively small sample size of the included studies, more well-designed, and large sample size studies are still needed.",
              "With the rapid development of human society, cancer-related knowledge is also growing exponentially, which has caused a knowledge gap for clinic physicians1.",
              "With the increasing understanding of each patient, more and more information need to be absorbed from the literature in providing evidence-based cancer treatment.",
              "Research shows that clinic physicians can only spend 4.",
              "6 h a week to acquire the latest professional knowledge2, resulting in a relative delay in information absorption, leading to an increasing gap between the results achieved by academic research centers and the actual situation3.",
              "However, compared with physicians in other clinical disciplines, clinical oncologists urgently need to acquire evidence-based medicine knowledge in time to support patients' personalized treatment plans.",
              "Consequently, clinicians need some new types of tools to bridge this knowledge gap, support and adopt new treatment methods in an evidence-based manner, so that more patients can benefit from social investment in research and development4,5.",
              "Artificial intelligence (AI) first appeared in the early 1950s, which refers to the creation of intelligent machines with functions and reactions like human beings6.",
              "The goal of AI is to replicate human mind, that is to say, it can perform tasks such as identification, interpretation, reasoning and transformation, and it is good at the areas that human beings are not good at, such as absorbing a large amount of qualitative information that can recognize the patterns of relevant information7,8.",
              "Now AI has gradually entered medicine.",
              "Image recognition using AI has been successfully applied to image-based clinical diagnosis, such as melanoma recognition in dermoscopy images9 or detection of diabetic retinopathy in retinal fundus photographs10, and more and more researches on AI are also carried out in oncology11,12,13,14.",
              "AI aims to enhance human capabilities, enable human beings to apply more and more complex knowledge to clinical decision-making, and bring more and more diversified and complex patient data into personalized management.",
              "Due to the recent development of cognitive computing technology, its application in clinical oncology still lacks large-scale data, and there are clinical differences in different regions and ethnic groups.",
              "Watson for Oncology (WFO), an artificial intelligence assistant decision system, was developed by IBM Corporation (USA) with the help of top oncologists from Memorial Sloan Kettering Cancer Center (MSK).",
              "It took more than 4 years of training, based on national comprehensive cancer network (NCCN) cancer treatment guidelines and more than 100 years of clinical cancer treatment experience in the United States, and can recommend appropriate chemotherapy regimens for specific cancer patients.",
              "As for supported cases, the treatment recommendations provided by WFO are divided into 3 groups: Recommended, i.",
              "e. green \"buckets\", which represents a treatment supported by obvious evidence;",
              "For consideration, i.",
              "e. yellow \"buckets\", which represents a potentially suitable alternative;",
              "and Not recommended, i.",
              "e. red \"buckets\", which stands for a treatment with contraindications or obvious evidence against its use.",
              "In order to compare the consistency between WFO and clinicians in different countries and regions in various aspects and on a large scale, many hospitals have formed Multidisciplinary Team (MDT), which is composed of oncologists, surgeons, pathologists and radiologists, etc.",
              "They discuss the advantages and disadvantages of each candidate treatment scheme and finally determine the treatment scheme.",
              "If the concordance is achieved when the MDT recommendation is in the \u2018Recommended\u2019/\u2018Recommended\u2019 or \u2018For consideration\u2019 categories of WFO, it is defined as concordant;",
              "Otherwise, it is discordant.",
              "The results showed that there were obvious differences in the concordance rate of different regions and types of cancers.",
              "And so far, there has been no published meta-analysis comparing the consistency of WFO and MDT.",
              "Therefore, this study aims to systematically review the literature and provide the latest evidence of WFO's clinical use, analyze the consistency, advantages and disadvantages between WFO's treatment scheme in cancer patients and that of clinicians, and further summarize and analyze WFO's clinical practice, so as to provide references for further clinical application of WFO.",
              "This meta-analysis is registered in the International Prospective Register of Systematic Reviews (PROSPERO) trial registry (CRD42020199418).",
              "In addition and where applicable, the general guidelines of the Preferred Reporting Items for Systematic Reviews and Meta-Analysis (PRISMA) Statement were followed.",
              "And this study was performed and prepared according to the guidelines proposed by Cochrane Collaboration (http://www.",
              "cochrane-handbook.",
              "org).",
              "Since WFO started commercial use in 2015, literatures from 2015 onwards were searched.",
              "Cochrane Library, PubMed, Excerpta Medica Database (EMbase), China National Knowledge Infrastructure (CNKI), CQVIP and Chinese Biomedicine (CBM) databases (updated until December 31, 2019) were searched using the following terms: artificial intelligence, clinical decision-support system, Watson for Oncology, neoplasm, treatment, Multidisciplinary Team, concordance and comparative study.",
              "Other potentially qualified articles were also screened manually.",
              "The studies meeting the following criteria would be included: (a) The clinical use of WFO has been focused on regardless of cancer type, (b) the studies contain at least one subgroup of analysis data, (c) the studies should be original research articles published either in Chinese or English regardless of nationality, (d) the studies have compared the consistency of treatment schemes determined by WFO and MDT, and (e) there is no limit to whether the article is a prospective or a retrospective study and whether blind methods have used.",
              "The following are the major exclusion criteria: (a) The studies only describe the simple use of WFO and do not involve any data or only WFO research and development process data, (b) the article does not compare the treatment schemes between WFO and MDT, and (c) book chapter, comment, case reports, and other forms without detailed data.",
              "Two investigators evaluated the quality of the literatures and extracted the data independently.",
              "Any disagreements were discussed and consulted by an additional independent arbitrator for further resolution.",
              "The lack of original data is supplemented by contacting the original author via e-mail.",
              "The data were extracted with a standardized table, including (a) general information, such as the title of the publication, first author\u2019s surname, the original document number and source, year of publication and country, (b) research characteristics, such as the eligibility of the research, the characteristics of the research object, the design scheme and quality of the literature, the design scheme and quality of the literature, the specific contents and implementation methods of the research measures, relevant bias prevention measures, and the main test results;",
              "(c) data needed for this meta-analysis, such as the total number of cases in each group, and the number of cases of events were collected by the second classification.",
              "According to the Cochrane Reviewers\u2019 Handbook 6.",
              "1 (http://www.",
              "cochrane-handbook.",
              "org), the quality of the literature was evaluated including 7 aspects: random sequence generation (selection bias), allocation concealment (selection bias), blinding of participants and personnel (performance bias), blinding of outcome assessment (detection bias), incomplete outcome data (attrition bias), selective reporting (reporting bias) and other bias, and the judgment of \"yes\" (low bias), \"no\" (high bias) and \"unclear\" (lack of relevant information or uncertainty of bias) is made respectively.",
              "Review Manager statistical software (RevMan, version 5.",
              "3.",
              "5, Cochrane Collaboration Network) was applied to assess the risk-of-bias and provide visual results.",
              "RevMan 5.",
              "3.",
              "5 was also applied to analyze the extracted data.",
              "The main purpose of this study was to compare the consistency of treatment schemes determined by WFO and MDT in different cancer types, so the statistical data were dichotomous data (coincidence or non-coincidence).",
              "In the analysis, odds ratios (ORs) and the 95% confidence intervals (CIs) were performed for clinic-pathological features (TNM stage, histopathological category, etc.)",
              ".",
              "Q test or I2 test was used to judge the heterogeneity among the studies.",
              "When P < 0.",
              "05 or I2 > 50%, there was significant heterogeneity among the studies.",
              "On the contrary, there was no heterogeneity.",
              "When there was no statistical heterogeneity between studies, the fixed effect model was used to merge the results.",
              "If there was statistical heterogeneity, we analyzed the causes of heterogeneity, and adopted subgroup analysis or sensitivity analysis.",
              "For the documents that still could not eliminate heterogeneity, the data could be combined from the perspective of clinical significance.",
              "Random effect model was adopted for combination analysis, and the results were carefully interpreted.",
              "If the data provided could not be meta-analyzed, only descriptive analysis would be done.",
              "A total of 367 relevant publications from January 2015 to December 2019, were obtained from the preliminary search.",
              "There were 237 English literatures (Pubmed: 102, Embase: 106, Cochrane Library: 29) and 130 Chinese literatures (CNKI: 43, CQVIP: 47, CBM: 40).",
              "After reading the title, abstract and full text successively, 8 articles15,16,17,18,19,20,21,22 and 1 conference abstract 23 were finally included, all of which were Non-RCTs published between 2017 and 2019, 7 studies15,16,17,19,20,22,23 were published in English, and 2 studies18,21 in Chinese.",
              "The basic process of publication selection, the main characteristics and quality evaluation of included publications have been shown in Fig.",
              "1, Table 1, Supplementary Fig.",
              "1, 2, respectively.",
              "Of the 9 studies, 7 studies15,16,17,19,20,21,22 clearly defined the method of selecting cases, and other studies did not indicate the \"randomization\" of the included samples.",
              "In all studies, WFO and MDT treatment schemes were formulated successively for the same patient in the group, so there was no allocation bias.",
              "7 studies15,16,18,19,20,21,22 did not indicate specific blind method implementation plan or did not adopt blind method, but the result judgment and measurement will not be affected.",
              "Although two studies16,22 did not provide detailed four-category data, they did not completely affect our meta-analysis, so we believed that all studies had no obvious bias in selective reporting results and ensured the basic integrity of the data, but other biases were still unclear.",
              "Because it was of little significance to use Begg\u2019s funnel plot and Egger test to detect publication bias when the number of documents was too small (< 10), no publication bias analysis had been performed in this study.",
              "Due to the little difference in the quality of the documents included in this meta-analysis, no further sensitivity analysis had been made.",
              "After subgroup analysis, most I2 test results were less than 50%, and there was lower heterogeneity among the studies included in this system evaluation.",
              "Flow diagram of the study selection process.",
              "Of the 9 included studies, a total of 7 studies15,17,18,19,20,21,23 provided four types of complete data (including WFO three types of treatment schemes and unavailable cases) on the consistency of treatment schemes determined by WFO and MDT in different cancer types, involving seven types of cancers including breast cancer, rectal cancer, colon cancer, gastric cancer, lung cancer, ovarian cancer and cervical cancer.",
              "Of the 1738 cases included (shown in Supplementary Fig.",
              "3), 959 (55.",
              "18%) cases were WFO \u2018Recommended\u2019 schemes (green schemes) that were consistent with MDT treatment schemes, 503 cases (28.",
              "94%) were \u2018For consideration\u2019 (orange schemes), and the sum of the two was 1462 cases (84.",
              "12%).",
              "However, there were 166 cases (9.",
              "55%) that were \u2018Not recommend\u2019 scheme (pink scheme) and 110 cases (6.",
              "33%) that were not supported by WFO (\u2018Not available\u2019 scheme).",
              "Under the condition that the MDT recommendations were consistent with the \u2018Recommended\u2019 or \u2018For consideration\u2019 categories of WFO, we conducted meta-analysis according to different clinical stages of patients (stage I\u2013III vs. stage IV).",
              "A total of 8 studies15,16,17,18,19,20,21,23 were included in the analysis.",
              "Of the 1807 cases included, 1473 (81.",
              "52%) WFO treatment schemes were consistent with the MDT.",
              "The concordance rate of stage I\u2013III was 86.",
              "00% (1026/1193), which was higher than 80.",
              "78% (496/614) of stage IV.",
              "But the meta-analysis results showed that there was a significant statistical heterogeneity (I2 = 83%) at different stages, the meta-analysis was conducted using random effect model (shown in Fig.",
              "2A).",
              "The results showed that the difference was not statistically significant, P = 0.",
              "20 [OR 1.",
              "68, 95% CI (0.",
              "76, 3.",
              "74)].",
              "In order to further analyze the consistency between MDT and WFO, we analyzed the situation that only WFO \u2018Recommended\u2019 was included but \u2018For consideration\u2019 was excluded.",
              "A total of 9 studies15,16,17,18,19,20,21,22,23 were included in the analysis.",
              "Of the 2463 cases included, 1299 (52.",
              "74%) WFO treatment schemes were consistent with MDT.",
              "The consistency of stage I\u2013III was 56.",
              "46% (962/1704), which was greater than 44.",
              "40% (337/759) of stage IV.",
              "The meta-analysis results showed that there was significant statistical heterogeneity (I2 = 90%) in different stages (shown in Fig.",
              "3A), so we also conducted the meta-analysis using random effect model.",
              "The results also showed that the difference was not statistically significant, P = 0.",
              "08 [OR 1.",
              "77, 95% CI (0.",
              "93, 3.",
              "40)].",
              "Meta-analysis showed significant statistical heterogeneity (I2 > 50%), so subgroup analysis was further adopted according to tumor classification.",
              "Forest plot of consistency between WFO (\u2018Recommended\u2019 or \u2018For consideration\u2019) and MDT for patients with various cancers.",
              "Treatment was considered concordant if the delivered treatment was rated as either \u2018Recommended\u2019 or \u2018For consideration\u2019 by WFO and discordant if the delivered treatment was either \u2018Not recommended\u2019 by WFO or was physician\u2019s choice (not included in WFO).",
              "Overall concordance of various cancers in stages I\u2013III and IV (A).",
              "Concordance of various estrogen and progesterone receptors (ER+/PR+ vs. ER\u2212, PR\u2212) in breast cancer (B).",
              "Concordance of various pathological types (small cell vs. non-small cell) in lung cancer (C).",
              "Forest plot of consistency between WFO (only \u2018Recommended\u2019) and MDT for patients with various cancers.",
              "Treatment was considered concordant if the delivered treatment was rated as \u2018Recommended\u2019 by WFO and discordant if the delivered treatment was rated as other options by WFO or was physician\u2019s choice (not included in WFO).",
              "Overall concordance of various cancers in stages I\u2013III and IV (A).",
              "Concordance of various estrogen and progesterone receptors (ER+/PR+vs. ER\u2212, PR\u2212) in breast cancer (B).",
              "Concordance of various performance status (ECOG 0 vs. ECOG 1\u20132) in colorectal cancer (C).",
              "Concordance of various age (< 70-year-old vs. older) in colorectal cancer (D).",
              "Concordance of various pathological types (small cell vs. non-small cell) in lung cancer (E).",
              "Under the condition that the MDT recommendations were consistent with the \u2018Recommended\u2019 or \u2018For consideration\u2019 categories of WFO, we conducted meta-analysis according to different clinical stages of patients (stage I\u2013III vs. stage IV).",
              "The results showed that the consistency of stage I\u2013III was greater than that of stage IV except lung cancer (shown in Table 2 and Fig.",
              "4).",
              "A total of 3 studies17,20,21 (n = 890) were included in our meta-analysis of breast cancer, the results showed that the difference was statistically significant, P = 0.",
              "001 [OR 2.",
              "29, 95% CI (1.",
              "37, 3.",
              "82)].",
              "A total of 4 studies16,17,18,23 (n = 398) were included in our analysis of colorectal cancer, the results showed that the difference was statistically significant, P < 0.",
              "0001 [OR 3.",
              "44, 95% CI (1.",
              "91, 6.",
              "17)].",
              "A total of 3 studies17,18,23 (n = 181) were included in our analysis of colon cancer, the results showed that the difference was statistically significant, P = 0.",
              "04 [OR 2.",
              "31, 95% CI (1.",
              "06, 5.",
              "05)].",
              "A total of 2 studies17,23 (n = 148) were included in our analysis of rectal cancer, the results showed that the difference was not statistically significant, P = 0.",
              "17 [OR 3.",
              "31, 95% CI (0.",
              "60, 18.",
              "25)].",
              "A total of 2 studies15,17 (n = 107) were included in our analysis of gastric cancer, the results showed that the difference was statistically significant, P = 0.",
              "07 [OR 9.",
              "81, 95% CI (0.",
              "86, 111.",
              "5)].",
              "A total of 3 studies17,19,23 (n = 374) were included in our analysis of lung cancer, the results showed that the difference was not statistically significant, P = 0.",
              "08 [OR 0.",
              "32, 95% CI (0.",
              "09, 1.",
              "13)].",
              "Forest plot of consistency between WFO (\u2018Recommended\u2019 or \u2018For consideration\u2019) and MDT for patients (subgroup).",
              "In addition, a total of 3 studies17,20,21 (n = 890) provided data on estrogen and progesterone receptors (ER+/PR+ vs. ER\u2212, PR\u2212) in breast cancer patients, so meta-analysis was further carried out.",
              "The results showed (shown in Fig.",
              "2B) that there was not statistically significant difference, P = 0.",
              "47 [OR 0.",
              "85, 95% CI (0.",
              "54, 1.",
              "34)].",
              "A total 2 of studies17,19 (n = 262) provided data on pathological types (small cell vs. non-small cell) of lung cancer patients.",
              "The results showed that the consistency of small cell lung cancer was higher than that of non-small cell lung cancer (shown in Fig.",
              "2C), and the difference was statistically significant, P = 0.",
              "02 [OR 3, 95% CI (1.",
              "20, 7.",
              "48)].",
              "Under the condition that the MDT recommendations were consistent with only the \u2018Recommended\u2019 categories of WFO, we conducted meta-analysis again according to different clinical stages of patients (stage I\u2013III vs. stage IV).",
              "Similarly, the results showed that the consistency of stage I\u2013III was greater than that of stage IV except lung cancer (shown in Table 3 and Fig.",
              "5).",
              "A total of 3 studies17,20,21 (n = 890) were included in our meta-analysis of breast cancer, the results showed that the difference was not statistically significant, P = 0.",
              "37 [OR 1.",
              "33, 95% CI (0.",
              "72, 2.",
              "47)].",
              "A total of 5 studies16,17,18,22,23 (n = 1054) were included in our analysis of colorectal cancer, the results showed that the difference was statistically significant, P < 0.",
              "0001 [OR 3.",
              "70, 95% CI (1.",
              "93, 7.",
              "11)].",
              "A total of 4 studies17,18,22,23 (n = 837) were included in our analysis of colon cancer, the results showed that the difference was statistically significant, P = 0.",
              "0004 [OR 2.",
              "49, 95% CI (1.",
              "50, 4.",
              "14)].",
              "A total of 2 studies17,23 (n = 148) were included in our analysis of rectal cancer, the results showed that the difference was statistically significant, P = 0.",
              "0001 [OR 5.",
              "87, 95% CI (2.",
              "36, 14.",
              "58)].",
              "A total of 2 studies15,17 (n = 107) were included in our analysis of gastric cancer, the results showed that the difference was statistically significant, P = 0.",
              "01 [OR 3.",
              "48, 95% CI (1.",
              "28, 9.",
              "43)].",
              "A total of 3 studies17,19,23 (n = 374) were included in our analysis of lung cancer, the results showed that the difference was not statistically significant, P = 0.",
              "18 [OR 0.",
              "36, 95% CI (0.",
              "08, 1.",
              "57)].",
              "Forest plot of consistency between WFO (only \u2018Recommended\u2019) and MDT for patients with various cancers in stages I\u2013III and IV (subgroup).",
              "In addition, a total of 3 studies17,20,21 (n = 890) provided data on estrogen and progesterone receptors (ER+/PR+ vs. ER\u2212, PR\u2212) in breast cancer patients.",
              "The meta-analysis results showed that the consistency of hormone receptor-positive patients (Luminal A and Luminal B) was lower than that of negative patients (HER2 positive and triple negative), and the difference was statistically significant, P = 0.",
              "02 [OR 0.",
              "72, 95% CI (0.",
              "54, 0.",
              "95)] (shown in Fig.",
              "3B).",
              "A total of 2 studies16,22 provided data of different performance status (ECOG 0 vs. ECOG 1\u20132) and age (< 70-year-old vs. older) of colorectal cancer patients.",
              "The results showed that the consistency of ECOG 0 patients was higher than that of ECOG 1\u20132 patients and the difference was statistically significant, P = 0.",
              "003 [OR 1.",
              "59, 95% CI (1.",
              "17, 2.",
              "17)] (shown in Fig.",
              "3C);",
              "the consistency of patients under 70 years old was higher than that of older, the difference was statistically significant, P = 0.",
              "03 [OR 4.",
              "06, 95% CI (1.",
              "18, 13.",
              "97)] (shown in Fig.",
              "3D).",
              "A total of 2 studies17,19 (n = 262) provided data on pathological types (small cell vs. non-small cell) of lung cancer patients.",
              "The results also showed that the consistency of small cell lung cancer was higher than that of non-small cell lung cancer, and the difference was statistically significant, P < 0.",
              "00001 [OR 11.",
              "05, 95% CI (4.",
              "93, 24.",
              "77)] (shown in Fig.",
              "3E).",
              "On the whole, it is found that the consistency of stage I\u2013III of other cancers except lung cancer is better than that of stage IV, and most of the results are statistically significant (P < 0.",
              "05), regardless of setting WFO consistent with MDT at the \u2018For consideration\u2019 level (\u2018Recommended\u2019 or \u2018For consideration\u2019) or at the \u2018Recommended\u2019 level (only \u2018Recommended\u2019).",
              "At the \u2018For consideration\u2019 level, the overall concordance rate of breast cancer is the highest (88.",
              "99%), while that of gastric cancer is the lowest (57.",
              "94%).",
              "The consistency of small cell lung cancer in patients with lung cancer is higher than that of non-small cell lung cancer, and the difference is statistically significant.",
              "At the \u2018Recommended\u2019 level, the overall concordance rate of rectal cancer is the highest (81.",
              "76%), while that of gastric cancer is still the lowest (29.",
              "90%).",
              "The consistency of hormone receptor-positive patients (Luminal A and B) of breast cancer is lower than that of hormone receptor-negative patients (HER2 positive and triple negative).",
              "In colorectal cancer patients, the consistency of ECOG 0 is higher than that of ECOG 1\u20132 and under 70 years old is higher than older.",
              "However, in lung cancer patients, the consistency of small cell lung cancer is still higher than that of non-small cell lung cancer, and the difference is statistically significant.",
              "Besides showing high consistency with MDT in most cancers, WFO, as an artificial intelligence clinical decision support system also has the following advantages: (a) WFO improves doctors' work efficiency and reduces workload.",
              "Hu\u2019s study18 showed that using WFO can save an average of 8.",
              "2 min per case (the average time for obtaining reports is 7.",
              "3 \u00b1 2.",
              "2 min, and the average time for MDT consultation is 15.",
              "5 \u00b1 6.",
              "1 min).",
              "There is no need to wait for MDT to discuss together helps to reduce the time required to formulate chemotherapy scheme24, thus shortening the hospitalization time of patients.",
              "(b) WFO can prevent man-made calculation errors.",
              "Chemotherapy schemes and drug selection involve complicated and time-consuming processes, and there may be errors in selection25,26;",
              "it can realize accurate medication through computer programs to prevent such errors20,27.",
              "(c) WFO can improve the quality of doctor-patient communication and prevent doctor-patient disputes.",
              "Nowadays, due to a variety of reasons, patients' distrust of doctors is increasing in China28,29.",
              "The more patients participate in the decision-making of their own therapeutic regimen and understand the incidence of adverse events and other information, the more they have confidence in the therapeutic regimen and will cooperate with doctors more actively30.",
              "(d) WFO can reduce the burden on patients.",
              "It can eliminate the time wasted by patients in consultation in various large hospitals, help patients to obtain the more accurate treatment as soon as possible, avoid fatigue caused by transportation, and reduce travel and accommodation costs while avoiding fatigue caused by travel.",
              "(e) WFO can improve the professional level of young doctors.",
              "It can significantly shorten the time that junior doctors must spend on consulting relevant documents.",
              "At the same time, WFO will give reasons for selection, evidence documents and drug use instructions for each scheme, and update the system once every 1\u20132 months, thus improving the ability of junior doctors to make accurate diagnosis and treatment recommendations in a short time and improving self-confidence.",
              "Recent studies showed that the consistency between WFO and MDT for cancer patients is not completely consistent, especially in patients with advanced cancer, there is a significant decrease in consistency.",
              "It is confirmed that WFO still has certain limitations, which lead to differences in the consistency rate when the system is applied in other countries.",
              "The limitations are shown as follows: (a) Different treatment schemes: yellow and white people have significant differences in sensitivity and tolerance to certain specific chemotherapeutic drugs due to their different constitutions and key enzyme groups of drug metabolism, so that clinical guidelines between different countries and regions must also have certain differences.",
              "For example, the mutation rate of EGFR in lung cancer in European and American countries is about 15%, while that in China is more than 50%31,32.",
              "In China, primary research drugs Icotinib and Endostar33,34,35 are used to instead of other first-generation epidermal growth factor receptor-tyrosine kinase inhibitor (EGFR-TKI) and bevacizumab, because studies have shown that they are as effective as EGFR-TKI and bevacizumab in lung cancer patients in China36,37.",
              "Liu et al.",
              "19 and others have proposed that if WFO system can provide these two alternative therapeutic regimens in \u2018Recommended\u2019 or \u2018For consideration\u2019, the overall consistency of lung cancer in China can be increased from 65.",
              "8 to 93.",
              "2%.",
              "Xu et al.",
              "21 also believe that the difference in first-line treatment of advanced breast cancer can also be attributed to the fact that CDK4/6 inhibitors cannot be used because they are not listed in China.",
              "Similarly, WFO recommended panizumab targeted therapy in colon cancer patients, but it is not listed in China and patients cannot choose it38.",
              "(b) Different drug choices: WFO recommended chemotherapy regimen complies with NCCN guidelines, but it also includes thousands of clinical practice cases from MSK16.",
              "For example, due to the large difference between the surgical methods and guidelines for adjuvant treatment of gastric cancer in China and the United States39,40, the WFO applied research on gastric cancer in the study shows poor concordance rate.",
              "On the contrary, the adjuvant therapy and drug selection for colon cancer in eastern and western countries are more consistent, so the concordance rate between WFO and MDT is obviously increased.",
              "Liu et al.",
              "19 also suggested that WFO recommended concurrent chemoradiation during the treatment of lung cancer, whereas China performs sequential chemoradiation (up to 67%).",
              "Chinese patients often cannot tolerate concurrent radiotherapy and chemotherapy because their physique is usually weaker than that of western patients.",
              "The physique of Chinese patients is usually weaker than that of western patients, which leads to the decrease of coincidence rate between WFO and MDT.",
              "(c) Complications: comprehensive treatment for cancer patients is continuous, and patients may suffer from reversible and transient organ function damage.",
              "WFO may sometimes exclude some available schemes in the process of selecting the candidate scheme only based on the transient abnormal biochemical results of the patient41.",
              "In Hu's study18, a biochemical blood test of a colon cancer patient showed creatinine clearance rate < 30.",
              "WFO did not recommend CapeOX (oxaliplatin + capecitabine) scheme for the patient, but MDT considered that this was only the result of transient biochemical abnormality of the patient, so creatinine clearance rate was rechecked one week later and the result was > 30, so CapeOX scheme treatment was still carried out.",
              "In Liu's study19, a patient with active pulmonary tuberculosis was also diagnosed as stage III squamous cell lung cancer.",
              "If the standard chemoradiotherapy recommended by WFO is accepted, tuberculosis may spread rapidly, resulting in rapid death.",
              "Therefore, Liu et al.",
              "modified the treatment strategy to oral anti-tuberculosis drugs before radiotherapy and chemotherapy.",
              "Therefore, it is believed that if such individualized information can be incorporated into WFO, the coincidence rate between WFO and MDT will be greatly improved.",
              "(d) Economic factors: for example, in the treatment of breast cancer, WFO recommends the use of trastuzumab for HER2 positive patients, but patients in China are often forced to choose chemotherapy first due to the high price of this drug38.",
              "In the Republic of Korea, both WFO and MDT recommend regorafenib for patients with stage IV rectal cancer42, but some patients still received 5-fluorouracil (5-Fu)-base chemotherapy, because regorafenib is not only expensive, but also not covered by the national health insurance system16.",
              "Similarly, China also needs to consider the issue of medical insurance reimbursement, which also affects the consistency between WFO and MDT.",
              "If WFO can make targeted improvements to the treatment recommendations for patients with advanced cancer, non-small cell lung cancer, breast cancer with hormone receptor-positive and colorectal cancer with ECOG 1\u20132 or older (age > 70), it will be more suitable for clinical use in other countries.",
              "Although WFO has been gradually developed in many countries and regions, and the types of cancers supported are also gradually increasing, so far there is still a lack of evidence-based medicine research for this system.",
              "In order to understand the consistency between WFO and MDT, WFO advantages and disadvantages in clinical use, and to solve the practical problems encountered in the practical use of the system, we carried out a targeted meta-analysis.",
              "Unlike most of the original studies, which only carry out the consistency research at the \u2018For consideration\u2019 level (\u2018Recommended\u2019 or \u2018For consideration\u2019) or at the \u2018Recommended\u2019 level (only \u2018Recommended\u2019), this research respectively carries out meta-analysis of the above two aspects, which further supports some statistical results obtained from the original studies and provides new statistical evidence.",
              "It not only reminds clinicians to pay enough attention to patients with advanced cancer, non-small cell lung cancer, Luminal A and B breast cancer and colorectal cancer with ECOG 1\u20132 or older (age > 70) in the future when using WFO, but also provides clinical evidence for improvement of WFO.",
              "Of course, this meta-analysis still has certain limitations, which are mainly manifested in the following aspects: (a) The possibility of selection bias may exist in a few included studies;",
              "(b) The number of samples included in some studies is relatively small, and some study results are not fully reported, lacking complete data of the four classifications.",
              "(3) Most studies did not mention the relevant data of WFO's advantages such as shortening consultation time and coincidence between junior or senior doctors and WFO, which leads us to fail to further analyze some of WFO's advantages.",
              "(d) All data are published research or conference summaries, lack of grey literature, and possible literature selectivity bias.",
              "In addition, 182 cases were included in the initial stage in Liu's study on lung cancer19.",
              "In the further study, a total of 33 cases were excluded from the study without the support of WFO, and the remaining 149 patients were included in the study.",
              "However, the clinical stages of these 33 cases are not listed in detail and cannot be included for further Meta-analysis.",
              "Moreover, the distribution of patients in this study is unbalanced, that is, there are fewer patients in early stage, which is obviously different from the situation that there are more early-stage patients than late-stage patients in other cancers.",
              "All these may lead to different conclusions about lung cancer from other cancers.",
              "Of course, the sample size included in our systematic evaluation is small, so larger sample size, multi-center and high-quality randomized controlled trials are still needed for further verification in order to reach more reliable conclusions.",
              "To sum up, we should regard WFO as \"a tool, not a crutch\"43.",
              "If WFO is properly used, it will be regarded as a valuable tool.",
              "Proper use requires WFO to be only in the position of a complement to the doctor's work, instead of relying on it completely.",
              "Oncologists can integrate it with traditional resources such as colleagues' experience and scientific journals to choose the most effective method to provide chemotherapy schemes for patients, to help patients obtain more accurate and effective treatment, fasten and improve their treatment results.",
              "Of course, WFO should also make continuous improvement according to clinical use in other countries.",
              "People often say that AI will change medicine.",
              "In fact, through examples like WFO, we can look forward to how AI can enable people all over the world to obtain the best quality medical services fairly, no matter where or who the patients are44.",
              "Denu, R.",
              "A.",
              "et al.",
              "Influence of patient, physician, and hospital characteristics on the receipt of guideline-concordant care for inflammatory breast cancer.",
              "Cancer Epidemiol.",
              "40, 7\u201314.",
              "https://doi.",
              "org/10.",
              "1016/j.",
              "canep.",
              "2015.",
              "11.",
              "003 (2016).",
              "Article PubMed Google Scholar Woolhandler, S.",
              "& Himmelstein, D.",
              "U.",
              "Administrative work consumes one-sixth of U.",
              "S.",
              "physicians\u2019 working hours and lowers their career satisfaction.",
              "Int.",
              "J.",
              "Health Serv.",
              "44(4), 635\u2013642.",
              "https://doi.",
              "org/10.",
              "2190/HS.",
              "44.",
              "4.",
              "a (2014).",
              "Article PubMed Google Scholar American Society of Clinical Oncology.",
              "The state of cancer care in America, 2016: A report by the American Society of Clinical Oncology.",
              "J.",
              "Oncol.",
              "Pract.",
              "12(4), 339\u2013383 (2016).",
              "Article Google Scholar Yu, P.",
              ", Artz, D.",
              "& Warner, J.",
              "Electronic health records (EHRs): Supporting ASCO\u2019s vision of cancer care.",
              "Am.",
              "Soc.",
              "Clin.",
              "Oncol.",
              "Educ.",
              "Book 2014, 225\u2013231.",
              "https://doi.",
              "org/10.",
              "14694/EdBook_AM.",
              "2014.",
              "34.",
              "225 (2014).",
              "Article Google Scholar Castaneda, C.",
              "et al.",
              "Clinical decision support systems for improving diagnostic accuracy and achieving precision medicine.",
              "J.",
              "Clin.",
              "Bioinform.",
              "5, 4.",
              "https://doi.",
              "org/10.",
              "1186/s13336-015-0019-3 (2015).",
              "Article Google Scholar Musib, M.",
              "et al.",
              "Artificial intelligence in research.",
              "Science 357(6346), 28\u201330.",
              "https://doi.",
              "org/10.",
              "1126/science.",
              "357.",
              "6346.",
              "28 (2017).",
              "Article ADS PubMed Google Scholar Spangler, S.",
              "et al.",
              "Automated Hypothesis Generation Based on Mining Scientific Literature: Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.",
              "New York, NY, USA 2014, 1877\u20131886.",
              "https://doi.",
              "org/https://doi.",
              "org/10.",
              "1145/2623330.",
              "2623667 (2014).",
              "Dayarian, A.",
              "et al.",
              "Predicting protein phosphorylation from gene expression: Top methods from the IMPROVER Species Translation Challenge.",
              "Bioinformatics 31(4), 462\u2013470.",
              "https://doi.",
              "org/10.",
              "1093/bioinformatics/btu490 (2015).",
              "Article CAS PubMed Google Scholar Codella, N.",
              "et al.",
              "Deep learning, sparse coding, and SVM for melanoma recognition in dermoscopy images.",
              "Mach.",
              "Learn.",
              "Med.",
              "Imaging 2015, 118\u2013126.",
              "https://doi.",
              "org/10.",
              "1007/978-3-319-24888-2_15 (2015).",
              "Article Google Scholar Gulshan, V.",
              "et al.",
              "Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs.",
              "JAMA 316(22), 2402\u20132410.",
              "https://doi.",
              "org/10.",
              "1001/jama.",
              "2016.",
              "17216 (2016).",
              "Article PubMed Google Scholar Malek, M.",
              "et al.",
              "A machine learning approach for distinguishing uterine sarcoma from leiomyomas based on perfusion weighted MRI parameters.",
              "Eur.",
              "J.",
              "Radiol.",
              "110, 203\u2013211.",
              "https://doi.",
              "org/10.",
              "1016/j.",
              "ejrad.",
              "2018.",
              "11.",
              "009 (2019).",
              "Article PubMed Google Scholar Kawakami, E.",
              "et al.",
              "Application of artificial intelligence for preoperative diagnostic and prognostic prediction in epithelial ovarian cancer based on blood biomarkers.",
              "Clin.",
              "Cancer Res.",
              "25(10), 3006\u20133015.",
              "https://doi.",
              "org/10.",
              "1158/1078-0432.",
              "CCR-18-3378 (2019).",
              "Article CAS PubMed Google Scholar Li, S.",
              "et al.",
              "A DNA nanorobot functions as a cancer therapeutic in response to a molecular trigger in vivo.",
              "Nat.",
              "Biotechnol.",
              "36(3), 258\u2013264.",
              "https://doi.",
              "org/10.",
              "1038/nbt.",
              "4071 (2018).",
              "Article CAS PubMed Google Scholar Lu, H.",
              "N.",
              "et al.",
              "A mathematical-descriptor of tumor-mesoscopic-structure from computed-tomography images annotates prognostic- and molecular-phenotypes of epithelial ovarian cancer.",
              "Nat.",
              "Commun.",
              "10(1), 764.",
              "https://doi.",
              "org/10.",
              "1038/s41467-019-08718-9 (2019).",
              "Article ADS CAS PubMed PubMed Central Google Scholar Choi, Y.",
              "I.",
              "et al.",
              "Concordance rate between clinicians and Watson for Oncology among patients with advanced gastric cancer: Early, real-world experience in Korea.",
              "Can.",
              "J.",
              "Gastroenterol.",
              "Hepatol.",
              "2019, 8072928.",
              "https://doi.",
              "org/10.",
              "1155/2019/8072928 (2019).",
              "Article PubMed PubMed Central Google Scholar Kim, E.",
              "J.",
              "et al.",
              "Early experience with Watson for oncology in Korean patients with colorectal cancer.",
              "PLoS ONE 14(3), e0213640.",
              "https://doi.",
              "org/10.",
              "1371/journal.",
              "pone.",
              "0213640 (2019).",
              "Article CAS PubMed PubMed Central Google Scholar Zhou, N.",
              "et al.",
              "Concordance study between IBM Watson for Oncology and clinical practice for patients with cancer in China.",
              "Oncologist 24(6), 812\u2013819.",
              "https://doi.",
              "org/10.",
              "1634/theoncologist.",
              "2018-0255 (2019).",
              "Article PubMed Google Scholar Hu, C.",
              "L.",
              "et al.",
              "The application value of Watson for oncology in patients with colon cancer.",
              "Chin.",
              "J.",
              "Front.",
              "Med.",
              "Sci.",
              "(Electronic Version) 10(10), 116\u2013120.",
              "https://doi.",
              "org/10.",
              "12037/YXQY.",
              "2018.",
              "10-27 (2018).",
              "Article Google Scholar Liu, C.",
              "et al.",
              "Using artificial intelligence (Watson for Oncology) for treatment recommendations amongst Chinese patients with lung cancer: Feasibility study.",
              "J.",
              "Med.",
              "Internet Res.",
              "20(9), e11087.",
              "https://doi.",
              "org/10.",
              "2196/11087 (2018).",
              "Article PubMed PubMed Central Google Scholar Somashekhar, S.",
              "P.",
              "et al.",
              "Watson for Oncology and breast cancer treatment recommendations: Agreement with an expert multidisciplinary tumor board.",
              "Ann.",
              "Oncol.",
              "29(2), 418\u2013423.",
              "https://doi.",
              "org/10.",
              "1093/annonc/mdx781 (2018).",
              "Article CAS PubMed Google Scholar Xu, J.",
              "N.",
              ", Jiang, Y.",
              "J.",
              ", Duan, Y.",
              "Y.",
              ", Hua, S.",
              "Y.",
              "& Sun, T.",
              "Application of Watson for Oncology on therapy in patients with breast cancer.",
              "J.",
              "Chin.",
              "Res.",
              "Hosp.",
              "3, 19\u201324.",
              "https://doi.",
              "org/10.",
              "19450/j.",
              "cnki.",
              "jcrh.",
              "2018.",
              "03.",
              "005 (2018).",
              "Article Google Scholar Lee, W.",
              "S.",
              "et al.",
              "Assessing concordance with Watson for Oncology, a cognitive computing decision support system for colon cancer treatment in Korea.",
              "JCO Clin.",
              "Cancer Inform.",
              "2, 1\u20138.",
              "https://doi.",
              "org/10.",
              "1200/CCI.",
              "17.",
              "00109 (2018).",
              "Article PubMed Google Scholar Somashekhar, S.",
              "P.",
              "et al.",
              "Early experience with IBM Watson for Oncology (WFO) cognitive computing system for lung and colorectal cancer treatment.",
              "In Journal of clinical oncology, Conference: 2017 annual meeting of the american society of clinical oncology, ASCO.",
              "United States 35(15 Supplement 1) (2017).",
              "Printz, C.",
              "Artificial intelligence platform for oncology could assist in treatment decisions.",
              "Cancer 123(6), 905.",
              "https://doi.",
              "org/10.",
              "1002/cncr.",
              "30655 (2017).",
              "Article PubMed Google Scholar Murphy, E.",
              "V.",
              "Clinical decision support: Effectiveness in improving quality processes and clinical outcomes and factors that may influence success.",
              "Yale J.",
              "Biol.",
              "Med.",
              "87(2), 187\u2013197 (2014).",
              "PubMed PubMed Central Google Scholar Keiffer, M.",
              "R.",
              "Utilization of clinical practice guidelines: Barriers and facilitators.",
              "Nurs.",
              "Clin.",
              "N.",
              "Am.",
              "50(2), 327\u2013345.",
              "https://doi.",
              "org/10.",
              "1016/j.",
              "cnur.",
              "2015.",
              "03.",
              "007 (2015).",
              "Article Google Scholar Svenstrup, D.",
              ", J\u00f8rgensen, H.",
              "L.",
              "& Winther, O.",
              "Rare disease diagnosis: A review of web search, social media and large-scale datamining approaches.",
              "Rare Dis.",
              "3(1), e1083145.",
              "https://doi.",
              "org/10.",
              "1080/21675511.",
              "2015.",
              "1083145 (2015).",
              "Article PubMed PubMed Central Google Scholar Zhou, M.",
              ", Zhao, L.",
              ", Campy, K.",
              "S.",
              "& Wang, S.",
              "Changing of China\u2019s health policy and doctor-patient relationship: 1949\u20132016.",
              "Health Policy Technol.",
              "6(3), 358\u2013367.",
              "https://doi.",
              "org/10.",
              "1016/j.",
              "hlpt.",
              "2017.",
              "05.",
              "002 (2017).",
              "Article Google Scholar Chan, C.",
              "S.",
              "Mistrust of physicians in China: Society, institution, and interaction as root causes.",
              "Dev.",
              "World Bioeth.",
              "18(1), 16\u201325.",
              "https://doi.",
              "org/10.",
              "1111/dewb.",
              "12162 (2018).",
              "Article PubMed Google Scholar Fang, J.",
              "M.",
              "et al.",
              "The establishment of a new medical model for tumor treatment combined with Watson for Oncology, MDT and patient involvement.",
              "J.",
              "Clin.",
              "Oncol.",
              "36(15 suppl), e18504.",
              "https://doi.",
              "org/10.",
              "1200/JCO.",
              "2018.",
              "36.",
              "15_suppl.",
              "e18504 (2018).",
              "Article Google Scholar Li, T.",
              ", Kung, H.",
              "J.",
              ", Mack, P.",
              "C.",
              "& Gandara, D.",
              "R.",
              "Genotyping and genomic profiling of non-small-cell lung cancer: Implications for current and future therapies.",
              "J.",
              "Clin.",
              "Oncol.",
              "31(8), 1039\u20131049.",
              "https://doi.",
              "org/10.",
              "1200/JCO.",
              "2012.",
              "45.",
              "3753 (2013).",
              "Article CAS PubMed PubMed Central Google Scholar Zhou, C.",
              "Lung cancer molecular epidemiology in China: Recent trends.",
              "Transl.",
              "Lung Cancer Res.",
              "3(5), 270\u2013279.",
              "https://doi.",
              "org/10.",
              "3978/j.",
              "issn.",
              "2218-6751.",
              "2014.",
              "09.",
              "01 (2014).",
              "Article CAS PubMed PubMed Central Google Scholar Lu, S.",
              "et al.",
              "A multicenter, open-label, randomized phase II controlled study of rh-endostatin (Endostar) in combination with chemotherapy in previously untreated extensive-stage small-cell lung cancer.",
              "J.",
              "Thorac.",
              "Oncol.",
              "10(1), 206\u2013211.",
              "https://doi.",
              "org/10.",
              "1097/JTO.",
              "0000000000000343 (2015).",
              "Article CAS PubMed Google Scholar Sun, Y.",
              "et al.",
              "Endostar Phase III NSCLC Study Group.",
              "Long-term results of a randomized, double-blind, and placebo-controlled phase III trial: Endostar (rh-endostatin) versus placebo in combination with vinorelbine and cisplatin in advanced non-small cell lung cancer.",
              "Thorac.",
              "Cancer 4(4), 440\u2013448.",
              "https://doi.",
              "org/10.",
              "1111/1759-7714.",
              "12050 (2013).",
              "Article CAS PubMed Google Scholar Wang, J.",
              ", Gu, L.",
              "J.",
              ", Fu, C.",
              "X.",
              ", Cao, Z.",
              "& Chen, Q.",
              "Y.",
              "Endostar combined with chemotherapy compared with chemotherapy alone in the treatment of nonsmall lung carcinoma: A meta-analysis based on Chinese patients.",
              "Indian J.",
              "Cancer 51(Suppl 3), e106\u2013e109.",
              "https://doi.",
              "org/10.",
              "4103/0019-509X.",
              "154099 (2014).",
              "Article PubMed Google Scholar Grigoriu, B.",
              ", Berghmans, T.",
              "& Meert, A.",
              "P.",
              "Management of EGFR mutated nonsmall cell lung carcinoma patients.",
              "Eur.",
              "Respir.",
              "J.",
              "45(4), 1132\u20131141.",
              "https://doi.",
              "org/10.",
              "1183/09031936.",
              "00156614 (2015).",
              "Article CAS PubMed Google Scholar Shi, Y.",
              "et al.",
              "Icotinib versus gefitinib in previously treated advanced non-small-cell lung cancer (ICOGEN): A randomized, double-blind phase 3 non-inferiority trial.",
              "Lancet Oncol.",
              "14(10), 953\u2013961.",
              "https://doi.",
              "org/10.",
              "1016/S1470-2045(13)70355-3 (2013).",
              "Article CAS PubMed Google Scholar Zhou, N.",
              ", Li, A.",
              "Q.",
              ", Liu, G.",
              "W.",
              ", Zhang, G.",
              "Q.",
              "& Zhang, X.",
              "C.",
              "Clinical application of artificial intelligence-Watson for Oncology.",
              "China Digit.",
              "Med.",
              "13(10), 23\u201325 (2018).",
              "Google Scholar Zhou, J.",
              "& Fan, Y.",
              "Z.",
              "Different methods of alimentary tract reconstruction after gastrectomy.",
              "Surg.",
              "Res.",
              "New Tech.",
              "4(4), 270\u2013277 (2015).",
              "Google Scholar Strong, V.",
              "E.",
              "et al.",
              "Comparison of young patients with gastric cancer in the United States and China.",
              "Ann.",
              "Surg.",
              "Oncol.",
              "24(13), 3964\u20133971.",
              "https://doi.",
              "org/10.",
              "1245/s10434-017-6073-2 (2017).",
              "Article PubMed Google Scholar Wang, C.",
              "F.",
              "Discussion on the comprehensive treatment and prevention of cancer.",
              "World Latest Med.",
              "Inf.",
              "18(35), 180\u2013183.",
              "https://doi.",
              "org/10.",
              "19613/j.",
              "cnki.",
              "1671-3141.",
              "2018.",
              "35.",
              "118 (2018).",
              "Article Google Scholar Grothey, A.",
              "et al.",
              "Regorafenib monotherapy for previously treated metastatic colorectal cancer (CORRECT): An international, multicentre, randomised, placebo-controlled, phase 3 trial.",
              "Lancet 381(9863), 303\u2013312.",
              "https://doi.",
              "org/10.",
              "1016/S0140-6736(12)61900-X (2013).",
              "Article CAS PubMed Google Scholar Hamilton, J.",
              "G.",
              "et al.",
              "\u201cA Tool, Not a Crutch\u201d: Patient perspectives about IBM Watson for Oncology trained by memorial sloan kettering.",
              "J.",
              "Oncol.",
              "Pract.",
              "15(4), e277\u2013e288 (2019).",
              "Article Google Scholar Krittanawong, C.",
              ", Zhang, H.",
              "J.",
              ", Wang, Z.",
              ", Aydar, M.",
              "& Kitai, T.",
              "Artificial intelligence in precision cardiovascular medicine.",
              "J.",
              "Am.",
              "Coll.",
              "Cardiol.",
              "69(21), 2657\u20132664.",
              "https://doi.",
              "org/10.",
              "1016/j.",
              "jacc.",
              "2017.",
              "03.",
              "571 (2017).",
              "Article PubMed Google Scholar Download references Scientific Research and Technology Development Program of Guangxi (NO.",
              "Guike 14124004) and the Natural Science Foundation of Guangxi (NO.",
              "GXNSFAA118147).",
              "These authors contributed equally: Zhou Jie and Zeng Zhiying.",
              "Department of Gynecologic Oncology, Guangxi Medical University Cancer Hospital, Key Laboratory of Early Prevention and Treatment for Regional High Frequency Tumor, Ministry of Education, Nanning, 530021, Guangxi, People\u2019s Republic of China Zhou Jie & Li Li Department of Gynecology, The Second Affiliated Hospital, University of South China, Hengyang, 421001, Hunan, People\u2019s Republic of China Zhou Jie Department of Anesthesiology, The Second Affiliated Hospital, University of South China, Hengyang, 421001, Hunan, People\u2019s Republic of China Zeng Zhiying You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar You can also search for this author in PubMed Google Scholar Conceptualization, L.",
              "L.",
              "and Z.",
              "J.",
              ";",
              "software, Z.",
              "Z.",
              ";",
              "validation, L.",
              "L.",
              "and Z.",
              "J.",
              ";",
              "investigation, Z.",
              "J.",
              ";",
              "resources, Z.",
              "J.",
              ";",
              "data curation, Z.",
              "Z.",
              ";",
              "writing\u2014original draft preparation, Z.",
              "J.",
              ";",
              "writing\u2014review and editing, L.",
              "L.",
              ";",
              "visualization, L.",
              "L.",
              ";",
              "supervision, L.",
              "L.",
              ";",
              "project administration, L.",
              "L.",
              ";",
              "funding acquisition, L.",
              "L.",
              "All authors have read and agreed to the published version of the manuscript.",
              "Correspondence to Li Li.",
              "The authors declare no competing interests.",
              "Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.",
              "Open Access This article is licensed under a Creative Commons Attribution 4.",
              "0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made.",
              "The images or other third party material in this article are included in the article's Creative Commons licence, unless indicated otherwise in a credit line to the material.",
              "If material is not included in the article's Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.",
              "To view a copy of this licence, visit http://creativecommons.",
              "org/licenses/by/4.",
              "0/.",
              "Reprints and Permissions Jie, Z.",
              ", Zhiying, Z.",
              "& Li, L.",
              "A meta-analysis of Watson for Oncology in clinical application.",
              "Sci Rep 11, 5792 (2021).",
              "https://doi.",
              "org/10.",
              "1038/s41598-021-84973-5 Download citation Received: 21 July 2020 Accepted: 25 November 2020 Published: 11 March 2021 DOI: https://doi.",
              "org/10.",
              "1038/s41598-021-84973-5 Anyone you share the following link with will be able to read this content: Sorry, a shareable link is not currently available for this article.",
              "Provided by the Springer Nature SharedIt content-sharing initiative Nature Reviews Clinical Oncology (2023) Journal of Gastrointestinal Cancer (2023) Drug Safety (2023) Experimental Hematology & Oncology (2022) BMC Medical Informatics and Decision Making (2022) By submitting a comment you agree to abide by our Terms and Community Guidelines.",
              "If you find something abusive or that does not comply with our terms or guidelines please flag it as inappropriate.",
              "Advertisement Scientific Reports (Sci Rep) ISSN 2045-2322 (online) \u00a9 2023 Springer Nature Limited Sign up for the Nature Briefing newsletter \u2014 what matters in science, free to your inbox daily."
            ]
          },
          {
            "title": "STAT: IBM&#39;s Watson gave &#39;unsafe and incorrect&#39; cancer treatment advice ...",
            "url": "https://www.healthcaredive.com/news/stat-ibms-watson-gave-unsafe-and-incorrect-cancer-treatment-advice/528666/",
            "content": [
              "STAT: IBM&#39;s Watson gave &#39;unsafe and incorrect&#39; cancer treatment advice ...",
              "Let Healthcare Dive's free newsletter keep you informed, straight from your inbox.",
              "Topics covered: Hospital administration, operations, care delivery, M&A, health IT, policy & regulations, health insurance Topics covered: Payer-provider partnerships, value-based care efforts, payer market moves, healthcare reform Topics covered: Interoperability, artificial intelligence, digital health, EHRs, cybersecurity, vendor activity, and telehealth The documents include comments from a physician at Jupiter Hospital in Florida, who told IBM officers: \u201cThis product is a piece of s\u2014.",
              "We bought it for marketing and with hopes that you would achieve the vision.",
              "We can\u2019t use it for most cases.",
              "\u201d Several IBM employees also reported to Norden that Watson for Oncology was \u201cvery limited,\u201d according to STAT.",
              "In a statement, IBM defended Watson for Oncology, saying it has trained oncologists to treat 13 cancers and supported care for more than 84,000 patients at 230 hospitals around the world.",
              "\u201cWe have learned and improved Watson Health based on continuous feedback from clients, new scientific evidence and new cancers and treatment alternatives.",
              "This includes 11 software releases for even better functionality during the past year, including national guidelines for cancers ranging from colon to liver cancer,\u201d the statement reads.",
              "This is not the first troubling account of the program.",
              "A 2017 Forbes report found that Watson Health\u2019s partnership with MD Anderson Cancer Center was not meeting up to its goals.",
              "The report said MD Anderson was actively seeking bids from other contractors that might replace IBM in future projects.",
              "And a previous STAT investigation found Watson Health has struggled to learn about different cancer types, with a relatively small number of hospitals adopting its oncology offerings.",
              "Watson Health has been showing other signs of stress recently.",
              "Last month, Watson Health officials cited soft product demand and changes to the Affordable Care Act for a decision to scale back its hospital business.",
              "The decision marks an abrupt turn for a company that has invested heavily to win contracts with hospitals moving to value-based care.",
              "The business develops tools to help providers manage their pay-for-performance contracts.",
              "IBM also recently confirmed that it had laid off an undisclosed number of workers at Watson Health, but maintained its cognitive solutions unit would remain strong.",
              "The reports of inaccurate advice could slow growth of machine learning and artificial intelligence-assisted efforts in medicine, or at least deepen the conviction many hold that humans need to make the ultimate decisions regarding patient care.",
              "During HIMSS 2018, an expert panel suggested that AI\u2019s potential may be overhyped, but that the technology is ready for prime time.",
              "What\u2019s needed is physician trust that AI is reliable and worthy of being adopted.",
              "Get the free daily newsletter read by industry experts In an increasingly murky legal environment, providers should focus on minimizing and protecting the data they collect, experts said.",
              "Changes to the Medicare Shared Savings Program would give some accountable care organizations more time to ramp up to performance-based risk and updated quality reporting.",
              "Subscribe to Healthcare Dive for top news, trends & analysis Get the free daily newsletter read by industry experts In an increasingly murky legal environment, providers should focus on minimizing and protecting the data they collect, experts said.",
              "Changes to the Medicare Shared Savings Program would give some accountable care organizations more time to ramp up to performance-based risk and updated quality reporting.",
              "The free newsletter covering the top industry headlines"
            ]
          }
        ],
        "DeepMind is a company that develops AI systems for healthcare applications such as protein folding, eye disease detection, and radiotherapy planning.": [
          {
            "title": "Scaling Streams with Google - Google DeepMind",
            "url": "https://deepmind.google/discover/blog/scaling-streams-with-google/",
            "content": [
              "Scaling Streams with Google - Google DeepMind",
              "Company Demis Hassabis, Mustafa Suleyman, Dominic King We\u2019re excited to announce that the team behind Streams - our mobile app that supports doctors and nurses to deliver faster, better care to patients - will be joining Google.",
              "It\u2019s been a phenomenal journey to see Streams go from initial idea to live deployment, and to hear how it\u2019s helped change the lives of patients and the nurses and doctors who treat them.",
              "The arrival of world-leading health expert Dr.",
              "David Feinberg at Google will accelerate these efforts, helping to make a difference to the lives of millions of patients around the world.",
              "This is a major milestone for DeepMind!",
              "One of the reasons for joining forces with Google in 2014 was the opportunity to use Google\u2019s scale and experience in building billion-user products to bring our breakthroughs more rapidly to the wider world.",
              "It\u2019s been amazing to put this into practice in data centre efficiency, Android battery life, text-to-speech applications, and now the work of our Streams team.",
              "Over the past three years we\u2019ve built a team of experts in what it takes to deploy clinical tools in practice - engineers, clinicians, translational researchers and more.",
              "In that time, we\u2019ve also made major advances in healthcare AI research: detecting eye disease more quickly and accurately than experts;",
              "planning cancer radiotherapy treatment in seconds rather than hours;",
              "and working to detect patient deterioration from electronic records.",
              "Our vision is for Streams to now become an AI-powered assistant for nurses and doctors everywhere - combining the best algorithms with intuitive design, all backed up by rigorous evidence.",
              "The team working within Google, alongside brilliant colleagues from across the organisation, will help make this vision a reality.",
              "The Streams team will remain in London, under the leadership of former NHS surgeon and researcher Dr Dominic King.",
              "We\u2019re fully committed to all our NHS partners, and to delivering on our current projects and more.",
              "We\u2019ll be working closely with them as we plan for the team\u2019s transition, and information governance and safety remain our top priorities.",
              "Patient data remains under our partners\u2019 strict control, and all decisions about its use will continue to lie with them.",
              "As a research organisation, DeepMind will continue to lead the way in fundamental research applying AI to important science and medical research questions, in collaboration with academic partners, to accelerate scientific progress for the benefit of everyone.",
              "Over the coming years, we expect AI to help scientists make transformative advances on problems ranging from protein folding to image analysis, potentially improving medical diagnosis, drug discovery and much more.",
              "We\u2019re excited to play our part in that journey both at DeepMind and at Google, in the service of patients and clinicians around the world.",
              "Update: On September 18 2019, we confirmed DeepMind Health had joined the Google Health family.",
              "Find out more here.",
              "I accept Google's Terms and Conditions and acknowledge that my information will be used in accordance with Google's Privacy Policy."
            ]
          },
          {
            "title": "Lessons from DeepMind\u2019s breakthrough in protein-folding A.I. - Fortune",
            "url": "https://fortune.com/2020/12/01/lessons-from-deepminds-a-i-breakthrough-eye-on-ai/",
            "content": [
              "Lessons from DeepMind\u2019s breakthrough in protein-folding A.I. - Fortune",
              "This is the web version of Eye on A.",
              "I.",
              ", Fortune\u2019s weekly newsletter covering artificial intelligence and business.",
              "To get it delivered weekly to your in-box, sign up here.",
              "The biggest news in A.",
              "I.",
              "this week is DeepMind\u2019s breakthrough on protein-folding.",
              "A question that had confounded scientists for more than 50 years\u2014how to use a protein\u2019s genetic sequence to predict the exact three-dimensional shape that a protein will take\u2014has effectively been answered by DeepMind\u2019s A.",
              "I.",
              "system, which can now predict the structure of a protein to within an atom\u2019s width of accuracy in many cases.",
              "I got exclusive access to DeepMind\u2019s protein-folding team in the run up to Monday\u2019s announcement.",
              "You can read my in-depth feature on exactly how the London-based A.",
              "I.",
              "company accomplished this goal here.",
              "You can also read about how its A.",
              "I.",
              "system, called AlphaFold 2, has already contributed to the fight against the COVID-19 pandemic here.",
              "Today, I\u2019ll highlight some lessons that emerged from DeepMind\u2019s work on AlphaFold 2 that could apply to any company building an A.",
              "I.",
              "system.",
              "\u2022 \u201cOff-the-shelf\u201d A.",
              "I.",
              "will only get you so far.",
              "Two years ago, DeepMind created a different A.",
              "I.",
              "system to predict protein structures.",
              "That original AlphaFold\u2014AlphaFold 1.",
              "0 if you will\u2014was pretty good, but not good enough to be very useful for biologists and medical researchers.",
              "John Jumper, the senior researcher who leads DeepMind\u2019s protein folding team, tells me that the original AlphaFold used \u201crelatively off the shelf neural network technology,\u201d in this case a standard type of neural network architecture originally used to classify objects in images.",
              "When it came time to try to improve the system, he says, \u201cWhat we found is we\u2019ve hit a real wall in what we were able to do with these types of techniques.",
              "\u201dTo get better performance, DeepMind had to go back to the drawing board and design a neural network that was much more bespoke to the problem it was trying to solve.",
              "It began with a first principles question, Jumper says: \u201cWhat should the solution look like?",
              "And how do we put that into our neural network instead of around it?",
              "\u201dThat\u2019s an important lesson for companies to remember, particularly if they are considering using outside vendors and pre-built A.",
              "I.",
              "components.",
              "\u2022End-to-end systems are better than assemblages of components.",
              ".",
              ".",
              "The 2018 AlphaFold was a collection of parts: one neural network predicted the distance between amino acid pairs in a protein, another tried to determine the most likely angles between them, and a third piece refined the overall structure.",
              "By contrast, AlphaFold 2 is what\u2019s known as an \u201cend-to-end system\u201d\u2014it takes the genetic information as an input and directly outputs a three-dimensional structure.",
              "It\u2019s a good reminder that end-to-end systems generally achieve better performance.",
              "\u2022.",
              ".",
              ".",
              "but don\u2019t ignore the \u201ctrust\u201d factor.",
              "But a big problem with neural networks that perform a task end-to-end is that they can be highly inscrutable.",
              "And that opacity can make it difficult for humans using the software to trust it.",
              "In fact, this is why, in 2018, when DeepMind built a different A.",
              "I.",
              "system to diagnose 50 different sight-threatening eye diseases from a particular kind of eye scan, it used a system consisting of two different neural networks: One took in the raw data from the scanner and turned that into disease features;",
              "one then made diagnoses.",
              "This allowed human doctors to have more insight into why the diagnostic system was making its decisions.",
              "In the case of AlphaFold 2, what DeepMind has done instead is build in a confidence gauge, which asks AlphaFold 2 to say how confident it is in its own predictions for each part of the protein structure.",
              "That confidence doesn\u2019t really explain why AlphaFold 2 is predicting the structure, but it will give biologists and medical researchers some sense of when they should trust the predictions and when to treat them with more skepticism \u2022Domain expertise matters.",
              "DeepMind trounced academic molecular biology labs that had been working on the protein-folding problem for a lot longer.",
              "Part of the reason is that while these academic labs are full of people who deeply understand protein structure, they are not computer scientists.",
              "DeepMind has a level of machine learning expertise and engineering resources that these academic labs lack.",
              "But, that being said, the team required input from protein structure experts.",
              "\u201cWe are always collaborative with domain experts,\u201d Demis Hassabis, DeepMind\u2019s co-founder and chief executive officer says.",
              "Eventually DeepMind even hired some of these experts, like Jumper.",
              "\u2022But having a diverse team matters too.",
              "DeepMind also had people on the team from a range of different science backgrounds.",
              "That diversity is helpful, Pushmeet Kohli, the head of DeepMind\u2019s A.",
              "I.",
              "for science division, tells me, because sometimes people coming from outside the field will have an insight that people from within the field can miss.",
              "The key to making a diverse team work?",
              "\u201cRespect,\u201d Kohli says.",
              "\u201cBeing respectful of all different ways that people contribute and all the different insights that all these different people have.",
              "\u201d But, Kohli tells me, each person on the team should never lose sight of the fact that the goal is to solve the problem\u2014not to prove that a particular approach to solving it is the right one.",
              "\u201cThe problem is the most important thing and everyone is contributing towards it in their own different way,\u201d he says.",
              "\u2022Try more than one \u201cmode\u201d of working.",
              "Researchers who worked on AlphaFold 2 told me that they got stuck many times and couldn\u2019t figure out how they were ever going to make more progress.",
              "In such moments, Hassabis says, it is worth switching between two different modes of working: One, which he calls \u201cstrike mode,\u201d involves pushing the team to ring as much performance as possible out of the existing approach.",
              "But, when this stops working, he says, it is critical to switch to a \u201ccreative mode.",
              "\u201d In this work style, Hassabis no longer presses the team on performance\u2014in fact, he tolerates and even expects some temporary declines\u2014and instead encourages the team to experiment widely.",
              "\u201cYou want to encourage as many crazy ideas as possible, brainstorming,\u201d he says.",
              "While some people can work equally well in both modes, others are more comfortable with one work style.",
              "Hassabis says it is important to recognize this\u2014and even be prepared to change up the team\u2019s composition and bring in fresh people with new ideas or people better suited to a particular work mode.",
              "Now, here\u2019s the rest of this week\u2019s A.",
              "I.",
              "news.",
              "Jeremy Kahn@jeremyakahnjeremy.",
              "kahn@fortune.",
              "com Facebook's use of A.",
              "I.",
              "for content moderation under fire for failures.",
              "Last month Facebook announced that its automated content moderation systems had gotten good enough that they would take over triaging the posts that are brought to the company's 15,000 human content moderators for review.",
              "But the new system doesn't seem to have pleased many folks.",
              "Bloomberg reported that many small businesses have had their advertising accounts banned in error by the new software and that they've been unable to get the company to address the problems. Facebook has issued a statement apologizing for \"any inconvenience recent disruptions may have caused\" but the underlying issue does not seem to have been remedied.",
              "For more about how Facebook is using A.",
              "I.",
              "across its business and whether it is actually making a dent in the company's massive issues with hate speech, disinformation, phony accounts and more, tune into Web Summit for my fireside chat with Mike \"Schrep\" Schroepfer, Facebook's chief technology officer, on December 2nd at 7:25 p.",
              "m.",
              "GMT (2:25 pm EST).",
              "ServiceNow acquires Element AI.",
              "The Montreal-based Element AI, which builds machine learning systems for industry customers, is being acquired by ServiceNow, the cloud-based IT services company, for $500 million, according to a story in TechCrunch.",
              "The acquisition represents a major push into A.",
              "I.",
              "for ServiceNow, which is now being helmed by former SAP CEO Bill McDermott, who has made a series of deals recently as he seeks to turn ServiceNow into a one-stop shop for managing companies' digital transformation efforts.",
              "Cerebras claims its massive A.",
              "I.",
              "computer chip can map fluid dynamics faster than a supercomputer.",
              "The Silicon Valley-based A.",
              "I.",
              "computer chip startup says that its CS-1 system, which consists of a single 18-gigabyte chip that has to be kept in a cooling device about the size of a mini-refrigerator, was 200 times faster at running a complex fluid dynamics simulation than the U.",
              "S.",
              "Department of Energy's Joule supercomputer, according to a story in tech publication The Register.",
              "But the CS-1 was only racing against Joule's largest processing cluster, consisting of 16,384 cores, and not Joule's complete arsenal of 84,000 cores.",
              "Plus, \"the results should be taken with a pinch of salt,\" The Register cautions, \"as the company has yet to publicly disclose its chip performance in more typical benchmarking tests used for AI and machine learning.\"",
              "FAA gets closer to approving commercial drones that can operate autonomously.",
              "In a move that brings drone delivery operations in the U.",
              "S.",
              "one step closer to reality, the U.",
              "S.",
              "Federal Aviation Authority has issued airworthiness criteria for 10 drones, some of which are designed to operate autonomously out of the line of sight of their operators, the agency said.",
              "The criteria were issued for drones made by Amazon, as well as startup Airobtoics, Zipline and Wingcopter, among others.",
              "A Supreme Court case could make it easier for researchers to find security flaws in A.",
              "I.",
              "systems. This week the U.",
              "S.",
              "Supreme Court heard oral arguments in Van Buren v.",
              "United States which will test whether cybersecurity researchers are potentially violating the 1986 Computer Fraud and Abuse Act (CFAA) when they try to find vulnerabilities in existing software and systems. A lower court ruled that this sort of research should not run afoul of the law.",
              "If the Supreme Court agrees, it will also make it easier for researchers interested in adversarial machine learning\u2014a field of research which deals with how A.",
              "I.",
              "systems can be tricked into incorrect classification decisions or predictions.",
              "But if the Court reverses the lower court and says that security researchers can be prosecuted for improper use of software, it is likely to have a chilling effect on the field, according to a story in Venture Beat.",
              "My colleague Aaron Pressman also has more about the law and the case in Monday's Data Sheet newsletter.",
              "Archaeologists are using machine learning to take the grunt work out of their jobs.",
              "A.",
              "I.",
              "is starting to have a major impact on science, as the DeepMind protein-folding breakthrough shows.",
              "But so far, most uses of machine learning in science are less about these fundamental advances and more about process: automating time-consuming and tedious data-collection processes, as a story in The New York Times demonstrates.",
              "The paper looks at how A.",
              "I.",
              "is being used to spot possible Scythian burial mounds in satellite images, count and classify Roman pottery sherds, or identify human bones illegally being sold on the Internet.",
              "ABBYY, a digital intelligence and robotic process automation company based in Milpitas, California, has named Weronika Niemczyk as chief people officer, the company said in a statement.",
              "Niemczyk previously led human resources Ascential, a British media business specializing in events, exhibitions and festivals.",
              "Orbital Insight, the Palo Alto, California-based satellite imagery analytics company, has appointed Kevin O'Brien as its new chief executive officer, the company said in a news release.",
              "O'Brien had previously been the company's chief operating officer.",
              "Company founder James Crawford, who had been CEO, is transitioning to become chairman of the board as well as chief technology officer.",
              "Your fancy-pants sales forecasting A.",
              "I.",
              "might not be as good as you think.",
              "That's the conclusion of a study conducted by researchers from Naver, the South Korea Internet company.",
              "In a paper published on the research repository arxiv.",
              "org, the Naver team looked at the performance of probabilistic time-series models that have become popular lately for sales forecasting tasks and compared them to a simpler machine learning model and to linear regression.",
              "The bad news?",
              "Both the simple methods outperformed three supposedly state-of-the-art probabilistic A.",
              "I.",
              "techniques.",
              "Part of the problem, the researchers report, is that past tests of the probabilistic methods mostly evaluated them on whether they were above or below a certain limit, but not how well they did at forecasting a precise future sales figure.",
              "But having an exact forecast \"is essential in industries that require specific numbers, such as the number of delivery people in a logistics company.\"",
              "What's more, many of the more sophisticated sales forecasting models had erratic performance on different tests, the researchers found.",
              "They issued a fairly stinging indictment of the way research on probabilistic models has been conducted and suggest that many previous studies may have cherry-picked the data used to evaluate these systems. \"Prominent probabilistic time-series models do not work effectively especially for other datasets not used in the original papers,\" the researchers report.",
              "As libraries fight for access to e-books, a new copyright champion emerges\u2014by Jeff John Roberts This new VR simulator helps you prepare for the most awkward office encounters\u2014by Lee Clifford Why India\u2019s software startups are poised for global dominance\u2014by Atul Jalan and Brewer Stone Know when to fold \u2019em: How a company best known for playing games used A.",
              "I.",
              "to solve one of biology\u2019s greatest mysteries\u2014by Jeremy Kahn The technological arms race between the U.",
              "S.",
              "and China over artificial intelligence is growing.",
              "Both nations believe that A.",
              "I.",
              "could give their respective militaries a big strategic and tactical advantage.",
              "But Avi Goldfarb and Jon Lindsay take a sober look at just what kind of military advantage A.",
              "I.",
              "may convey in a new report published by The Brookings Institution.",
              "The answer, they say, has as much to do with the human strengths of the military organization using A.",
              "I.",
              "as it does the technological capabilities themselves.",
              "\"In cases where decision problems are well-defined and plentiful relevant data is available, it may indeed be possible for machines to replace humans.",
              "In the military context, however, such situations are rare.",
              "Military problems tend to be more ambiguous while reliable data is sparse.",
              "Therefore, we expect AI to enhance the need for military personnel to determine which data to collect, which predictions to make, and which decisions to take.\"",
              "Goldfarb and Lindsay say that it is critical that junior military staff understand the data that is fed into automated decision systems, and how an enemy might try to target or manipulate that data.",
              "More human judgment is needed in the lower ranks, not less.",
              "They also write that having better A.",
              "I.",
              "prediction systems may also lead to a kind of analysis-paralysis on the part of human decision makers: \"Ironically, however, the same organizational capacity that enables judgment, and thereby makes war fighting more predictable and controllable, also has the potential to make conflict more ambiguous and less decisive.",
              "In short, the ability to automate aspects of decisionmaking can make it harder to come to a decision within an organization or on the battlefield.\"",
              "Do these same lessons apply in many business contexts?",
              "I am always wary about analogies between business and war, and between the organization of militaries and companies, but my guess is that they probably do.",
              "\u00a9 2023 Fortune Media IP Limited.",
              "All Rights Reserved.",
              "Use of this site constitutes acceptance of our Terms of Use and Privacy Policy | CA Notice at Collection and Privacy Notice | Do Not Sell/Share My Personal Information | Ad Choices FORTUNE is a trademark of Fortune Media IP Limited, registered in the U.",
              "S.",
              "and other countries.",
              "FORTUNE may receive compensation for some links to products and services on this website.",
              "Offers may be subject to change without notice.",
              "S&P Index data is the property of Chicago Mercantile Exchange Inc.",
              "and its licensors.",
              "All rights reserved.",
              "Terms & Conditions.",
              "Powered and implemented by Interactive Data Managed Solutions."
            ]
          },
          {
            "title": "AI Imaging &amp; Diagnostics - Google Health",
            "url": "https://health.google/health-research/imaging-and-diagnostics/",
            "content": [
              "AI Imaging &amp; Diagnostics - Google Health",
              "Health Skip to Content Health Overview The Check Up Health equity Privacy About us The Check Up Learn from Dr.",
              "Karen DeSalvo and others about Google Health, our company-wide effort to help billions of people be healthier.",
              "with Consumers Overview YouTube DermAssist Google Fit Fitbit Health Connect Google Health Studies Nest Google Search Self-assessments Caregivers Overview ARDA Care Studio Mammography Ultrasound Google Cloud Communities Overview Data and tools Research Informing communities Researchers Overview Genomics Imaging & Diagnostics Mobile sensing Publications In partnership with healthcare organizations globally, wea\u0302\u0080\u0099re researching robust new AI-enabled tools focused on diagnostics to assist clinicians.",
              "Drawing from diverse datasets, high-quality labels, and state-of-the-art deep learning techniques, we are making models that we hope will eventually support medical specialists in diagnosing disease.",
              "Wea\u0302\u0080\u0099re excited to further develop this research towards new frontiersa\u0302\u0080\u0094and to demonstrate that AI has the ability to enable novel, transformative diagnostics.",
              "This product has been CE marked as a Class I medical device in the EU.",
              "It is not available in the United States.",
              "Through computer vision AI and image search capabilities, we are developing a tool to help individuals better research & identify their skin, hair, and nail conditions.",
              "The tool supports hundreds of conditions, including more than 80% of the conditions seen in clinics and more than 90% of the most commonly searched conditions.",
              "The work was highlighted in both Nature Medicine and JAMA Network Open.",
              "Learn more Automated Retinal Disease Assessment (ARDA) is being used to help clinicians detect diabetic retinopathy, a leading cause of blindness, in India and across the world.",
              "With widespread adoption, perhaps millions of patients with diabetes could keep their vision in part to ARDA assisting doctors.",
              "Our research was published in JAMA and Ophthalmology.",
              "Additional research, published in Lancet Digital Health, showed that we can predict whether patients will develop diabetic retinopathy in the future, which can help doctors customize both treatment and eye screening frequencies for their patients.",
              "The solution is currently being evaluated in clinical studies in the United States as well as in Thailand.",
              "Learn more.",
              "Lung cancer leads to over 1.",
              "8 million deaths per year world wide, accounting for almost one in five cancer deaths, and is the largest cause of cancer mortality.",
              "Our research, published in Nature Medicine, shows that deep learning may eventually help physicians more accurately screen for lung cancer and identify the disease even in incidental lung cancer detection workflows.",
              "Read the post Anemia Detection Computer Vision The human eye can reveal signs of underlying diseases like anemia, a condition that affects 1.",
              "6 billion people worldwide causing tiredness, weakness, dizziness and drowsiness.",
              "In research published in Nature Biomedical Engineering, we were able to use deep learning to quantify hemoglobin levels and detect anemia with de-identified photographs of the back of the eye.",
              "This result means ita\u0302\u0080\u0099s possible that someday providers may be able to detect the disease with a simple non-invasive screening tool.",
              "Read the post The human eye can reveal signs of underlying diseases like anemia, a condition that affects 1.",
              "6 billion people worldwide causing tiredness, weakness, dizziness and drowsiness.",
              "In research published in Nature Biomedical Engineering, we were able to use deep learning to quantify hemoglobin levels and detect anemia with de-identified photographs of the back of the eye.",
              "This result means ita\u0302\u0080\u0099s possible that someday providers may be able to detect the disease with a simple non-invasive screening tool.",
              "Read the post Assessing the risk of cardiovascular diseases is the first and most critical step toward reducing the likelihood that a patient suffers a cardiovascular event in the future.",
              "By applying deep learning techniques to retinal images, wea\u0302\u0080\u0099ve been able to reveal factors associated with the risk of a major cardiovascular event like a heart attack or stroke, as published in Nature Biomedical Engineering.",
              "This research could help scientists generate more targeted hypotheses and drive a wide range of future research.",
              "Read the post Assessing the risk of cardiovascular diseases is the first and most critical step toward reducing the likelihood that a patient suffers a cardiovascular event in the future.",
              "By applying deep learning techniques to retinal images, wea\u0302\u0080\u0099ve been able to reveal factors associated with the risk of a major cardiovascular event like a heart attack or stroke, as published in Nature Biomedical Engineering.",
              "This research could help scientists generate more targeted hypotheses and drive a wide range of future research.",
              "Read the post Clinical Practice Deep Learning Breast cancer screening helps detect cancer earlier, but diagnosing breast cancer accurately and consistently remains a challenge, with half of all women experiencing a false-positive over a 10-year period.",
              "In Nature, we demonstrated the potential of our AI model to analyze de-identified retrospectively collected screening mammograms with similar or better accuracy than clinicians.",
              "Now, wea\u0302\u0080\u0099re collaborating on an investigative device research study to understand how the model can help in clinical practice to reduce the time from screening mammography to diagnosis, narrowing the assessment gap and improving the patient experience.",
              "Read the post Breast cancer screening helps detect cancer earlier, but diagnosing breast cancer accurately and consistently remains a challenge, with half of all women experiencing a false-positive over a 10-year period.",
              "In Nature, we demonstrated the potential of our AI model to analyze de-identified retrospectively collected screening mammograms with similar or better accuracy than clinicians.",
              "Now, wea\u0302\u0080\u0099re collaborating on an investigative device research study to understand how the model can help in clinical practice to reduce the time from screening mammography to diagnosis, narrowing the assessment gap and improving the patient experience.",
              "Read the post In our pathology research published in the Archives of Pathology & Laboratory Medicine as well as The American Journal of Surgical Pathology, we showed how a proof-of-concept assistance tool (LYNA) could use deep learning to increase the accuracy of metastatic breast cancer detection.",
              "Read the post In our pathology research published in the Archives of Pathology & Laboratory Medicine as well as The American Journal of Surgical Pathology, we showed how a proof-of-concept assistance tool (LYNA) could use deep learning to increase the accuracy of metastatic breast cancer detection.",
              "Read the post Wea\u0302\u0080\u0099re doing research and building AI models that can not only decipher important information from retinal images, but rather from external eye images.",
              "In our research published in The Lancet Digital Health, we show that a deep learning model can predict the presence of diabetic retinal disease and other biomarkers such as HbA1c or eGFR from external eye images alone.",
              "This could reduce the need for specialized equipment and expand access to care for the growing population of patients with diabetes or other chronic diseases.",
              "Read the post We continue to advance AI-enabled imaging research in other domains, expanding this technology to facilitate transformative diagnostics.",
              "AI Advances AI Learning AI Diagnosis Building off of work done with the University College London Hospitals and published in JMIR Publications, we are collaborating with Mayo Clinic to study the use of AI to help clinicians plan radiotherapy treatment for cancer.",
              "Wea\u0302\u0080\u0099ve joined forces to research, train and validate an algorithm to assist physicians with segmenting healthy tissue and organs from tumors to reduce treatment planning time and improve the efficiency of radiotherapy, hopefully allowing clinicians to spend less time planning and more time with their patients.",
              "Read the post Building off of work done with the University College London Hospitals and published in JMIR Publications, we are collaborating with Mayo Clinic to study the use of AI to help clinicians plan radiotherapy treatment for cancer.",
              "Wea\u0302\u0080\u0099ve joined forces to research, train and validate an algorithm to assist physicians with segmenting healthy tissue and organs from tumors to reduce treatment planning time and improve the efficiency of radiotherapy, hopefully allowing clinicians to spend less time planning and more time with their patients.",
              "Read the post Colorectal cancer (CRC) is a global health problem and the second deadliest cancer in the United States, resulting in an estimated 900K deaths per year.",
              "By alerting physicians to missed regions of the colon wall, our algorithm has the potential to lead to the discovery of more adenomas, thereby increasing the adenoma detection rate and decreasing the rate of interval colorectal cancer, as published in IEEE Transactions on Medical Imaging.",
              "Read the post Colorectal cancer (CRC) is a global health problem and the second deadliest cancer in the United States, resulting in an estimated 900K deaths per year.",
              "By alerting physicians to missed regions of the colon wall, our algorithm has the potential to lead to the discovery of more adenomas, thereby increasing the adenoma detection rate and decreasing the rate of interval colorectal cancer, as published in IEEE Transactions on Medical Imaging.",
              "Read the post To diagnose the severity of prostate cancer, biopsies are analyzed and given a Gleason grade, which is scored on comparisons to healthy cells.",
              "In work published in JAMA Oncology and JAMA Network Open, we explored whether an AI system could accurately Gleason grade prostate biopsies, and our results indicated that the deep learning system has the potential to support expert-level diagnoses.",
              "Read the post To diagnose the severity of prostate cancer, biopsies are analyzed and given a Gleason grade, which is scored on comparisons to healthy cells.",
              "In work published in JAMA Oncology and JAMA Network Open, we explored whether an AI system could accurately Gleason grade prostate biopsies, and our results indicated that the deep learning system has the potential to support expert-level diagnoses.",
              "Read the post Follow us"
            ]
          }
        ],
        "Waymo is a company that develops self-driving cars that use AI to perceive their surroundings and navigate complex scenarios.": [
          {
            "title": "The Waymo Driver Handbook: Teaching an autonomous vehicle how to ...",
            "url": "https://waymo.com/blog/2021/10/the-waymo-driver-handbook-perception.html",
            "content": [
              "The Waymo Driver Handbook: Teaching an autonomous vehicle how to ...",
              "October 28, 2021 Waymo may disclose user personal information to third parties to tailor advertising and offers to your interests.",
              "Such disclosures may be considered \u201csales\u201d or \u201csharing\u201d of personal information under the laws described above.",
              "California residents may opt-out of these below.",
              "If you opt out, Waymo will not disclose your personal information to third parties for purposes of tailoring advertising or offers to your interests.",
              "Note that any choice you make here will only affect this website on this browser and device.",
              "To learn more about how your data is shared, view our Privacy Policy page."
            ]
          },
          {
            "title": "Case Study: Waymo - Pioneering Self-Driving Technology with AI and ...",
            "url": "https://aitrot.com/case-study-waymo-pioneering-self-driving-technology-with-ai-and-lidar/applications/",
            "content": [
              "Case Study: Waymo - Pioneering Self-Driving Technology with AI and ...",
              "AITroT AITroT One of the most famous and influential case studies showcasing the key advancements in AI algorithms empowering LIDAR data analysis is the development of Google\u2019s autonomous vehicle project, now known as Waymo.",
              "Waymo, a subsidiary of Alphabet Inc.",
              "(formerly Google\u2019s self-driving car project), has emerged as a trailblazer in the autonomous vehicle industry.",
              "Central to Waymo\u2019s success is the seamless integration of AI algorithms with LIDAR technology, revolutionizing the way self-driving cars perceive and navigate the world around them.",
              "The journey of Waymo began in 2009 when Google initiated its ambitious self-driving car project.",
              "The project aimed to create fully autonomous vehicles capable of safely navigating complex real-world scenarios.",
              "In the early stages, the team experimented with various sensor technologies, including cameras and radar.",
              "However, the limitations of these sensors in challenging environments led Waymo to explore the integration of LIDAR technology.",
              "Waymo\u2019s journey is far from over.",
              "The company\u2019s commitment to continuous innovation has propelled the development of more sophisticated AI algorithms, leading to ever-improving LIDAR data analysis.",
              "As Waymo continues to expand its autonomous vehicle fleet and deploy self-driving technology in various real-world applications, their advancements will undoubtedly shape the future of transportation and inspire further innovations across the autonomous vehicle industry.",
              "Waymo\u2019s integration of AI algorithms with LIDAR technology has been at the forefront of autonomous vehicle development.",
              "Their groundbreaking work has demonstrated the transformative potential of combining these cutting-edge technologies.",
              "As the autonomous vehicle industry continues to evolve, Waymo\u2019s pioneering efforts in AI-powered LIDAR remain a landmark case study, inspiring further advancements in self-driving technology and contributing to a safer, more efficient, and sustainable future of transportation.",
              "Self-Driving Technology with AI and LIDAR on Amazon Source OpenAI\u2019s GPT-3 language model, Fleeky, MIB, & Picsart AI is a magnificient tool when stirred with knowledge and wisdom.",
              "This site is made with help of AI tools.",
              "Enjoy the beauty!",
              "Your email address will not be published.",
              "Required fields are marked * Name * Email * Website Comment * Save my name, email, and website in this browser for the next time I comment.",
              "Website Comment for robots Please empty this comment field to prove you're human.",
              "\"Artificial Intelligence.",
              "Made by Humans.\"",
              "A blog filled with AI transformative generated content, text, images, video, gifs, refs.",
              "Questions, answers, solutions, directions.",
              "Bookmark our site and spread the word.",
              "Thank you!",
              "\u00a9\ufe0f All rights reserved 2023 Mlaure | Powered by WordPress This website uses cookies to improve your experience.",
              "We assume you're ok with this, but you can opt-out if you wish.",
              "Read More Accessibility Tools"
            ]
          },
          {
            "title": "Waymo&#39;s Self-Driving Cars: How They Work - Lifewire",
            "url": "https://www.lifewire.com/waymo-self-driving-cars-4171314",
            "content": [
              "Waymo&#39;s Self-Driving Cars: How They Work - Lifewire",
              "EVs have been around a long time but are quickly gaining speed in the automotive industry.",
              "Learn how the long-coming and inevitable shift to electric impacts you.",
              "Whether you want to build your own home theater or just learn more about TVs, displays, projectors, and more, we've got you covered.",
              "Get tech's top stories in 30 seconds: Driverless vehicles stir fear and excitement about the future of transportation Jump to a Section Waymo, which began as a Google research project, is at the forefront of the self-driving car revolution.",
              "The company has real-world testing underway in dozens of cities and has ambitious plans for a driverless, ride-hailing service.",
              "Waymo's stated mission is to \"make it easy and safe for people and objects to move around.\"",
              "The basic idea is that some people are really good drivers but a lot are not, and a world full of self-driving cars could potentially be much safer than a world full of human drivers.",
              "Whether or not that's true, self-driving cars from companies like Waymo can be a tremendous asset for elderly or disabled drivers, as well as people who do not have a driver's license.",
              "Driverless technology also shows promise in emergency situations.",
              "For example, if a driver becomes ill or incapacitated and cannot drive, a vehicle equipped with self-driving technology could take over and drive them to safety.",
              "The real-world applications for self-driving technology are in moving people and goods from one place to another.",
              "Ride-sharing services like Lyft and Uber, as well as delivery services like UPS, stand to save millions in labor costs.",
              "There are real concerns about the automation of these jobs and what such displacement will have on the job market.",
              "Nonetheless, companies like Waymo are charting a path towards a driverless economy with little to no obstruction.",
              "Waymo has testing locations in California, Texas, Washington, Georgia, Michigan, and Arizona, with the most extensive testing taking place in Arizona.",
              "Ultimately, the availability of Waymo hinges on local laws governing self-driving vehicles.",
              "That means driverless cars can only operate on public roads in locations where they have received explicit approval.",
              "Some of the friendliest laws for self-driving cars are in Arizona and California.",
              "Waymo kicked off its Early Rider program in Chandler, AZ in 2017.",
              "Members of the program are able to request a Waymo ride to school, work, the grocery store, or other destinations.",
              "California granted similar approval to the company in 2019, allowing Waymo to transport passengers with its fleet of robotaxis.",
              "Waymo launched in 2009 as the Google Self-Driving Car Project.",
              "In 2016, it was spun off as a subsidiary of Google's parent company Alphabet.",
              "Prior to the split, the Self-Driving Car Project was responsible for many of the most important breakthroughs in the world of driverless vehicles.",
              "In 2012, Waymo's predecessor received the first-ever license for a self-driving car, when a heavily modified Toyota Prius was granted permission to drive on Nevada roads.",
              "At the time, state law required an emergency backup driver to be behind the wheel at all times, as well as a second person in the passenger seat.",
              "The legislation opened the door for real-world testing of Google's self-driving technology.",
              "Between 2012 and 2018, vehicles powered by Google and Waymo's driverless technology racked up over six million miles on public roads.",
              "By 2017, Waymo was allowed to deploy its driverless cars on Arizona roads without safety drivers.",
              "Arizona was also the site of Waymo's first semi-public driverless ride-hailing tests.",
              "The test was initially centered around the Phoenix suburb of Chandler, AZ.",
              "It was only made available to members of Waymo's Early Rider program.",
              "Waymo is intent on building self-driving technology rather than cars themselves.",
              "Google's Firefly prototype was an exception to this philosophy.",
              "The Firefly was designed exclusively for self-driving technology without a steering wheel, brake or gas pedals, or traditional controls of any kind.",
              "The Firefly prototype revealed what a driverless car could look like in the future.",
              "Waymo, however, left the concept behind to pursue a more traditional direction.",
              "Waymo's fleet of self-driving cars consists entirely of production model cars modified with self-driving technology.",
              "The two models that Waymo identified for its initial driverless fleet were the Chrysler Pacifica and the Jaguar I-Pace.",
              "Waymo worked closely with Chrysler to design a Pacifica minivan that would mesh with driverless technology, and the I-Pace is Jaguar's first all-electric crossover SUV.",
              "The technology behind Waymo's driverless cars is, on the surface, pretty simple.",
              "Each Waymo car includes highly detailed maps of the region in which it is permitted to drive.",
              "These maps are accurate down to the inch and include precise locations of roads, stop signs, traffic signals, and other driving cues.",
              "Since real-world conditions can't be predicted by even the most precise maps, each Waymo car is equipped with a LIDAR system.",
              "LIDAR is a technology that uses lasers to generate a highly accurate spacial representations.",
              "Unlike a human driver, LIDAR is able to generate a 360-degree view around a vehicle.",
              "Waymo cars can plot a course from one location to another and then react, in real-time, to the flow of traffic.",
              "Map data, LIDAR, and other sensors help keep the vehicle on a safe course.",
              "Self-driving cars rely on a lot of the same drive-by-wire technologies you can find in newer cars.",
              "For example, a self-driving car uses LIDAR to generate a picture of its surroundings, but it relies on familiar brake-by-wire technology to slow down, electronic throttle control to accelerate, and steer-by-wire technology to turn.",
              "All of these systems are controlled by onboard computers.",
              "The technology in Waymo cars allows for totally autonomous operation.",
              "However, most local laws still require driverless cars to have human operators present.",
              "In these regions, the safety driver has to sit behind the wheel and switch it into manual mode when the situation requires.",
              "Such a situation is called disengagement, and Waymo claims to have a relatively low rate.",
              "Get the Latest Tech News Delivered Every Day Hit Refresh on Your Tech News By clicking \u201cAccept All Cookies\u201d, you agree to the storing of cookies on your device to enhance site navigation, analyze site usage, and assist in our marketing efforts."
            ]
          }
        ]
      },
      "evidence": {
        "Deep learning has enabled many of the recent achievements in AI, such as AlphaGoZero, GPT-3, and StyleGAN.": [
          "Among their accomplishments, particular focus will be placed upon the recent success of AlphaGo Zero which made waves in the machine learning and artificial intelligence communities.",
          "AlphaGo Zero has surpassed its predecessor\u2019s abilities, bypassing AI\u2019s traditional method of learning games, which involves watching thousands of hours of human play.",
          "It proved that AI systems can learn how to solve the most challenging problems in highly complex domains.",
          "Deep learning (DL) and reinforcement learning (RL) methods seem to be a part of indispensable factors to achieve human-level or super-human AI systems. On the other hand, both DL and RL have strong connections with our brain functions."
        ],
        "Reinforcement learning has been used to solve challenging problems such as controlling robots, playing video games, optimizing logistics, and more.": [
          "In recent years, RL has been applied on many platforms of the robotic systems like an air-based, under-water, land-based, etc.",
          "Reinforcement learning (RL) is a framework that helps in the development of self-learning capability in robots.",
          "Therefore, RL must take a key role in the creation of autonomous robotic systems. In recent years, RL has been applied on many platforms of the robotic systems like an air-based, under-water, land-based, etc., and got a lot of success in solving complex tasks.",
          "Broadly, machine learning is classified into three parts, namely, (3) reinforcement learning: it is a learning mechanism where an agent learns through interaction with the environment."
        ],
        "One of the most notable examples of reinforcement learning is AlphaStar, a program that learned to play the game of StarCraft II at a superhuman level by competing against itself and other players.": [
          "AlphaStar is the first agent to achieve Grandmaster level in StarCraft II, and the first to reach the highest league of human players in a widespread professional esport without simplification of the game.",
          "AlphaStar relies on imitation learning combined with reinforcement learning, which has been used several times in the past.",
          "We apply reinforcement learning to improve the performance of AlphaStar based on agent-versus-agent games.",
          "AlphaStar uses a model-free, end-to-end learning approach to playing StarCraft II that sidesteps the difficulties of search-based methods that result from imperfect models, and is applicable to any domain that shares some of the challenges present in StarCraft.",
          "AlphaStar took on human opponents in a series of high profile games in January.",
          "AlphaStar was rated at Grandmaster level for all three StarCraft races and above 99.",
          "98 percent of human players, the machine-learning-focused Google spinoff announced in a new paper AlphaStar, the AI in question, achieved its Grandmaster status the old fashioned way: grinding through dozens of matches against human opponents, the paper, published on Wednesday in Nature, explains."
        ],
        "Computer vision has made significant progress in tasks such as face detection and recognition, object detection and segmentation, scene understanding, pose estimation, image synthesis, and more.": [
          "Pose estimation utilizes pose and orientation to predict and track the location of a person or object.",
          "Pose estimation operates by finding key points of a person or object.",
          "Today, the most powerful image processing models are based on convolutional neural networks (CNNs).",
          "Semantic segmentation is an important tool for visual scene understanding and a meaningful measure of uncertainty is essential for decision making.",
          "Scene understanding of high resolution aerial images is of great importance for the task of automated monitoring in various remote sensing applications.",
          "Pose estimation is a fundamental task in computer vision and artificial intelligence (AI) that involves detecting and tracking the position and orientation of human body parts in images or videos."
        ],
        "Computer vision has enabled many applications such as face unlock, augmented reality, self-driving cars, medical imaging, and more.": [
          "Medical imaging is another area where computer vision is making a big impact.",
          "The researchers have coined the term \"augmented endoscopy\" for this highly accurate, state-of-the-art method of live surgical visualization.",
          "Computer vision object tracking' is used in surveillance, autonomous vehicles, augmented reality, sports analysis, and more.",
          "Autonomous vehicles, also known as self-driving cars, are a rapidly growing area of research and development.",
          "It is used in a wide range of applications such as image and facial recognition, self-driving cars, and medical imaging analysis.",
          "Augmented reality is a technology that overlays digital information on the physical world.",
          "Computer vision in augmented reality (AR) is used to track and interpret the user's environment, and to overlay digital content on it."
        ],
        "Natural language processing has made progress in tasks such as machine translation, sentiment analysis, question answering, and text summarization.": [
          "This document aims to track the progress in Natural Language Processing (NLP) and give an overview of the state-of-the-art (SOTA) across the most common NLP tasks and their corresponding datasets.",
          "It has spread its applications in various fields such as machine translation, email spam detection, information extraction, summarization, medical, and question answering etc.",
          "It has spread its applications in various fields such as machine translation, email spam detection, information extraction, summarization, medical, and question answering etc.",
          "NLP can be used to solve various problems, such as text summarization, sentiment analysis, machine translation, and many more."
        ],
        "AlphaGoZero is a program that learned to play the game of Go from scratch and defeated the world champion.": [
          "Recently, AlphaGo became the first program to defeat a world champion in the game of Go.",
          "AlphaGo Zero rapidly progressed from entirely random moves towards a sophisticated understanding of Go concepts, including fuseki (opening), tesuji (tactics), life-and-death, ko (repeated board situations), yose (endgame), capturing races, sente (initiative), shape, influence and territory, all discovered from first principles.",
          "By playing games against itself, AlphaGo Zero surpassed the strength of AlphaGo Lee in three days by winning 100 games to 0, reached the level of AlphaGo Master in 21 days, and exceeded all the old versions in 40 days."
        ],
        "IBM Watson is a system that can analyze medical records and literature to provide evidence-based recommendations for cancer care.": [
          "In 2012, IBM closed a deal with Memorial Sloan Kettering, one of the preeminent cancer centers in the country, to train an AI to make treatment recommendations.",
          "Watson for Oncology (WFO), an artificial intelligence assistant decision system, was developed by IBM Corporation (USA) with the help of top oncologists from Memorial Sloan Kettering Cancer Center (MSK).",
          "It took more than 4 years of training, based on national comprehensive cancer network (NCCN) cancer treatment guidelines and more than 100 years of clinical cancer treatment experience in the United States, and can recommend appropriate chemotherapy regimens for specific cancer patients.",
          "In a statement, IBM defended Watson for Oncology, saying it has trained oncologists to treat 13 cancers and supported care for more than 84,000 patients at 230 hospitals around the world.",
          "They were really trying to democratize the expertise of Memorial Sloan Kettering\u2019s oncologists, to make that expertise available to patients all over the world and to develop this standardized engine for providing optimal treatment recommendations, customized to a patient, in front of a doctor, thousands of miles away."
        ],
        "DeepMind is a company that develops AI systems for healthcare applications such as protein folding, eye disease detection, and radiotherapy planning.": [
          "In that time, we\u2019ve also made major advances in healthcare AI research: detecting eye disease more quickly and accurately than experts;",
          "this week is DeepMind\u2019s breakthrough on protein-folding.",
          "planning cancer radiotherapy treatment in seconds rather than hours;"
        ],
        "Waymo is a company that develops self-driving cars that use AI to perceive their surroundings and navigate complex scenarios.": [
          "Waymo, which began as a Google research project, is at the forefront of the self-driving car revolution.",
          "One of the most famous and influential case studies showcasing the key advancements in AI algorithms empowering LIDAR data analysis is the development of Google\u2019s autonomous vehicle project, now known as Waymo.",
          "Central to Waymo\u2019s success is the seamless integration of AI algorithms with LIDAR technology, revolutionizing the way self-driving cars perceive and navigate the world around them.",
          "The project aimed to create fully autonomous vehicles capable of safely navigating complex real-world scenarios."
        ]
      },
      "subconclusions": {
        "Deep learning has enabled many of the recent achievements in AI, such as AlphaGoZero, GPT-3, and StyleGAN.": "partially supported",
        "Reinforcement learning has been used to solve challenging problems such as controlling robots, playing video games, optimizing logistics, and more.": "partially supported",
        "One of the most notable examples of reinforcement learning is AlphaStar, a program that learned to play the game of StarCraft II at a superhuman level by competing against itself and other players.": "supported",
        "Computer vision has made significant progress in tasks such as face detection and recognition, object detection and segmentation, scene understanding, pose estimation, image synthesis, and more.": "partially supported",
        "Computer vision has enabled many applications such as face unlock, augmented reality, self-driving cars, medical imaging, and more.": "supported",
        "Natural language processing has made progress in tasks such as machine translation, sentiment analysis, question answering, and text summarization.": "supported",
        "AlphaGoZero is a program that learned to play the game of Go from scratch and defeated the world champion.": "partially supported",
        "IBM Watson is a system that can analyze medical records and literature to provide evidence-based recommendations for cancer care.": "supported",
        "DeepMind is a company that develops AI systems for healthcare applications such as protein folding, eye disease detection, and radiotherapy planning.": "supported",
        "Waymo is a company that develops self-driving cars that use AI to perceive their surroundings and navigate complex scenarios.": "supported"
      }
    }
  }
}